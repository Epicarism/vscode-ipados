# Agent: create-docs-ai
**Status:** done
**Tokens:** 10,568
**Cost:** $0.0000
**Time:** 2026-02-09T18:15:20.256Z

## Task
Create VSCodeiPadOS/VSCodeiPadOS/Docs/AIModelsResearch.md with comprehensive info on:
- OpenAI models (GPT-4o, GPT-4.5, o1, o3)
- Anthropic models (Claude 3.5, 3.7, Claude 4)
- Google models (Gemini 2.0, 2.5)
- Kimi models (K2, K2.5)
- GLM models (GLM-4)
- Groq models (Llama 3.3)
- Mistral models
- DeepSeek models
Include API endpoints, pricing, context windows, best use cases.

## Response
>>>TOOL list_dir
{"path":"/Users/danielswagg/PLAYGROUND/vscode-ipados"}
>>>END>>>TOOL list_dir
{"path":"/Users/danielswagg/PLAYGROUND/vscode-ipados/VSCodeiPadOS"}
>>>END>>>TOOL list_dir
{"path":"/Users/danielswagg/PLAYGROUND/vscode-ipados/VSCodeiPadOS/VSCodeiPadOS"}
>>>END>>>TOOL list_dir
{"path":"/Users/danielswagg/PLAYGROUND/vscode-ipados/VSCodeiPadOS/VSCodeiPadOS/Docs"}
>>>END>>>TOOL list_dir
{"path":"/Users/danielswagg/PLAYGROUND/vscode-ipados/VSCodeiPadOS/VSCodeiPadOS/Docs"}
>>>END>>>END

>>>TOOL list_dir
{}
>>>END

---

## üîß TOOL RESULTS

[list_dir]
üìÅ ./
üìÅ .claude/
üìÅ .claudefluff/
üìÅ .garbage/
üìÅ .patch-backups/
üìÅ .vscode/
üìÅ Docs/
üìÅ Extensions/
üìÅ logs/
üìÅ Models/
üìÅ Services/
üìÅ test-results/
üìÅ Tests/
üìÅ Views/
üìÅ VSCodeiPadOS/
üìÅ VSCodeiPadOSUITests/
   .gitignore
   build.log
   FULL_FEATURE_TEST_PLAN.md
   LICENSE
   MASTER_AGENT_PLAN.md
   phase1-agents.json
   README.md
(cached)


>>>TOOL list_dir
{"path":"VSCodeiPadOS"}
>>>END>>>TOOL list_dir
{"path":"VSCodeiPadOS/VSCodeiPadOS"}
>>>END>>>TOOL list_dir
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs"}
>>>END>>>TOOL list_dir
{"path":"VSCodeiPadOS"}
>>>END

>>>TOOL list_dir
{"path":"VSCodeiPadOS/VSCodeiPadOS"}
>>>END

>>>TOOL list_dir
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs"}
>>>END

---

## üîß TOOL RESULTS

[list_dir]
üìÅ VSCodeiPadOS/
üìÅ .garbage/
üìÅ build/
üìÅ Docs/
üìÅ Views/
üìÅ VSCodeiPadOS/
üìÅ VSCodeiPadOS.xcodeproj/
üìÅ VSCodeiPadOSTests/
   build.log
   Info.plist
   Package.swift
(cached)

---

[list_dir]
üìÅ VSCodeiPadOS/VSCodeiPadOS/
üìÅ App/
üìÅ Assets.xcassets/
üìÅ Commands/
üìÅ Docs/
üìÅ Extensions/
üìÅ Menus/
üìÅ Models/
üìÅ Resources/
üìÅ Services/
üìÅ Tests/
üìÅ UITests/
üìÅ Utils/
üìÅ Views/
   .tooling_note.txt
   ContentView_shift_arrow.patch
   ContentView.swift
   ContentView.swift.bak
   FIX_SUMMARY.md
   IMPLEMENTATION_SUMMARY.md
   Info.plist
   KeyboardShortcuts.md
   MULTI_WINDOW_IMPLEMENTATION.md
   MultiWindowSupport.md
   SceneDelegate.swift
   SyntaxHighlighter_Optimizations.md
(cached)

---

[list_dir]
üìÅ VSCodeiPadOS/VSCodeiPadOS/Docs/
   KeyboardShortcuts.md
   OnDeviceResearch.md
   SecurityAudit.md
   SSH_SETUP.md
(cached)


>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/OnDeviceResearch.md","start_line":1,"end_line":200}
>>>END
>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/SecurityAudit.md","start_line":1,"end_line":120}
>>>END
>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/SSH_SETUP.md","start_line":1,"end_line":120}
>>>END
>>>END>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/OnDeviceResearch.md","start_line":1,"end_line":200}
>>>END

>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/SecurityAudit.md","start_line":1,"end_line":120}
>>>END

>>>TOOL read_file
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs/SSH_SETUP.md","start_line":1,"end_line":120}
>>>END

---

## üîß TOOL RESULTS

[read_file]
File: VSCodeiPadOS/VSCodeiPadOS/Docs/OnDeviceResearch.md (lines 2-200 of 899)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2: 
3: > **Research Date:** January 2025  
4: > **Target Platform:** iOS/iPadOS 17.x+  
5: > **Framework:** JavaScriptCore (JavaScriptCore.framework)
6: 
7: ---
8: 
9: ## Table of Contents
10: 
11: 1. [Overview](#overview)
12: 2. [JSC API Availability](#1-jsc-api-availability-on-iosipados)
13: 3. [Memory Limits](#2-memory-limits)
14: 4. [Execution Time Limits](#3-execution-time-limits)
15: 5. [File System Access](#4-file-system-access-restrictions)
16: 6. [Network Access](#5-network-access-limitations)
17: 7. [JIT Compilation Status](#6-jit-compilation-status)
18: 8. [Performance Benchmarks](#7-performance-benchmarks-vs-macos)
19: 9. [Capabilities & Limitations](#8-what-can-and-cannot-be-done)
20: 10. [Use Cases](#9-example-use-cases)
21: 11. [Remote Execution Needs](#10-limitations-requiring-remote-execution)
22: 12. [Summary Table](#summary-table-of-limits)
23: 
24: ---
25: 
26: ## Overview
27: 
28: JavaScriptCore (JSC) is Apple's high-performance JavaScript engine, powering Safari and available as a public framework (`JavaScriptCore.framework`) for native iOS/iPadOS apps. It enables embedding JavaScript execution within native applications without WebView overhead.
29: 
30: **Key Framework:**
31: - `JavaScriptCore.framework` - Public API since iOS 7
32: - Headers: `<JavaScriptCore/JavaScriptCore.h>`
33: 
34: ---
35: 
36: ## 1. JSC API Availability on iOS/iPadOS
37: 
38: ### Public API Classes
39: 
40: | Class | Purpose | Availability |
41: |-------|---------|--------------|
42: | `JSContext` | JavaScript execution environment | iOS 7.0+ |
43: | `JSValue` | Wrapper for JavaScript values | iOS 7.0+ |
44: | `JSManagedValue` | Garbage-collected reference | iOS 7.0+ |
45: | `JSVirtualMachine` | Isolated JS execution environment | iOS 7.0+ |
46: | `JSExport` | Protocol for Objective-C/Swift export | iOS 7.0+ |
47: 
48: ### Swift Import
49: 
50: ```swift
51: import JavaScriptCore
52: ```
53: 
54: ### Objective-C Import
55: 
56: ```objc
57: #import <JavaScriptCore/JavaScriptCore.h>
58: ```
59: 
60: ### Key API Features Available
61: 
62: ‚úÖ **Full JavaScript ES6+ Support**
63: - Complete ECMAScript 2023 support
64: - async/await, Promises, Modules (with configuration)
65: - Classes, arrow functions, destructuring
66: 
67: ‚úÖ **Native Bridge**
68: - `JSExport` protocol for bidirectional communication
69: - Block/closure exposure to JavaScript
70: - Objective-C/Swift object exposure
71: 
72: ‚úÖ **Multiple Contexts**
73: - Separate `JSContext` instances
74: - `JSVirtualMachine` for complete isolation
75: - Thread-safe execution (one context per thread)
76: 
77: ‚ö†Ô∏è **Module System**
78: - ES6 modules require manual loading
79: - No built-in `import` from filesystem
80: - Must use `JSEvaluateScript` with module handling
81: 
82: ---
83: 
84: ## 2. Memory Limits
85: 
86: ### Per-App Memory Constraints
87: 
88: | Device Type | Typical Limit | Notes |
89: |-------------|---------------|-------|
90: | iPad (base) | ~3-4 GB | iPad 9th/10th gen |
91: | iPad Air | ~5-6 GB | M1/M2 iPad Air |
92: | iPad Pro (M2) | ~8-12 GB | Depends on total RAM |
93: | iPad Pro (M4) | ~12-16 GB | 16GB models |
94: 
95: **Important:** These are *total app memory*, not JSC-specific.
96: 
97: ### JSC-Specific Memory Behavior
98: 
99: ```swift
100: // Configure memory limits via JSContext
101: let context = JSContext()
102: 
103: // JSC uses garbage collection - no explicit heap limit setting
104: // Memory pressure handled by system
105: 
106: // Monitor memory usage
107: context.exceptionHandler = { context, exception in
108:     print("JS Exception: \(exception?.toString() ?? "unknown")")
109: }
110: ```
111: 
112: ### Memory Warnings
113: 
114: ```swift
115: // Handle memory pressure notifications
116: NotificationCenter.default.addObserver(
117:     forName: UIApplication.didReceiveMemoryWarningNotification,
118:     object: nil,
119:     queue: .main
120: ) { _ in
121:     // Clear JS caches, release unused contexts
122:     context.globalObject.deleteProperty("cachedData")
123: }
124: ```
125: 
126: ### Practical Limits for JSC
127: 
128: | Scenario | Recommended Max | Notes |
129: |----------|-----------------|-------|
130: | Large arrays/objects | ~100-500MB | Before performance degradation |
131: | Concurrent contexts | 2-4 | Each VM adds overhead |
132: | String processing | No hard limit | Subject to app memory |
133: 
134: ---
135: 
136: ## 3. Execution Time Limits
137: 
138: ### Watchdog and Timeout Behavior
139: 
140: **No Built-in Execution Timeout in JSC API**
141: 
142: Unlike `WKWebView`, `JSContext` has **no automatic watchdog timer**. However, practical limits exist:
143: 
144: | Limit Type | Behavior | Mitigation |
145: |------------|----------|------------|
146: | Main thread blocking | App killed after ~10-20s | Use background threads |
147: | Background execution | ~30s typical | Use `beginBackgroundTask` |
148: | Infinite loops | Hangs until memory/CPU pressure | Manual interruption needed |
149: 
150: ### Manual Timeout Implementation
151: 
152: ```swift
153: import JavaScriptCore
154: import Dispatch
155: 
156: class JSTimeoutContext {
157:     private var context: JSContext?
158:     private var timeoutWorkItem: DispatchWorkItem?
159:     
160:     func evaluateWithTimeout(script: String, timeout: TimeInterval) -> JSValue? {
161:         context = JSContext()
162:         
163:         // Set up timeout
164:         let semaphore = DispatchSemaphore(value: 0)
165:         var result: JSValue?
166:         
167:         timeoutWorkItem = DispatchWorkItem { [weak self] in
168:             // Force context invalidation on timeout
169:             self?.context?.exception = JSValue(
170:                 newErrorFromMessage: "Execution timeout",
171:                 in: self?.context
172:             )
173:             semaphore.signal()
174:         }
175:         
176:         DispatchQueue.global().async {
177:             result = self.context?.evaluateScript(script)
178:             semaphore.signal()
179:         }
180:         
181:         DispatchQueue.global().asyncAfter(deadline: .now() + timeout, execute: timeoutWorkItem!)
182:         
183:         semaphore.wait()
184:         return result
185:     }
186: }
187: ```
188: 
189: ### Background Execution Strategy
190: 
191: ```swift
192: func executeLongRunningJS() {
193:     let backgroundTask = UIApplication.shared.beginBackgroundTask {
194:         // Cleanup if needed
195:     }
196:     
197:     DispatchQueue.global(qos: .userInitiated).async {
198:         let context = JSContext()
199:         let result = context?.evaluateScript(longRunningScript)
200:         

---

[read_file]
File: VSCodeiPadOS/VSCodeiPadOS/Docs/SecurityAudit.md (lines 2-120 of 508)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2: 
3: > **Audit Date:** February 2025  
4: > **Platform:** iOS/iPadOS 17.x+  
5: > **Scope:** JavaScriptCore, WebAssembly, and embedded interpreter security
6: 
7: ---
8: 
9: ## Executive Summary
10: 
11: This security audit covers the security implications of executing user-provided code on iPadOS devices within a VS Code-like environment. The analysis evaluates risks associated with JavaScriptCore, WebAssembly, and potential Python execution, along with recommended mitigation strategies.
12: 
13: **Risk Level:** MEDIUM-HIGH  
14: **Primary Concerns:** Resource exhaustion, information disclosure, sandbox escape attempts  
15: **Recommendation:** Implement strict resource limits and hybrid execution model
16: 
17: ---
18: 
19: ## 1. iOS Sandbox Overview
20: 
21: ### Seatbelt Profile
22: 
23: iOS uses the Seatbelt mandatory access control framework with app-specific profiles:
24: 
25: ```
26: App Container Structure:
27: ‚îú‚îÄ‚îÄ Documents/          ‚Üê User data, read/write
28: ‚îú‚îÄ‚îÄ Library/            ‚Üê App settings, caches
29: ‚îÇ   ‚îú‚îÄ‚îÄ Caches/
30: ‚îÇ   ‚îú‚îÄ‚îÄ Preferences/
31: ‚îÇ   ‚îî‚îÄ‚îÄ Application Support/
32: ‚îú‚îÄ‚îÄ tmp/                ‚Üê Temporary files (cleaned periodically)
33: ‚îî‚îÄ‚îÄ .app/               ‚Üê Bundle resources (read-only)
34: ```
35: 
36: ### Sandbox Restrictions
37: 
38: | Resource | Access Level | Notes |
39: |----------|--------------|-------|
40: | App Container | ‚úÖ Full | Within own container only |
41: | System Files | ‚ùå Denied | Cannot access /etc, /System, etc. |
42: | Other Apps | ‚ùå Denied | No inter-app file access (except via APIs) |
43: | Keychain | ‚ö†Ô∏è Limited | App-specific keychain items only |
44: | Network | ‚ö†Ô∏è Controlled | ATS (App Transport Security) enforced |
45: | Camera/Mic | ‚ö†Ô∏è Permission | Requires user authorization |
46: | Photos | ‚ö†Ô∏è Permission | PHPhotoLibrary API required |
47: | Location | ‚ö†Ô∏è Permission | Core Location with authorization |
48: 
49: ---
50: 
51: ## 2. File System Security
52: 
53: ### 2.1 App Container Isolation
54: 
55: ```swift
56: // Secure file access within app container
57: let documentsPath = FileManager.default.urls(
58:     for: .documentDirectory, 
59:     in: .userDomainMask
60: ).first!
61: 
62: // ALLOWED: Access within container
63: let userFile = documentsPath.appendingPathComponent("user-script.js")
64: 
65: // BLOCKED by sandbox: System file access
66: let systemFile = URL(fileURLWithPath: "/etc/passwd") // ‚ùå Access denied
67: ```
68: 
69: ### 2.2 File System Attack Vectors
70: 
71: | Attack | Risk | Mitigation |
72: |--------|------|------------|
73: | Path Traversal | HIGH | Validate all paths, reject `../` |
74: | Symlink Escape | MEDIUM | Check `URL.resolvingSymlinksInPath()` |
75: | Hard Links | LOW | Use `stat` to verify file identity |
76: | Resource Forks | LOW | Avoid extended attributes |
77: | Temporary File Exhaustion | MEDIUM | Limit temp file size/count |
78: 
79: ### 2.3 Secure File Handling
80: 
81: ```swift
82: /// Validates that a path is within the app container
83: func validateSandboxPath(_ url: URL) throws -> URL {
84:     let containerURL = FileManager.default.urls(
85:         for: .documentDirectory, 
86:         in: .userDomainMask
87:     ).first!.deletingLastPathComponent()
88:     
89:     let resolvedPath = url.resolvingSymlinksInPath()
90:     
91:     // Ensure path starts with container
92:     guard resolvedPath.path.hasPrefix(containerURL.path) else {
93:         throw SecurityError.pathEscapeAttempt
94:     }
95:     
96:     // Reject parent directory traversal
97:     guard !url.path.contains("..") else {
98:         throw SecurityError.pathTraversalAttempt
99:     }
100:     
101:     return resolvedPath
102: }
103: ```
104: 
105: ---
106: 
107: ## 3. Network Security
108: 
109: ### 3.1 App Transport Security (ATS)
110: 
111: ATS enforces secure network connections by default:
112: 
113: ```xml
114: <!-- Required Info.plist configuration -->
115: <key>NSAppTransportSecurity</key>
116: <dict>
117:     <!-- Default: Only HTTPS with TLS 1.2+ -->
118:     <key>NSAllowsArbitraryLoads</key>
119:     <false/>
120:     

---

[read_file]
File: VSCodeiPadOS/VSCodeiPadOS/Docs/SSH_SETUP.md (lines 2-120 of 183)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2: 
3: ## Overview
4: 
5: The terminal now uses **SwiftNIO SSH** (apple/swift-nio-ssh) for real SSH connections.
6: This is a pure Swift implementation that works on iOS without any C dependencies.
7: 
8: ## Adding SwiftNIO SSH Dependency
9: 
10: ### Method 1: Xcode Package Manager (Recommended)
11: 
12: 1. Open `VSCodeiPadOS.xcodeproj` in Xcode
13: 2. Go to **File ‚Üí Add Package Dependencies...**
14: 3. Enter the URL: `https://github.com/apple/swift-nio-ssh`
15: 4. Select version **0.8.0** or later
16: 5. Choose to add **NIOSSH** product to the VSCodeiPadOS target
17: 6. Xcode will automatically resolve and add:
18:    - swift-nio-ssh
19:    - swift-nio
20:    - swift-crypto
21: 
22: ### Method 2: Manual Package.swift
23: 
24: A `Package.swift` file is provided at the project root for reference.
25: You can use Swift Package Manager from command line:
26: 
27: ```bash
28: cd VSCodeiPadOS
29: swift package resolve
30: ```
31: 
32: ## Files Added
33: 
34: ### Services/SSHManager.swift
35: 
36: Main SSH connection manager using SwiftNIO SSH:
37: 
38: ```swift
39: // Usage example
40: let sshManager = SSHManager()
41: sshManager.delegate = self
42: 
43: let config = SSHConnectionConfig(
44:     name: "My Server",
45:     host: "example.com",
46:     port: 22,
47:     username: "user",
48:     authMethod: .password("secret")
49: )
50: 
51: sshManager.connect(config: config) { result in
52:     switch result {
53:     case .success:
54:         print("Connected!")
55:     case .failure(let error):
56:         print("Failed: \(error)")
57:     }
58: }
59: 
60: // Send commands
61: sshManager.send(command: "ls -la")
62: 
63: // Send control characters
64: sshManager.sendInterrupt() // Ctrl+C
65: sshManager.sendTab()       // Tab completion
66: sshManager.sendEscape()    // ESC key
67: ```
68: 
69: ### Services/SFTPManager.swift
70: 
71: Basic SFTP operations (uses shell commands as SwiftNIO SSH doesn't include SFTP subsystem):
72: 
73: ```swift
74: let sftp = SFTPManager()
75: sftp.connect(config: config) { result in
76:     // Directory operations via shell commands
77:     sftp.createDirectory(remotePath: "~/newdir") { _ in }
78:     sftp.delete(remotePath: "~/oldfile") { _ in }
79: }
80: ```
81: 
82: ## Features
83: 
84: ### Authentication Methods
85: 
86: 1. **Password Authentication**
87:    ```swift
88:    .password("your-password")
89:    ```
90: 
91: 2. **SSH Key Authentication**
92:    ```swift
93:    .privateKey(key: pemString, passphrase: nil)
94:    ```
95: 
96: ### Terminal Features
97: 
98: - Real SSH protocol (not raw TCP)
99: - PTY allocation for interactive shells
100: - Terminal resize support
101: - ANSI escape sequence handling
102: - Command history
103: - Connection persistence (saved connections)
104: 
105: ### Saved Connections
106: 
107: Connections are stored in UserDefaults and persist across app launches:
108: 
109: ```swift
110: // Access saved connections
111: let store = SSHConnectionStore.shared
112: let connections = store.savedConnections
113: 
114: // Save a new connection
115: store.save(config)
116: 
117: // Delete a connection
118: store.delete(config)
119: ```
120: 


>>>TOOL web_search
{"query":"OpenAI API pricing GPT-4o o1 o3 GPT-4.5 context window endpoint api.openai.com/v1 responses","max_results":5}
>>>END
>>>TOOL web_search
{"query":"Anthropic API pricing Claude 3.5 Claude 3.7 Claude 4 context window endpoint api.anthropic.com/v1/messages","max_results":5}
>>>END
>>>TOOL web_search
{"query":"Google Gemini API pricing Gemini 2.0 2.5 context window endpoint generativelanguage.googleapis.com","max_results":5}
>>>END
>>>TOOL web_search
{"query":"Moonshot AI Kimi API pricing K2 K2.5 context length endpoint","max_results":5}
>>>END
>>>END>>>TOOL web_search
{"query":"OpenAI API pricing GPT-4o o1 o3 GPT-4.5 context window endpoint api.openai.com/v1 responses","max_results":5}
>>>END

>>>TOOL web_search
{"query":"Anthropic API pricing Claude 3.5 Claude 3.7 Claude 4 context window endpoint api.anthropic.com/v1/messages","max_results":5}
>>>END

>>>TOOL web_search
{"query":"Google Gemini API pricing Gemini 2.0 2.5 context window endpoint generativelanguage.googleapis.com","max_results":5}
>>>END

>>>TOOL web_search
{"query":"Moonshot AI Kimi API pricing K2 K2.5 context length endpoint","max_results":5}
>>>END

---

## üîß TOOL RESULTS

[web_search]
üîç DuckDuckGo results for "OpenAI API pricing GPT-4o o1 o3 GPT-4.5 context window endpoint api.openai.com/v1 responses" (5 results):

1. **API Pricing - OpenAI**
   https://openai.com/api/pricing/
   Text models price image tokens at standard text token rates, while GPT Image and gpt-realtime uses a separate image token rate. Models like gpt-4.1-mini, gpt-4.1-nano, and o4-mini convert images into tokens differently.

2. **OpenAI API Pricing Calculator | GPT-5.2 pro, GPT-5.2, GPT-5.1 &amp; GPT-5**
   https://invertedstone.com/calculators/openai-pricing
   OpenAI&#x27;s model pricing is subject to change. While we maintain current rates for all models including GPT-5.2 pro, GPT-5.2, GPT-5.1, GPT-5 family, O1, O3-mini, and GPT-4o in our calculator, always verify the latest pricing on OpenAI&#x27;s official website.

3. **OpenAI gpt-4o Pricing Calculator | API Cost Estimation**
   https://www.helicone.ai/llm-cost/provider/OPENAI/model/gpt-4o
   Explore AI costs with our comprehensive OpenAI gpt-4o Pricing Calculator. Compare prices for 300+ models across 10+ providers, get accurate API pricing, token costs, and budget estimations.

4. **OpenAI API Cost Calculator - Estimate GPT Model Pricing | CalcAI**
   https://calcai.io/openai-api-cost/
   Estimate your OpenAI API costs for GPT-4o, GPT-4o Mini, GPT-3.5 Turbo, and more. Use this free calculator to forecast per-request and total billing before making API calls.

5. **gpt-4o-vs-o1-openai-model-comparison-guide - galileo.ai**
   https://galileo.ai/blog/gpt-4o-vs-o1-openai-model-comparison-guide
   Compare GPT-4o vs O1: speed, cost analysis, reasoning capabilities. Get frameworks to choose the right OpenAI model for your AI project needs.

---

[web_search]
üîç DuckDuckGo results for "Anthropic API pricing Claude 3.5 Claude 3.7 Claude 4 context window endpoint api.anthropic.com/v1/messages" (5 results):

1. **Pricing - Claude API Docs**
   https://platform.claude.com/docs/en/about-claude/pricing
   The Claude API is global-only (equivalent to the global endpoint offering and pricing from other providers). Scope: This pricing structure applies to Claude Sonnet 4.5, Haiku 4.5, and all future models.

2. **Plans &amp; Pricing | Claude by Anthropic**
   https://claude.com/pricing
   Choose the Claude plan that fits how you solve problems. Free, Pro, Max, Team, and Enterprise tiers, plus API pricing for developers.

3. **Claude Pricing Explained: Subscription Plans &amp; API Costs**
   https://intuitionlabs.ai/articles/claude-pricing-plans-api-costs
   A complete guide to Anthropic Claude pricing. Learn about subscription plans (Pro, Max, Team) and per-token API costs for models like Opus 4.5 and Sonnet.

4. **Claude Developer Platform | Claude - Anthropic**
   https://claude.com/platform/api
   Use our API to create new user experiences, products, and ways to work with the most advanced AI models on the market.

5. **Anthropic Claude API Pricing 2026: Complete Cost Breakdown | MetaCTO**
   https://www.metacto.com/blogs/anthropic-api-pricing-a-full-breakdown-of-costs-and-integration
   Combined with prompt caching (90% savings on repeated context), batch API (50% discount), and extended thinking capabilities, Claude 4.5 represents the most cost-effective frontier AI available today. ... Check out our guides on OpenAI API pricing, Cohere pricing, and Hugging Face costs.

---

[web_search]
üîç DuckDuckGo results for "Google Gemini API pricing Gemini 2.0 2.5 context window endpoint generativelanguage.googleapis.com" (5 results):

1. **Gemini Developer API pricing - Google AI for Developers**
   https://ai.google.dev/gemini-api/docs/pricing
   Gemini Developer API pricing On this page Gemini 3 Pro Preview Gemini 3 Flash Preview Gemini 3 Pro Image Preview üçå Gemini 2.5 Pro Gemini 2.5 Flash

2. **Gemini API Pricing Calculator &amp; Cost Guide (Feb 2026)**
   https://costgoat.com/pricing/gemini-api
   Calculate Gemini API costs instantly. Compare Pro, Flash, and Flash-Lite pricing per token with free tiers, batch API, and context caching discounts.

3. **Google Gemini API Pricing 2026: Complete Cost Guide per 1M Tokens**
   https://www.metacto.com/blogs/the-true-cost-of-google-gemini-a-guide-to-api-pricing-and-integration
   Google Gemini pricing: $1.25-$15/1M tokens for Pro, $0.075-$0.60 for Flash. Complete 2026 pricing tables for all models (2.5 Pro, Flash, Flash-Lite, TTS, Imagen, Veo) plus integration costs and MDM challenges.

4. **Google Gemini Cost (2026 Complete Pricing Guide)**
   https://www.ofzenandcomputing.com/google-gemini-cost/
   Discover Google Gemini pricing from free tier to enterprise. Compare all plans, API costs, and learn how to save up to 50% on usage. Updated for 2026.

5. **Pricing - Google Gemini API**
   https://gemini-api.apidog.io/doc-965864
   The Gemini API &quot;free tier&quot; is offered through the API service with lower rate limits for testing purposes. Google AI Studio usage is completely free in all available countries. The Gemini API &quot;paid tier&quot; comes with higher rate limits, additional features, and different data handling. Upgrade to the Paid Tier Gemini 2.5 Flash Preview # Try it in Google AI Studio Our first hybrid reasoning model ...

---

[web_search]
üîç DuckDuckGo results for "Moonshot AI Kimi API pricing K2 K2.5 context length endpoint" (5 results):

1. **Model Inference Pricing Explanation - Moonshot AI Open Platform - Kimi ...**
   https://platform.moonshot.ai/docs/pricing/chat
   Kimi Open Platform, providing trillion-parameter K2 large language model API, supporting 256K long context and Tool Calling. Professional code generation, intelligent dialogue, helping developers build AI applications.

2. **Kimi K2 API Pricing: Full Cost Breakdown + Calculator**
   https://agentsapis.com/kimi-api/k2-pricing/
   Updated Kimi K2 API pricing guide: token rates, caching discounts, Turbo pricing, web-search tool fees, and monthly cost estimates.

3. **Kimi K2.5 - Pricing, Context Window Size, and Benchmark Data**
   https://automatio.ai/models/kimi-k2-5
   Discover Moonshot AI&#x27;s Kimi K2.5, a 1T-parameter open-source agentic model featuring native multimodal capabilities, a 262K context window, and SOTA reasoning.

4. **Kimi API Pricing Calculator &amp; Cost Guide (Feb 2026)**
   https://costgoat.com/pricing/kimi-api
   Kimi API provides access to Moonshot AI&#x27;s large language models, including the flagship Kimi K2.5 - a native multimodal model with vision, thinking modes, and agentic capabilities. Built on the 1 trillion parameter Mixture-of-Experts architecture, K2.5 achieves open-source SOTA performance while maintaining competitive pricing. The API is fully compatible with OpenAI&#x27;s SDK. Native Multimodal ...

5. **Kimi API - Kimi K2.5 API**
   https://kimik2ai.com/api/
   Kimi is developed by Moonshot AI and offered through their Open Platform. The Open Platform provides an OpenAI-compatible base URL for API calls (plus region-specific alternatives), a model list endpoint, file endpoints, and documentation for tool calling and rate limiting.


>>>TOOL web_fetch
{"url":"https://openai.com/api/pricing/","max_length":12000}
>>>END
>>>TOOL web_search
{"query":"OpenAI Responses API endpoint https://api.openai.com/v1/responses documentation","max_results":5}
>>>END
>>>TOOL web_search
{"query":"OpenAI model context window gpt-4o o1 o3 gpt-4.5 API docs","max_results":5}
>>>END
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
Error: https://openai.com/api/pricing/ returned 403

---

[web_search]
üîç DuckDuckGo results for "OpenAI Responses API endpoint https://api.openai.com/v1/responses documentation" (5 results):

1. **Responses | OpenAI API Reference**
   https://platform.openai.com/docs/api-reference/responses
   Responses OpenAI&#x27;s most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model&#x27;s capabilities with built-in tools for file search, web search, computer use, and more.

2. **Azure OpenAI Responses API - Azure OpenAI | Microsoft Learn**
   https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses?view=foundry-classic
   The Responses API is a new stateful API from Azure OpenAI. It brings together the best capabilities from the chat completions and assistants API in one unified experience. The Responses API also adds support for the new computer-use-preview model which powers the Computer use capability.

3. **Responses API Reference | openai/completions-responses-migration-pack ...**
   https://deepwiki.com/openai/completions-responses-migration-pack/6-responses-api-reference
   Responses API Reference Relevant source files This document provides comprehensive reference documentation for the OpenAI /v1/responses API endpoint, covering all parameters, content types, streaming capabilities, tools integration, and structured output formats.

4. **Migrate to the Responses API | OpenAI API**
   https://platform.openai.com/docs/guides/migrate-to-responses
   The Responses API is a unified interface for building powerful, agent-like applications. It contains: Built-in tools like web search, file search , computer use, code interpreter, and remote MCPs. Seamless multi-turn interactions that allow you to pass previous responses for higher accuracy reasoning results. Native multimodal support for text and images.

5. **OpenAI Responses API: A Comprehensive Guide - Medium**
   https://medium.com/@odhitom09/openai-responses-api-a-comprehensive-guide-ad546132b2ed
   This is an OpenAI Responses API guide! This series will walk you through the essential features and functionalities of the new OpenAI Responses API that was just released The Responses API is a ...

---

[web_search]
üîç DuckDuckGo results for "OpenAI model context window gpt-4o o1 o3 gpt-4.5 API docs" (5 results):

1. **GPT-4o Model | OpenAI API**
   https://platform.openai.com/docs/models/gpt-4o
   GPT-4o (&quot;o&quot; for &quot;omni&quot;) is our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.

2. **The State of OpenAI&#x27;s GPT Models - Spring 2025**
   https://blog.risingstack.com/state-of-openai-gpt-models/
   What&#x27;s Currently Available in ChatGPT To sum up, here&#x27;s the list of models available in ChatGPT today: GPT-4o - the default for most users; multimodal (text, image, audio) GPT-4.5 - research preview, good for creative work and idea exploration GPT-4o with scheduled tasks - lets you set follow-up actions o3 - advanced reasoning o4-mini - fast, general-purpose model o4-mini-high ...

3. **o1 vs GPT-4o - Detailed Performance &amp; Feature Comparison**
   https://docsbot.ai/models/compare/o1/gpt-4o
   The latest GPT-4o model, provided by OpenAI, features a context window of 128K tokens and supports generating up to 16.4K tokens per request. It was released on August 6, 2024, with a knowledge cut-off as of October 2023. The model is available via OpenAI&#x27;s API, and it can empirically generate 77.4 tokens per second. Input costs $2.50 per million tokens and output costs $10 per million tokens.

4. **OpenAI Retires GPT-4o: The End of an Era (And Why You Won&#x27;t Miss It)**
   https://ai505.com/openai-retires-gpt-4o-the-end-of-an-era-and-why-you-won-t-miss-it/
   OpenAI officially retires GPT-4o on February 13, 2026. Here&#x27;s why the transition to GPT-5.2 marks a turning point for AI and what it means for you.

5. **Azure OpenAI reasoning models - GPT-5 series, o3-mini, o1, o1-mini ...**
   https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/reasoning?view=foundry-classic
   Azure OpenAI reasoning models are designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user&#x27;s request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations. Key capabilities of reasoning models: Complex Code Generation: Capable of generating ...


>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/api-reference/responses","max_length":12000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/models/gpt-4o","max_length":12000}
>>>END
>>>TOOL web_search
{"query":"site:platform.openai.com pricing gpt-4o input output per 1M tokens","max_results":5}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.claude.com/docs/en/about-claude/pricing","max_length":12000}
>>>END
>>>TOOL web_fetch
{"url":"https://ai.google.dev/gemini-api/docs/pricing","max_length":12000}
>>>END
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
Error: https://platform.openai.com/docs/api-reference/responses returned 403

---

[web_fetch]
üåê https://platform.openai.com/docs/models/gpt-4o

‚Ä¢ GPT-4o Model | OpenAI API
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
DocsDocsAPI referenceAPILog inSign up

SearchGet startedOverviewQuickstartModelsPricingLibrariesDocs MCPLatest: GPT-5.2Core conceptsText generationCode generationImages and visionAudio and speechStructured outputFunction callingResponses APIAgentsOverviewBuild agents

Deploy in your product

Optimize

Voice agentsToolsUsing toolsConnectors and MCPWeb searchCode interpreterFile search and retrieval

More tools

Run and scaleConversation stateBackground modeStreamingWebhooksFile inputsPrompting

Reasoning

EvaluationGetting startedWorking with evalsPrompt optimizerExternal modelsBest practicesRealtime APIOverviewConnect

Usage

Model optimizationOptimization cycleFine-tuning

GradersSpecialized modelsImage generationVideo generationText to speechSpeech to textDeep researchEmbeddingsModerationCoding agentsCodex cloud
Agent internet access
Codex CLI
Codex IDE
Codex changelog
Going liveProduction best practicesLatency optimization

Cost optimization

Accuracy optimizationSafety

Legacy APIsAssistants API

ResourcesTerms and policies
ChangelogYour dataPermissionsRate limitsDeprecationsMCP for deep researchDeveloper modeChatGPT Actions

ModelsGPT-4oDefault

Fast, intelligent, flexible GPT modelFast, intelligent, flexible GPT modelCompareTry in PlaygroundIntelligence

HighSpeed

MediumPrice$2.5‚Ä¢$10Input‚Ä¢OutputInput

Text, imageOutput

TextPrompt exampleMath TutorPrompt exampleTravel AssistantPrompt exampleClothing RecommendationPrompt exampleRecipe Generation
GPT-4o (‚Äúo‚Äù for ‚Äúomni‚Äù) is our versatile, high-intelligence flagship model.
It accepts both text and image inputs, and produces text outputs (including Structured Outputs).
It is the best model for most tasks, and is our most capable model outside of our o-series models.
128,000 context window
16,384 max output tokens
Oct 01, 2023 knowledge cutoffPricingPricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there‚Äôs a fee per tool call. See details in the [pricing page](/docs/pricing).Text tokensPer 1M tokens‚àôBatch API priceInput$2.50Cached input$1.25Output$10.00Quick comparisonInputCached inputOutputGPT-4o$2.50o3-mini$1.10GPT-4o mini$0.15Modalities

TextInput and output
ImageInput only

AudioNot supported

VideoNot supportedEndpoints

Chat Completionsv1/chat/completions

Responsesv1/responses

Realtimev1/realtime

Assistantsv1/assistants

Batchv1/batch
Fine-tuningv1/fine-tuning

Embeddingsv1/embeddings

Image generationv1/images/generations

Videosv1/videos

Image editv1/images/edits

Speech generationv1/audio/speech

Transcriptionv1/audio/transcriptions

Translationv1/audio/translations

Moderationv1/moderations

Completions (legacy)v1/completionsFeatures
StreamingSupported

Function callingSupported
Structured outputsSupported
Fine-tuningSupported
DistillationSupported
Predicted outputsSupportedSnapshotsSnapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for GPT-4o.gpt-4o
gpt-4o-2024-08-06gpt-4o-2024-11-20gpt-4o-2024-08-06gpt-4o-2024-05-13Rate limitsRate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.TierRPMTPMBatch queue limitFreeNot supportedTier 150030,00090,000Tier 25,000450,0001,350,000Tier 35,000800,00050,000,000Tier 410,0002,000,000200,000,000Tier 510,00030,000,0005,000,000,000

---

[web_search]
üîç DuckDuckGo results for "site:platform.openai.com pricing gpt-4o input output per 1M tokens" (5 results):

1. **Pricing - OpenAI API**
   https://platform.openai.com/docs/pricing
   These are billed at the model&#x27;s input token rate, unless otherwise specified. [1] For gpt-4o-mini and gpt-4.1-mini with the web search non-preview tool, search content tokens are charged as a fixed block of 8,000 input tokens per call.

2. **Compare models | OpenAI API**
   https://platform.openai.com/docs/models/compare?model=gpt-4o
   Compare models GPT-4o Fast, intelligent, flexible GPT model Learn more Playground Intelligence

3. **GPT-4o Model | OpenAI API**
   https://platform.openai.com/docs/models/gpt-4o?ref=getdeploying
   Pricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there&#x27;s a fee per tool call. See details in the pricing page.

4. **Compare models | OpenAI API**
   https://platform.openai.com/docs/models/compare?model=gpt-4o-mini
   Compare models GPT-4o mini Fast, affordable small model for focused tasks Learn more Playground Intelligence

5. **Compare models | OpenAI API**
   https://platform.openai.com/docs/models/compare?model=chatgpt-4o-latest
   Compare models ChatGPT-4o GPT-4o model used in ChatGPT Learn more Playground Intelligence Speed

---

[web_fetch]
üåê https://platform.claude.com/docs/en/about-claude/pricing

‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ Pricing - Claude API Docs
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ Cookie settings
We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).CustomizeCustomize Cookie SettingsRejectReject All CookiesAcceptAccept All CookiesLoading...

‚Ä¢ [Developer Guide](/docs/en/intro)
‚Ä¢ [API Reference](/docs/en/api/overview)
‚Ä¢ MCP

‚Ä¢ [Resources](/docs/en/resources/overview)
‚Ä¢ [Release Notes](/docs/en/release-notes/overview)English
Log in

Search...‚åòKFirst stepsIntro to ClaudeQuickstartModels & pricingModels overviewChoosing a modelWhat&#x27;s new in Claude 4.6Migration guideModel deprecationsPricingBuild with ClaudeFeatures overviewUsing the Messages APIHandling stop reasonsPrompting best practicesContext managementContext windowsCompactionContext editingCapabilitiesPrompt cachingExtended thinkingAdaptive thinkingEffortFast mode (research preview)Streaming MessagesBatch processingCitationsMultilingual supportToken countingEmbeddingsVisionPDF supportFiles APISearch resultsStructured outputsToolsOverviewHow to implement tool useFine-grained tool streamingBash toolCode execution toolProgrammatic tool callingComputer use toolText editor toolWeb fetch toolWeb search toolMemory toolTool search toolAgent SkillsOverviewQuickstartBest practicesSkills for enterpriseUsing Skills with the APIAgent SDKOverviewQuickstartTypeScript SDKTypeScript V2 (preview)Python SDKMigration GuideGuides
MCP in the APIMCP connectorRemote MCP serversClaude on 3rd-party platformsAmazon BedrockMicrosoft FoundryVertex AIPrompt engineeringOverviewPrompt generatorUse prompt templatesPrompt improverBe clear and directUse examples (multishot prompting)Let Claude think (CoT)Use XML tagsGive Claude a role (system prompts)Chain complex promptsLong context tipsExtended thinking tipsTest & evaluateDefine success criteriaDevelop test casesUsing the Evaluation ToolReducing latencyStrengthen guardrailsReduce hallucinationsIncrease output consistencyMitigate jailbreaksStreaming refusalsReduce prompt leakKeep Claude in characterAdministration and monitoringAdmin API overviewData residencyWorkspacesUsage and Cost APIClaude Code Analytics APIZero Data Retention

Console
Log in
Models & pricing
PricingLoading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...Loading...

Solutions
‚Ä¢ [AI agents](https://claude.com/solutions/agents)
‚Ä¢ [Code modernization](https://claude.com/solutions/code-modernization)
‚Ä¢ [Coding](https://claude.com/solutions/coding)
‚Ä¢ [Customer support](https://claude.com/solutions/customer-support)
‚Ä¢ [Education](https://claude.com/solutions/education)
‚Ä¢ [Financial services](https://claude.com/solutions/financial-services)
‚Ä¢ [Government](https://claude.com/solutions/government)
‚Ä¢ [Life sciences](https://claude.com/solutions/life-sciences)Partners
‚Ä¢ [Amazon Bedrock](https://claude.com/partners/amazon-bedrock)
‚Ä¢ [Google Cloud&#x27;s Vertex AI](https://claude.com/partners/google-cloud-vertex-ai)Learn
‚Ä¢ [Blog](https://claude.com/blog)
‚Ä¢ [Catalog](https://claude.ai/catalog/artifacts)
‚Ä¢ [Courses](https://www.anthropic.com/learn)
‚Ä¢ [Use cases](https://claude.com/resources/use-cases)
‚Ä¢ [Connectors](https://claude.com/partners/mcp)
‚Ä¢ [Customer stories](https://claude.com/customers)
‚Ä¢ [Engineering at Anthropic](https://www.anthropic.com/engineering)
‚Ä¢ [Events](https://www.anthropic.com/events)
‚Ä¢ [Powered by Claude](https://claude.com/partners/powered-by-claude)
‚Ä¢ [Service partners](https://claude.com/partners/services)
‚Ä¢ [Startups program](https://claude.com/programs/startups)Company
‚Ä¢ [Anthropic](https://www.anthropic.com/company)
‚Ä¢ [Careers](https://www.anthropic.com/careers)
‚Ä¢ [Economic Futures](https://www.anthropic.com/economic-futures)
‚Ä¢ [Research](https://www.anthropic.com/research)
‚Ä¢ [News](https://www.anthropic.com/news)
‚Ä¢ [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)
‚Ä¢ [Security and compliance](https://trust.anthropic.com)
‚Ä¢ [Transparency](https://www.anthropic.com/transparency)Learn
‚Ä¢ [Blog](https://claude.com/blog)
‚Ä¢ [Catalog](https://claude.ai/catalog/artifacts)
‚Ä¢ [Courses](https://www.anthropic.com/learn)
‚Ä¢ [Use cases](https://claude.com/resources/use-cases)
‚Ä¢ [Connectors](https://claude.com/partners/mcp)
‚Ä¢ [Customer stories](https://claude.com/customers)
‚Ä¢ [Engineering at Anthropic](https://www.anthropic.com/engineering)
‚Ä¢ [Events](https://www.anthropic.com/events)
‚Ä¢ [Powered by Claude](https://claude.com/partners/powered-by-claude)
‚Ä¢ [Service partners](https://claude.com/partners/services)
‚Ä¢ [Startups program](https://claude.com/programs/startups)Help and security
‚Ä¢ [Availability](https://www.anthropic.com/supported-countries)
‚Ä¢ [Status](https://status.claude.com/)
‚Ä¢ [Support](https://support.claude.com/)
‚Ä¢ [Discord](https://www.anthropic.com/discord)Terms and policies
‚Ä¢ [Privacy policy](https://www.anthropic.com/legal/privacy)
‚Ä¢ [Responsible disclosure policy](https://www.anthropic.com/responsible-disclosure-policy)
‚Ä¢ [Terms of service: Commercial](https://www.anthropic.com/legal/commercial-terms)
‚Ä¢ [Terms of service: Consumer](https://www.anthropic.com/legal/consumer-terms)
‚Ä¢ [Usage policy](https://www.anthropic.com/legal/aup)Models & pricing
# Pricing

Copy page
Learn about Anthropic&#x27;s pricing structure for models and features

Copy page

This page provides detailed pricing information for Anthropic&#x27;s models and features. All prices are in USD.

For the most current pricing information, please visit [claude.com/pricing](https://claude.com/pricing).

Model pricing

The following table shows pricing for all Claude models across different usage tiers:
ModelBase Input Tokens5m Cache Writes1h Cache WritesCache Hits & RefreshesOutput TokensClaude Opus 4.6$5 / MTok$6.25 / MTok$10 / MTok$0.50 / MTok$25 / MTokClaude Opus 4.5$5 / MTok$6.25 / MTok$10 / MTok$0.50 / MTok$25 / MTokClaude Opus 4.1$15 / MTok$18.75 / MTok$30 / MTok$1.50 / MTok$75 / MTokClaude Opus 4$15 / MTok$18.75 / MTok$30 / MTok$1.50 / MTok$75 / MTokClaude Sonnet 4.5$3 / MTok$3.75 / MTok$6 / MTok$0.30 / MTok$15 / MTokClaude Sonnet 4$3 / MTok$3.75 / MTok$6 / MTok$0.30 / MTok$15 / MTokClaude Sonnet 3.7 ([deprecated](/docs/en/about-claude/model-deprecations))$3 / MTok$3.75 / MTok$6 / MTok$0.30 / MTok$15 / MTokClaude Haiku 4.5$1 / MTok$1.25 / MTok$2 / MTok$0.10 / MTok$5 / MTokClaude Haiku 3.5$0.80 / MTok$1 / MTok$1.6 / MTok$0.08 / MTok$4 / MTokClaude Opus 3 ([deprecated](/docs/en/about-claude/model-deprecations))$15 / MTok$18.75 / MTok$30 / MTok$1.50 / MTok$75 / MTokClaude Haiku 3$0.25 / MTok$0.30 / MTok$0.50 / MTok$0.03 / MTok$1.25 / MTok

MTok = Million tokens. The &quot;Base Input Tokens&quot; column shows standard input pricing, &quot;Cache Writes&quot; and &quot;Cache Hits&quot; are specific to [prompt caching](/docs/en/build-with-claude/prompt-caching), and &quot;Output Tokens&quot; shows output pricing. Prompt caching offers both 5-minute (default) and 1-hour cache durations to optimize costs for different use cases.
The table above reflects the following pricing multipliers for prompt caching:

‚Ä¢ 5-minute cache write tokens are 1.25 times the base input tokens price

‚Ä¢ 1-hour cache write tokens are 2 times the base input tokens price

‚Ä¢ Cache read tokens are 0.1 times the base input tokens price

Third-party platform pricing

Claude models are available on [AWS Bedrock](/docs/en/build-with-claude/claude-on-amazon-bedrock), [Google Vertex AI](/docs/en/build-with-claude/claude-on-vertex-ai), and [Microsoft Foundry](/docs/en/build-with-claude/claude-in-microsoft-foundry). For official pricing, visit:

‚Ä¢ [AWS Bedrock pricing](https://aws.amazon.com/bedrock/pricing/)

‚Ä¢ [Google Vertex AI pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing)

‚Ä¢ [Microsoft Foundry pricing](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing)

Regional endpoint pricing for Claude 4.5 models and beyond
Starting with Claude Sonnet 4.5 and Haiku 4.5, AWS Bedrock and Google Vertex AI offer two endpoint types:

‚Ä¢ Global endpoints: Dynamic routing across regions for maximum availability

‚Ä¢ Regional endpoints: Data routing guaranteed within specific geographic regions

Regional endpoints include a 10% premium over global endpoints. The Claude API (1P) is global by default and unaffected by this change. The Claude API is global-only (equivalent to the global endpoint offering and pricing from other providers).
Scope: This pricing structure applies to Claude Sonnet 4.5, Haiku 4.5, and all future models. Earlier models (Claude Sonnet 4, Opus 4, and prior releases) retain their existing pricing.
For implementation details and code examples:

‚Ä¢ [AWS Bedrock global vs regional endpoints](/docs/en/build-with-claude/claude-on-amazon-bedrock#global-vs-regional-endpoints)

‚Ä¢ [Google Vertex AI global vs regional endpoints](/docs/en/build-with-claude/claude-on-vertex-ai#global-vs-regional-endpoints)

Feature-specific pricing

Data residency pricing

For Claude Opus 4.6 and newer models, specifying US-only inference via the inference_geo parameter incurs a 1.1x multiplier on all token pricing categories, including input tokens, output tokens, cache writes, and cache reads. Global routing (the default) uses standard pricing.

This applies to the Claude API (1P) only. Third-party platforms have their own regional pricing. See [AWS Bedrock](https://aws.amazon.com/bedrock/pricing/), [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/pricing), and [Microsoft Foundry](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing) for details. Earlier models retain their existing pricing regardless of inference_geo settings.

For more information, see the [data residency documentation](/docs/en/build-with-claude/data-residency).

Fast mode pricing

[Fast mode](/docs/en/build-with-claude/fast-mode) for Claude Opus 4.6 (resesarch preview) provides significantly faster output at premium pricing (6x standard rates). Currently supported on Opus 4.6:
Context windowInputOutput‚â§ 200K input tokens$30 / MTok$150 / MTok&gt; 200K input tokens$60 / MTok$225 / MTok

Fast mode pricing stacks with other pricing modifiers:

‚Ä¢ [Prompt caching multipliers](#model-pricing) apply on top of fast mode pricing

‚Ä¢ [Data residency](/docs/en/build-with-claude/data-residency) multipliers apply on top of fast mode pricing

Fast mode is not available with the [Batch API](#batch-processing).

For more information, see the [fast mode documentation](/docs/en/build-with-claude/fast-mode).

Batch processing

The Batch API allows asynchronous processing of large volumes of requests with a 50% discount on both input and output tokens.
ModelBatch inputBatch outputClaude Opus 4.6$2.50 / MTok$12.50 / MTokClaude Opus 4.5$2.50 / MTok$12.50 / MTokClaude Opus 4.1$7.50 / MTok$37.50 / MTokClaude Opus 4$7.50 / MTok$37.50 / MTokClaude Sonnet 4.5$1.50 / MTok$7.50 / MTokClaude Sonnet 4$1.50 / MTok$7.50 / MTokClaude Sonnet 3.7 ([deprecated](/docs/en/about-claude/model-deprecations))$1.50 / MTok$7.50 / MTokClaude Haiku 4.5$0.50 / MTok$2.50 / MTokClaude Haiku 3.5$0.40 / MTok$2 / MTokClaude Opus 3 ([deprecated](/docs/en/about-claude/model-deprecations))$7.50 / MTok$37.50 / MTokClaude Haiku 3$0.125 / MTok$0.625 / MTok

For more information about batch processing, see the [batch processing documentation](/docs/en/build-with-claude/batch-processing).

Long context pricing

When using Claude Opus 4.6, Sonnet 4.5, or Sonnet 4 with the [1M token context window enabled](/docs/en/build-with-claude/context-windows#1m-token-context-window), requests that exceed 200K input tokens are automatically charged at premium long context rates:

The 1M token context window is currently in beta for organizations in [usage tier](/docs/en/api/rate-limits) 4 and organiz

... [truncated]

---

[web_fetch]
üåê https://ai.google.dev/gemini-api/docs/pricing

‚Ä¢ 
    
‚Ä¢ 
    
‚Ä¢ 
    
‚Ä¢ 
    
‚Ä¢ 
    
‚Ä¢ 
‚Ä¢ 
      
‚Ä¢ 
‚Ä¢ 

‚Ä¢ 
      
‚Ä¢ 
    
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
      
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ 
‚Ä¢ Gemini Developer API ‰ª∑Ê†º  |  Gemini API  |  Google AI for Developers

‚Ä¢ 

‚Ä¢ 

    [
      
      Ë∑≥Ëá≥‰∏ªË¶ÅÂÜÖÂÆπ
    ](#main-content)

‚Ä¢ 

            /

‚Ä¢ 
      English

‚Ä¢ 
      Deutsch

‚Ä¢ 
      Espa√±ol ‚Äì Am√©rica Latina

‚Ä¢ 
      Fran√ßais

‚Ä¢ 
      Indonesia

‚Ä¢ 
      Italiano

‚Ä¢ 
      Polski

‚Ä¢ 
      Portugu√™s ‚Äì Brasil

‚Ä¢ 
      Shqip

‚Ä¢ 
      Ti√™ÃÅng Vi√™Ã£t

‚Ä¢ 
      T√ºrk√ße

‚Ä¢ 
      –†—É—Å—Å–∫–∏–π

‚Ä¢ 
      ◊¢◊ë◊®◊ô◊™

‚Ä¢ 
      ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©

‚Ä¢ 
      ŸÅÿßÿ±ÿ≥€å

‚Ä¢ 
      ‡§π‡§ø‡§Ç‡§¶‡•Ä

‚Ä¢ 
      ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ

‚Ä¢ 
      ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

‚Ä¢ 
      ‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì

‚Ä¢ 
      ‰∏≠Êñá ‚Äì ÁπÅÈ´î

‚Ä¢ 
      Êó•Êú¨Ë™û

‚Ä¢ 
      ÌïúÍµ≠Ïñ¥

            [
  Ëé∑Âèñ API ÂØÜÈí•
](https://aistudio.google.com/apikey?hl=zh-cn)
          
            [
  ÂÆûÊàòÂÆùÂÖ∏
](https://github.com/google-gemini/cookbook)
          
            [
  Á§æÂå∫
](https://discuss.ai.google.dev/c/gemini-api/?hl=zh-cn)

              ÁôªÂΩï

    [
    ÊñáÊ°£
  
    ](https://ai.google.dev/gemini-api/docs?hl=zh-cn)

    [
    API ÂèÇËÄÉ
  
    ](https://ai.google.dev/api?hl=zh-cn)

‚Ä¢ 

‚Ä¢ 

      Gemini API

‚Ä¢ 

      ÊñáÊ°£

‚Ä¢ 

      API ÂèÇËÄÉ

‚Ä¢ 

      Ëé∑Âèñ API ÂØÜÈí•

‚Ä¢ 

      ÂÆûÊàòÂÆùÂÖ∏

‚Ä¢ 

      Á§æÂå∫

‚Ä¢ 
        ÂºÄÂßã‰ΩøÁî®

‚Ä¢ Ê¶ÇËßà

‚Ä¢ Âø´ÈÄüÂÖ•Èó®

‚Ä¢ API ÂØÜÈí•

‚Ä¢ Â∫ì

‚Ä¢ Interactions API

‚Ä¢ 
        Ê®°Âûã

‚Ä¢ Gemini

‚Ä¢ Gemini 3

‚Ä¢ Nano Banana

‚Ä¢ Veo

‚Ä¢ Lyria

‚Ä¢ Imagen

‚Ä¢ Embeddings

‚Ä¢ Êú∫Âô®‰∫∫Â≠¶

‚Ä¢ ÊñáÂ≠óËΩ¨ËØ≠Èü≥

‚Ä¢ ‰ª∑Ê†º

‚Ä¢ ÈÄüÁéáÈôêÂà∂

‚Ä¢ 
        Ê†∏ÂøÉÂäüËÉΩ

‚Ä¢ ÊñáÊú¨

‚Ä¢ 
      
        ÂõæÁâá
      
‚Ä¢ ÂõæÁâáÁîüÊàê üçå
‚Ä¢ ÂõæÁâáÁêÜËß£

‚Ä¢ 
      
        ËßÜÈ¢ë
      
‚Ä¢ ËßÜÈ¢ëÁîüÊàê
‚Ä¢ ËßÜÈ¢ëÁêÜËß£

‚Ä¢ ÊñáÊ°£

‚Ä¢ 
      
        ËØ≠Èü≥ÂíåÈü≥È¢ë
      
‚Ä¢ ËØ≠Èü≥ÁîüÊàê
‚Ä¢ Èü≥È¢ëÁêÜËß£

‚Ä¢ 
      
        ÊÄùËÄÉÂûã
      
‚Ä¢ ÊÄùËÄÉÂûã
‚Ä¢ ÊÄùËÄÉÁ≠æÂêç

‚Ä¢ ÁªìÊûÑÂåñËæìÂá∫

‚Ä¢ ÂáΩÊï∞Ë∞ÉÁî®

‚Ä¢ Èïø‰∏ä‰∏ãÊñá

‚Ä¢ 
        Â∑•ÂÖ∑Âíå‰ª£ÁêÜ

‚Ä¢ Ê¶ÇËßà

‚Ä¢ Deep Research

‚Ä¢ Google Search

‚Ä¢ Google Maps

‚Ä¢ ‰ª£Á†ÅÊâßË°å

‚Ä¢ ÁΩëÂùÄ‰∏ä‰∏ãÊñá

‚Ä¢ ËÆ°ÁÆóÊú∫‰ΩøÁî®

‚Ä¢ Êñá‰ª∂ÊêúÁ¥¢

‚Ä¢ 
        Live API

‚Ä¢ ÂºÄÂßã‰ΩøÁî®

‚Ä¢ ÂäüËÉΩ

‚Ä¢ Â∑•ÂÖ∑‰ΩøÁî®

‚Ä¢ ‰ºöËØùÁÆ°ÁêÜ

‚Ä¢ ‰∏¥Êó∂‰ª§Áâå

‚Ä¢ 
        ÊåáÂçó

‚Ä¢ Batch API

‚Ä¢ 
      
        Êñá‰ª∂ËæìÂÖ•
      
‚Ä¢ ËæìÂÖ•Ê≥ï
‚Ä¢ Êñá‰ª∂ API

‚Ä¢ ‰∏ä‰∏ãÊñáÁºìÂ≠ò

‚Ä¢ OpenAI ÂÖºÂÆπÊÄß

‚Ä¢ Â™í‰ΩìÂàÜËæ®Áéá

‚Ä¢ ‰ª§ÁâåËÆ°Êï∞

‚Ä¢ ÊèêÁ§∫Â∑•Á®ã

‚Ä¢ 
      
        Êó•ÂøóÂíåÊï∞ÊçÆÈõÜ
      
‚Ä¢ Êó•Âøó‰ΩøÁî®ÂÖ•Èó®
‚Ä¢ Êï∞ÊçÆËÆ∞ÂΩïÂíåÂÖ±‰∫´

‚Ä¢ 
      
        ÂÆâÂÖ®
      
‚Ä¢ ÂÆâÂÖ®ËÆæÁΩÆ
‚Ä¢ ÂÆâÂÖ®ÊåáÂØº

‚Ä¢ 
      
        Ê°ÜÊû∂
      
‚Ä¢ LangChain Âíå LangGraph
‚Ä¢ CrewAI
‚Ä¢ LlamaIndex
‚Ä¢ Vercel AI SDK

‚Ä¢ 
        ËµÑÊ∫ê

‚Ä¢ ËøÅÁßªÂà∞ Gen AI SDK

‚Ä¢ ÁâàÊú¨ËØ¥Êòé

‚Ä¢ ÂºÉÁî®

‚Ä¢ API ÈóÆÈ¢òÊéíÊü•

‚Ä¢ Ë¥¶Âçï‰ø°ÊÅØ

‚Ä¢ Âêà‰Ωú‰ºô‰º¥ÂíåÂ∫ìÈõÜÊàê

‚Ä¢ 
      
        Google AI Studio
      
‚Ä¢ Âø´ÈÄüÂÖ•Èó®
‚Ä¢ Âú®‚ÄúÊûÑÂª∫‚ÄùÊ®°Âºè‰∏ãËøõË°åÊ∞õÂõ¥ÁºñÁ®ã
‚Ä¢ ËØïÁî® LearnLM
‚Ä¢ ÈóÆÈ¢òÊéíÊü•
‚Ä¢ Workspace Áî®Êà∑ÁöÑËÆøÈóÆÊùÉÈôê

‚Ä¢ 
      
        Google Cloud Platform
      
‚Ä¢ VertexAI Gemini API
‚Ä¢ OAuth Ë∫´‰ªΩÈ™åËØÅ

‚Ä¢ 
        ÊîøÁ≠ñ

‚Ä¢ ÊúçÂä°Êù°Ê¨æ

‚Ä¢ ÂèØÁî®Âå∫Âüü

‚Ä¢ ÂÖ∂‰ªñ‰ΩøÁî®ÊîøÁ≠ñ

‚Ä¢ 

  [
    
          È¶ñÈ°µ
        
  ](https://ai.google.dev/?hl=zh-cn)

‚Ä¢ 

  [
    
          Gemini API
        
  ](https://ai.google.dev/gemini-api?hl=zh-cn)

‚Ä¢ 

  [
    
          ÊñáÊ°£
        
  ](https://ai.google.dev/gemini-api/docs?hl=zh-cn)

      Gemini Developer API ‰ª∑Ê†º

ÊÇ®ÂèØ‰ª•ÂÖàÂÖçË¥πÂºÄÂßãÊûÑÂª∫Ôºå‰∫´ÂèóÂÆΩË£ïÁöÑÈôêÈ¢ùÔºåÁÑ∂Âêé‰∏∫Â∑≤ÂáÜÂ§áÂ•ΩÊäïÂÖ•Áîü‰∫ßÁöÑÂ∫îÁî®ÈááÁî®ÊåâÈúÄ‰ªòË¥πÂÆö‰ª∑Ê®°ÂºèËøõË°åÊâ©ÂÆπ„ÄÇ

          ÂÖçË¥π
          
Èù¢ÂêëÂàöÂºÄÂßã‰ΩøÁî® Gemini API ÁöÑÂºÄÂèëËÄÖÂíåÂ∞èÈ°πÁõÆ„ÄÇ

‚Ä¢ check_circleÂØπÊüê‰∫õÊ®°ÂûãÁöÑËÆøÈóÆÊùÉÈôêÊúâÈôê
              
‚Ä¢ check_circleÂÖçË¥πËæìÂÖ•ÂíåËæìÂá∫ token
              
‚Ä¢ check_circleGoogle AI Studio ËÆøÈóÆÊùÉÈôê
              
‚Ä¢ check_circleÁî®‰∫éÊîπËøõÊàë‰ª¨‰∫ßÂìÅÁöÑÂÜÖÂÆπ[*](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
          
          [ÂÖçË¥πÂºÄÂßã‰ΩøÁî®](https://aistudio.google.com?hl=zh-cn)

          ‰ªòË¥π
          
ÈÄÇÁî®‰∫éÈúÄË¶ÅÊõ¥Â§ßÈáèÊï∞ÊçÆÂíåÈ´òÁ∫ßÂäüËÉΩÁöÑÁîü‰∫ßÂ∫îÁî®„ÄÇ

‚Ä¢ check_circle‰∏∫Áîü‰∫ßÁéØÂ¢ÉÈÉ®ÁΩ≤ÊîæÂÆΩ‰∫ÜÈÄüÁéáÈôêÂà∂
              
‚Ä¢ check_circleËÆøÈóÆ‰∏ä‰∏ãÊñáÁºìÂ≠ò
              
‚Ä¢ check_circle ÊâπÂ§ÑÁêÜ APIÔºàÂèØÈôç‰Ωé 50% ÁöÑË¥πÁî®Ôºâ
              
‚Ä¢ check_circle‰ΩøÁî® Google ÊúÄÂÖàËøõÁöÑ AI Ê®°Âûã
              
‚Ä¢ check_circleÂÜÖÂÆπ‰∏ç‰ºöÁî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ[*](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
          
          [ÂçáÁ∫ß‰∏∫‰ªòË¥πË¥¶Âè∑](https://aistudio.google.com/api-keys?hl=zh-cn)

          ‰ºÅ‰∏ö
          
ÈÄÇÁî®‰∫éÂ§ßËßÑÊ®°ÈÉ®ÁΩ≤ÔºåÂú®ÂÆâÂÖ®ÊÄß„ÄÅÊîØÊåÅÂíåÂêàËßÑÊÄßÊñπÈù¢ÊúâËá™ÂÆö‰πâÈúÄÊ±ÇÔºåÁî± [Vertex AI](https://cloud.google.com/vertex-ai?hl=zh-cn) Êèê‰æõÊîØÊåÅ„ÄÇ

‚Ä¢ check_circle‰ªòË¥πÁâà‰∏≠ÁöÑÊâÄÊúâÂäüËÉΩÔºåÂ§ñÂä†ÂèØÈÄâÁöÑ‰ª•‰∏ãÂäüËÉΩÔºö
              
‚Ä¢ check_circle‰∏ìÂ±ûÊîØÊåÅÊ∏†ÈÅì
              
‚Ä¢ check_circleÈ´òÁ∫ßÂÆâÂÖ®‰∏éÂêàËßÑÂäüËÉΩ
              
‚Ä¢ check_circleÈ¢ÑÈÖçÁöÑÂêûÂêêÈáè
              
‚Ä¢ check_circleÂü∫‰∫éÁî®ÈáèÁöÑÊäòÊâ£
              
‚Ä¢ check_circleMLOps„ÄÅModel Garden Á≠â
          
          [‰∏éÈîÄÂîÆ‰∫∫ÂëòËÅîÁ≥ª](https://cloud.google.com/contact?hl=zh-cn)

## Gemini 3 Pro È¢ÑËßàÁâà

        gemini-3-pro-preview

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-3-pro-preview&hl=zh-cn)

ÂÆÉÊòØÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£Ê®°ÂûãÔºå‰πüÊòØÊàë‰ª¨ËøÑ‰ªä‰∏∫Ê≠¢ÊúÄÂº∫Â§ßÁöÑÊô∫ËÉΩ‰ΩìÂíåÊ∞õÂõ¥ÁºñÁ®ãÊ®°Âûã„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      2.00 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
4.00 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      12.00 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ËØçÂÖÉ
18.00 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ËØçÂÖÉ

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.20ÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™‰ª§Áâå
$0.40ÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™‰ª§Áâå
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå$4.50ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ*
      ‰∏çÂèØÁî®
      ÊØèÊúà 5,000 Ê¨°ÊèêÁ§∫ÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊêúÁ¥¢Êü•ËØ¢Êî∂Ë¥π 14 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      1.00 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
2.00 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      6.00 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
9.00 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.20ÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™‰ª§Áâå
$0.40ÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™‰ª§Áâå
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå$4.50ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ*
      ‰∏çÂèØÁî®
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêé‰∏∫ 14 ÁæéÂÖÉ / 1,000 Ê¨°ÊêúÁ¥¢Êü•ËØ¢

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

* ÂÆ¢Êà∑Âêë Gemini Êèê‰∫§ÁöÑËØ∑Ê±ÇÂèØËÉΩ‰ºöÂØºËá¥Á≥ªÁªüÂêë Google ÊêúÁ¥¢ÂèëÈÄÅ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Êü•ËØ¢„ÄÇÊÇ®ÈúÄË¶Å‰∏∫ÊâßË°åÁöÑÊØèÈ°πÂçïÁã¨ÁöÑÊêúÁ¥¢Êü•ËØ¢‰ªòË¥π„ÄÇ

## Gemini 3 Flash È¢ÑËßàÁâà

        gemini-3-flash-preview

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-3-flash-preview&hl=zh-cn)

Êàë‰ª¨ÊúÄÊô∫ËÉΩÁöÑÊ®°ÂûãÔºå‰∏ì‰∏∫ÈÄüÂ∫¶ËÄåÁîüÔºåÂ∞ÜÂâçÊ≤øÊô∫ËÉΩ‰∏éÂçìË∂äÁöÑÊêúÁ¥¢Âíå‰∫ãÂÆû‰æùÊçÆÁõ∏ÁªìÂêà„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ÂÖçË¥π
      0.50 ÁæéÂÖÉÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
1.00 ÁæéÂÖÉÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ÂÖçË¥π
      $3.00

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ÂÖçË¥π
      $0.05ÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ
$0.10ÔºàÈü≥È¢ëÔºâ
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå$1.00ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ*
      ‰∏çÂèØÁî®
      ÊØèÊúà 5,000 Ê¨°ÊèêÁ§∫ÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊêúÁ¥¢Êü•ËØ¢Êî∂Ë¥π 14 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.25ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$0.50ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      $1.50

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      ‰∏éÊ†áÂáÜÁâàÁõ∏ÂêåÔºåÊâπÈáè‰ª∑Ê†ºÂ∞öÊú™ÂÆûÊñΩ

        0.05 ÁæéÂÖÉÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ

        0.10 ÁæéÂÖÉÔºàÈü≥È¢ëÔºâ

        ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå 1.00 ÁæéÂÖÉÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ*
      ‰∏çÂèØÁî®
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêé‰∏∫ 14 ÁæéÂÖÉ / 1,000 Ê¨°ÊêúÁ¥¢Êü•ËØ¢

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

* ÂÆ¢Êà∑Âêë Gemini Êèê‰∫§ÁöÑËØ∑Ê±ÇÂèØËÉΩ‰ºöÂØºËá¥Á≥ªÁªüÂêë Google ÊêúÁ¥¢ÂèëÈÄÅ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Êü•ËØ¢„ÄÇÊÇ®ÈúÄË¶Å‰∏∫ÊâßË°åÁöÑÊØèÈ°πÂçïÁã¨ÁöÑÊêúÁ¥¢Êü•ËØ¢‰ªòË¥π„ÄÇ

## Gemini 3 Pro Image È¢ÑËßàÁâà üçå

        gemini-3-pro-image-preview

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-3-pro-image-preview&hl=zh-cn)

Êàë‰ª¨ÁöÑÂéüÁîüÂõæÁâáÁîüÊàêÊ®°ÂûãÔºåÂú®ÈÄüÂ∫¶„ÄÅÁÅµÊ¥ªÊÄßÂíå‰∏ä‰∏ãÊñáÁêÜËß£ÊñπÈù¢ÁªèËøá‰∏ìÈó®‰ºòÂåñ„ÄÇÊñáÊú¨ËæìÂÖ•ÂíåËæìÂá∫ÁöÑ‰ª∑Ê†º‰∏é [Gemini 3 Pro](#gemini-3-pro-preview) Áõ∏Âêå„ÄÇ

È¢ÑËßàÁâàÊ®°ÂûãÂú®Êàê‰∏∫Á®≥ÂÆöÁâà‰πãÂâçÂèØËÉΩ‰ºöÂèëÁîüÂèòÂåñÔºåÂπ∂‰∏îÂÖ∑ÊúâÊõ¥‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $2.00ÔºàÊñáÂ≠ó/ÂõæÁâáÔºâÔºå

      Áõ∏ÂΩì‰∫éÊØèÂº†ÂõæÁâá $0.0011*

      ËæìÂá∫‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $12.00ÔºàÊñáÂ≠óÂíåÊÄùËÄÉÔºâ

        $120.00ÔºàÂõæÁâáÔºâ

        Áõ∏ÂΩì‰∫éÊØèÂº† 1K/2K ÂõæÁâá $0.134**

        ÂíåÊØèÂº† 4K ÂõæÁâá $0.24**

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      1.00 ÁæéÂÖÉÔºàÊñáÂ≠óÔºâ„ÄÅ
0.0006 ÁæéÂÖÉÔºàÂõæÁâáÔºâ*

      ËæìÂá∫‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $6.00ÔºàÊñáÂ≠óÂíåÊÄùËÄÉÔºâ

        ÊØèÂº† 1K/2K ÂõæÁâá $0.067**

        ÊØèÂº† 4K ÂõæÁâá $0.12**

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

* ÂõæÁâáËæìÂÖ•ËÆæÁΩÆ‰∏∫ÊØèÂº†ÂõæÁâá 560 ‰∏™ token Êàñ 0.0011 ÁæéÂÖÉ„ÄÇ

**ÂõæÁâáËæìÂá∫ÁöÑË¥πÁî®‰∏∫ÊØè 100 ‰∏á‰∏™ token 120 ÁæéÂÖÉ„ÄÇËæìÂá∫ 1024x1024 ÂÉèÁ¥† (1K) Âà∞ 2048x2048 ÂÉèÁ¥† (2K) ÁöÑÂõæÁâá‰ºöÊ∂àËÄó 1,120 ‰∏™ tokenÔºåÁõ∏ÂΩì‰∫éÊØèÂº†ÂõæÁâá 0.134 ÁæéÂÖÉ„ÄÇËæìÂá∫Â∞∫ÂØ∏ÊúÄÂ§ß‰∏∫ 4096x4096 ÂÉèÁ¥† (4K) ÁöÑÂõæÁâá‰ºöÊ∂àËÄó 2,000 ‰∏™ tokenÔºåÁõ∏ÂΩì‰∫éÊØèÂº†ÂõæÁâá 0.24 ÁæéÂÖÉ„ÄÇ

## Gemini 2.5 Pro

        gemini-2.5-pro

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-2.5-pro&hl=zh-cn)

Google Êóó‰∏ãÂÖàËøõÁöÑÂ§öÁî®ÈÄîÊ®°ÂûãÔºåÊìÖÈïøÂ§ÑÁêÜÁºñÁ†ÅÂíåÂ§çÊùÇÁöÑÊé®ÁêÜ‰ªªÂä°„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ÂÖçË¥π
      1.25 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
2.50 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ÂÖçË¥π
      10.00 ÁæéÂÖÉÔºåÊèêÁ§∫‰∏çË∂ÖËøá 20 ‰∏á‰∏™ token
15.00 ÁæéÂÖÉÔºåÊèêÁ§∫Ë∂ÖËøá 20 ‰∏á‰∏™ token

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.125ÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™‰ª§Áâå
$0.25ÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™‰ª§Áâå
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå$4.50ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ‰∏çÂèØÁî®
      1,500 RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 ‰∏™Êé•Âú∞ÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      10,000 Ê¨° RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°Êé•Âú∞ÊèêÁ§∫Êî∂Ë¥π 25 ÁæéÂÖÉ

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.625ÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
$1.25ÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      5.00 ÁæéÂÖÉÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™ token
7.50 ÁæéÂÖÉÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™ token

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.125ÔºåÊèêÁ§∫ &lt;= 20 ‰∏á‰∏™‰ª§Áâå
$0.25ÔºåÊèêÁ§∫ > 20 ‰∏á‰∏™‰ª§Áâå
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™‰ª§Áâå$4.50ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ‰∏çÂèØÁî®
      1,500 RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 ‰∏™Êé•Âú∞ÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

## Gemini 2.5 Flash

        gemini-2.5-flash

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-2.5-flash&hl=zh-cn)

Êàë‰ª¨ÁöÑÈ¶ñ‰∏™Ê∑∑ÂêàÊé®ÁêÜÊ®°ÂûãÔºåÊîØÊåÅ 100 ‰∏á‰∏™ token ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåÂπ∂ÂÖ∑ÊúâÊÄùËÄÉÈ¢ÑÁÆó„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ÂÖçË¥π
      $0.30ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$1.00ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ÂÖçË¥π
      $2.50

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.03ÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ
$0.1ÔºàÈü≥È¢ëÔºâ
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™ token$1.00ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ÂÖçË¥πÔºåÊúÄÂ§ö 500 ‰∏™ RPDÔºà‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâ
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºå‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊúâÊ†πÊçÆÁöÑÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      500 RPD
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°Êé•Âú∞ÊèêÁ§∫Êî∂Ë¥π 25 ÁæéÂÖÉ

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.15ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$0.50ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      $1.25

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.03ÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ
$0.1ÔºàÈü≥È¢ëÔºâ
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™ token$1.00ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ‰∏çÂèØÁî®
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºå‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊúâÊ†πÊçÆÁöÑÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      ‰æùÊâò Google Âú∞ÂõæËøõË°åÊé•Âú∞
      ‰∏çÂèØÁî®
      ‰∏çÂèØÁî®

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

## Gemini 2.5 Flash È¢ÑËßàÁâà

        gemini-2.5-flash-preview-09-2025

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-2.5-flash-preview-09-2025&hl=zh-cn)

Âü∫‰∫é 2.5 Flash Ê®°ÂûãÁöÑÊúÄÊñ∞Ê®°Âûã„ÄÇ2.5 Flash È¢ÑËßàÁâàÊúÄÈÄÇÂêàÂ§ßËßÑÊ®°Â§ÑÁêÜ„ÄÅ‰ΩéÂª∂Ëøü„ÄÅÈúÄË¶ÅÊÄùËÄÉÁöÑÈ´òÊï∞ÊçÆÈáè‰ªªÂä°‰ª•Âèä‰ª£ÁêÜÂ∫îÁî®Âú∫ÊôØ„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ÂÖçË¥π
      $0.30ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$1.00ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ÂÖçË¥π
      $2.50

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.03ÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ
$0.1ÔºàÈü≥È¢ëÔºâ
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™ token$1.00ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ÂÖçË¥πÔºåÊúÄÂ§ö 500 ‰∏™ RPDÔºà‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâ
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºå‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊúâÊ†πÊçÆÁöÑÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

ÊâπÈáè

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.15ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$0.50ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ‰∏çÂèØÁî®
      $1.25

      ‰∏ä‰∏ãÊñáÁºìÂ≠ò‰ª∑Ê†º
      ‰∏çÂèØÁî®
      $0.03ÔºàÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ëÔºâ
$0.1ÔºàÈü≥È¢ëÔºâ
ÊØèÂ∞èÊó∂ÊØè 100 ‰∏á‰∏™ token$1.00ÔºàÂ≠òÂÇ®‰ª∑Ê†ºÔºâ

      ‰ΩøÁî® Google ÊêúÁ¥¢Âª∫Á´ã‰æùÊçÆ
      ‰∏çÂèØÁî®
      1,500 Ê¨° RPDÔºàÂÖçË¥πÔºå‰∏é Flash-Lite RPD ÂÖ±Áî®ÈôêÈ¢ùÔºâÔºå‰πãÂêéÊØè 1,000 Ê¨°ÊúâÊ†πÊçÆÁöÑÊèêÁ§∫Êî∂Ë¥π 35 ÁæéÂÖÉ

      Áî®‰∫éÊîπËøõÊàë‰ª¨ÁöÑ‰∫ßÂìÅ
      [ÊòØ](https://ai.google.dev/gemini-api/terms?hl=zh-cn)
      [Âê¶](https://ai.google.dev/gemini-api/terms?hl=zh-cn)

## Gemini 2.5 Flash-Lite

        gemini-2.5-flash-lite

        [Âú® Google AI Studio ‰∏≠ËØïÁî®](https://aistudio.google.com?model=gemini-2.5-flash-lite&hl=zh-cn)

Google Êóó‰∏ãÊúÄÂ∞èÂ∑ß‰∏îÊúÄÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊ®°ÂûãÔºå‰∏ì‰∏∫Â§ßËßÑÊ®°‰ΩøÁî®ËÄåÊâìÈÄ†„ÄÇ

Ê†áÂáÜ

      ÂÖçË¥πÂ±ÇÁ∫ß
      ‰ªòË¥πÂ±ÇÁ∫ßÔºåÊØè 100 ‰∏á‰∏™‰ª§ÁâåÔºàÁæéÂÖÉÔºâ

      ËæìÂÖ•‰ª∑Ê†ºÔºàÊñáÂ≠ó„ÄÅÂõæÁâá„ÄÅËßÜÈ¢ëÔºâ
      ÂÖçË¥π
      $0.10ÔºàÊñáÂ≠ó / ÂõæÁâá / ËßÜÈ¢ëÔºâ
$0.30ÔºàÈü≥È¢ëÔºâ

      ËæìÂá∫‰ª∑Ê†ºÔºàÂåÖÊã¨ÊÄùËÄÉ tokenÔºâ
      ÂÖçË¥π

... [truncated]




>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/api-reference/responses","max_length":12000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
Error: https://platform.openai.com/docs/api-reference/responses returned 403


>>>TOOL web_fetch
{"url":"https://openai.com/api/pricing/","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/api-reference/responses","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.claude.com/docs/en/about-claude/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://ai.google.dev/gemini-api/docs/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.moonshot.ai/docs/pricing/chat","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://openai.com/api/pricing/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 2.54s 
[SCRAPE].. ‚óÜ https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 0.08s 
[COMPLETE] ‚óè https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 2.63s 
[Skip to main content](https://openai.com/api/pricing/#main)
Log in
[](https://openai.com/)
Switch to
  * [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Sora(opens in a new window)](https://sora.com/)
  * [API Platform(opens in a new window)](https://platform.openai.com/)


[Home](https://openai.com/)
  * [API Platform](https://openai.com/api/)
  * [API Pricing](https://openai.com/api/pricing/)
  * [Agents](https://openai.com/agent-platform/)
  * [Codex](https://openai.com/codex/)
  * [Open Models](https://openai.com/open-models/)
  * [Community(opens in a new window)](https://community.openai.com/)


  * Research
Back to main menu
    * [Research Index](https://openai.com/research/index/)
    * [Research Overview](https://openai.com/research/)
    * [Research Residency](https://openai.com/residency/)
    * [OpenAI for Science](https://openai.com/science/)
    * Latest Advancements
    * [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)
    * [GPT-5.1](https://openai.com/index/gpt-5-1/)
    * [Sora 2](https://openai.com/index/sora-2/)
    * [GPT-5](https://openai.com/index/introducing-gpt-5/)
    * [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)
    * [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)
  * Safety
Back to main menu
    * [Safety Approach](https://openai.com/safety/)
    * [Security & Privacy](https://openai.com/security-and-privacy/)
  * For Business
Back to main menu
    * [Business Overview](https://openai.com/business/)
    * [Enterprise](https://openai.com/business/frontier/)
    * [Startups](https://openai.com/startups/)
    * [Solutions](https://openai.com/solutions/)
    * [Learn](https://openai.com/business/learn/)
    * [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)
    * [API Pricing](https://openai.com/api/pricing/)
    * [Contact Sales](https://openai.com/contact-sales/)
  * For Developers
Back to main menu
    * [API Platform](https://openai.com/api/)
    * [API Pricing](https://openai.com/api/pricing/)
    * [Agents](https://openai.com/agent-platform/)
    * [Codex](https://openai.com/codex/)
    * [Open Models](https://openai.com/open-models/)
    * [Community(opens in a new window)](https://community.openai.com/)
  * [ChatGPT](https://chatgpt.com/overview?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
Back to main menu
    * [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
    * [Business](https://chatgpt.com/for-business/team?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
    * [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
    * [Education](https://chatgpt.com/for-business/education?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
    * [Pricing](https://chatgpt.com/pricing?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
    * [Download](https://chatgpt.com/download?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Sora](https://openai.com/sora/)
  * [Codex](https://openai.com/codex/)
  * [Stories](https://openai.com/stories/)
  * Company
Back to main menu
    * [About Us](https://openai.com/about/)
    * [Our Charter](https://openai.com/charter/)
    * [Foundation](https://openai.com/foundation/)
    * [Careers](https://openai.com/careers/)
    * [Brand Guidelines](https://openai.com/brand/)
  * [News](https://openai.com/news/company-announcements/)


Log in
Pricing | OpenAI
# API Pricing
[Contact sales](https://openai.com/contact-sales/)
## Flagship models
Our frontier models are designed to spend more time thinking before producing a response, making them ideal for complex, multi-step problems.
## GPT-5.2
The best model for coding and agentic tasks across industries
### Price
Input:  
$1.750 / 1M tokens
Cached input:  
$0.175 / 1M tokens
Output:  
$14.000 / 1M tokens
## GPT-5.2 pro
The smartest and most precise model
### Price
Input:  
$21.00 / 1M tokens
Cached input:  
-
Output:  
$168.00 / 1M tokens
## GPT-5 mini
A faster, cheaper version of GPT-5 for well-defined tasks
### Price
Input:  
$0.250 / 1M tokens
Cached input:  
$0.025 / 1M tokens
Output:  
$2.000 / 1M tokens
Pricing reflects standard processing rates. To optimize cost and performance for different use cases, we also offer:
  * [**_Batch API‚Å†_** ‚Å†(opens in a new window)](https://platform.openai.com/docs/guides/batch): Save 50% on inputs and outputs with the Batch API and run tasks asynchronously over 24 hours.
  * [**_Priority processing_****‚Å†** ‚Å†](https://openai.com/api-priority-processing/): offers reliable, high-speed performance with the flexibility to pay-as-you-go.


### Fine-tuning our models
Customize our models to get even higher performance for your specific use cases.
## GPT-4.1
### Fine-tuning price
Input:  
$3.00 / 1M tokens
Cached input:  
$0.75 / 1M tokens
Output:  
$12.00 / 1M tokens
Training:  
$25.00 / 1M tokens
## GPT-4.1 mini
### Fine-tuning price
Input:  
$0.80 / 1M tokens
Cached input:  
$0.20 / 1M tokens
Output:  
$3.20 / 1M tokens
Training:  
$5.00 / 1M tokens
## GPT-4.1 nano
### Fine-tuning price
Input:  
$0.20 / 1M tokens
Cached input:  
$0.05 / 1M tokens
Output:  
$0.80 / 1M tokens
Training:  
$1.50 / 1M tokens
## o4-mini
### Reinforcement fine-tuning price
Input:  
$4.00 / 1M tokens
Cached input:  
$1.00 / 1M tokens
Output:  
$16.00 / 1M tokens
Training:  
$100.00 / training hour
  * [Explore detailed pricing(opens in a new window)](https://platform.openai.com/docs/pricing)


## Our APIs
## Realtime API
Build low-latency, multimodal experiences including speech-to-speech.
### Text
Text
gpt-realtime
$4.00 / 1M input tokens
$0.40 / 1M cached input tokens
$16.00 / 1M output tokens
gpt-realtime
$4.00 / 1M input tokens
$0.40 / 1M cached input tokens
$16.00 / 1M output tokens
gpt-realtime-mini
$0.60 / 1M input tokens
$0.06 / 1M cached input tokens
$2.40 / 1M output tokens
gpt-realtime-mini
$0.60 / 1M input tokens
$0.06 / 1M cached input tokens
$2.40 / 1M output tokens
### Audio
Audio
gpt-realtime
$32.00 / 1M input tokens
$0.40 / 1M cached input tokens
$64.00 / 1M output tokens
gpt-realtime
$32.00 / 1M input tokens
$0.40 / 1M cached input tokens
$64.00 / 1M output tokens
gpt-realtime-mini
$10.00 / 1M input tokens
$0.30 / 1M cached input tokens
$20.00 / 1M output tokens
gpt-realtime-mini
$10.00 / 1M input tokens
$0.30 / 1M cached input tokens
$20.00 / 1M output tokens
### Image
Image
gpt-realtime
$5.00 / 1M input tokens
$0.50 / 1M cached input tokens
-
gpt-realtime
$5.00 / 1M input tokens
$0.50 / 1M cached input tokens
-
gpt-realtime-mini
$0.80 / 1M input tokens
$0.08 / 1M cached input tokens
-
gpt-realtime-mini
$0.80 / 1M input tokens
$0.08 / 1M cached input tokens
-
## Sora Video API
Richly detailed, dynamic video generation and remixing with our latest generative model.
Models | Size | Price per second  
---|---|---  
sora-2 |  Portrait: 720 x 1280 Landscape: 1280 x 720 | $0.10  
sora-2-pro |  Portrait: 720 x 1280 Landscape: 1280 x 720 | $0.30  
sora-2-pro |  Portrait: 1024 x 1792 Landscape: 1792 x 1024 | $0.50  
## Image Generation API
Precise, high-fidelity image generation and editing with our latest multimodal model.
### Text
Text
GPT-image-1.5
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
$10.00 / 1M output tokens*
GPT-image-1.5
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
$10.00 / 1M output tokens*
GPT-image-1
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
-
GPT-image-1
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
-
GPT-image-1-mini
$2.00 / 1M input tokens
$0.20 / 1M cached input tokens*
-
GPT-image-1-mini
$2.00 / 1M input tokens
$0.20 / 1M cached input tokens*
-
### Image
Image
GPT-image-1.5
$8.00 / 1M input tokens
$2.00 / 1M cached input tokens*
$32.00 / 1M output tokens
GPT-image-1.5
$8.00 / 1M input tokens
$2.00 / 1M cached input tokens*
$32.00 / 1M output tokens
GPT-image-1
$10.00 / 1M input tokens
$2.50 / 1M cached input tokens*
$40.00 / 1M output tokens
GPT-image-1
$10.00 / 1M input tokens
$2.50 / 1M cached input tokens*
$40.00 / 1M output tokens
GPT-image-1-mini
$2.50 / 1M input tokens
$0.25 / 1M cached input tokens*
$8.00 / 1M output tokens
GPT-image-1-mini
$2.50 / 1M input tokens
$0.25 / 1M cached input tokens*
$8.00 / 1M output tokens
Prompts are billed similarly to other GPT models. Image outputs cost approximately $0.01 (low), $0.04 (medium), and $0.17 (high) for square images.
*available via the Responses API
*text output tokens include model reasoning tokens
For detailed token usage by image quality and size, see the [docs](https://platform.openai.com/docs/pricing).
## Responses API
Our newest API combining the simplicity of Chat Completions with the built-in tool use of Assistants.
Price
Responses API is not priced separately. Tokens are billed at the chosen language model‚Äôs input and output rates.
## Chat Completions API
Build text-based conversational experiences.
Price
Chat Completions API is not priced separately. Tokens are billed at the chosen language model's input and output rates.
## Assistants API
Build assistant-like experiences with our tools.
Price
Assistants API is not priced separately. Tokens are billed at the chosen language model's input and output rates.
## Built-in tools
Extend model capabilities with built-in tools in the API Platform.
Tool
Cost
Code Interpreter
$0.03 / session
File Search Storage
$0.10 / GB of vector storage per day (first GB free)
File Search Tool Call   
(Responses API only)
$2.50 / 1k tool calls
Web Search Tool Call
There are two components that contribute to the cost of using the web search tool: (1) Tool calls and (2) Search content tokens.
  * Tool calls are billed per 1,000 calls, according to the tool version and model type.
  * Search content tokens are tokens retrieved from the search index and fed to the model alongside your prompt to generate an answer. These are billed at the model‚Äôs input token rate, unless otherwise specified.


Tool Version | Cost  
---|---  
Web search (all models) | $10.00 / 1K calls + search content tokens billed at model rates1  
Web search preview (reasoning models) | $10.00 / 1K calls + search content tokens billed at model rates  
Web search preview (non-reasoning models) | $25.00 / 1K calls + search content tokens are free  
1For gpt-4o-mini and gpt-4.1-mini with the web search non-preview tool, search content tokens are charged as a fixed block of 8,000 input tokens per call.
The billing dashboard will report gpt-4.1 and gpt-4.1-mini search line items as ‚Äòweb search tool calls | gpt-4o‚Äô and ‚Äòweb search tool calls | gpt-4o-mini‚Äô
GB refers to binary gigabytes of storage (also known as gibibyte), where 1GB is 2^30 bytes.
## AgentKit
Build, deploy, and optimize production-grade agents with Agent Builder, ChatKit, and Evals.
Billing
Begins on November 1, 2025 ‚Äî no charges will apply before then.
Usage meter
Storage for ChatKit File / Image Uploads.
Free tier (per account, per month)
1 GB
Price beyond free tier
$0.10 / GB-day
What‚Äôs always free
Agent Builder ‚Äì design and iterate with zero cost until you hit Run. Self-hosted ChatKit ‚Äì host a custom ChatKit backend and pay only normal model-token charges. Enterprise controls ‚Äì SSO, RBAC, and audit logs are included at no additional fee.
  * [Explore detailed pricing(opens in a new window)](https://platform.openai.com/docs/pricing)


Explore our offerings for Enterprise customers: [**_Priority processing_** ‚Å†](https://openai.com/api-priority-processing/), [**_Scale Tier_** _‚Å†_ ‚Å†](https://openai.com/api-scale-tier/) and [**_Reserved Capacity_** _‚Å†_ ‚Å†](https://openai.com/reserved-capacity/).
### FAQ
### Which model should I use?
We recommend that developers use our large and mini GPT models for everyday tasks. Our large GPT models generally perform better on a wide range of tasks, while our mini GPT models are fast and inexpensive for simpler tasks.
Our large and mini reasoning models are ideal for complex, multi-step tasks and STEM use cases that require deep thinking about tough problems. You can choose the mini reasoning model if you're looking for a faster, more inexpensive option.
We recommend experimenting with all of these models in the [Playground‚Å†‚Å†(opens in a new window)](https://platform.openai.com/playground) to explore which models provide the best price performance trade-off for your usage.
### Do you offer an enterprise package or SLAs?
We offer different tiers of access to our enterprise customers that include SLAs, lower latency, and more. Please [_contact our sales team_ ‚Å†](https://openai.com/contact-sales/) to learn more.
### Will I be charged for API usage in the Playground? 
Yes, we treat Playground usage the same as regular API usage. You will be billed at the per-token input and output prices mentioned above.
### How will I know how many tokens I‚Äôve used each month?
A token is a mathematical representation of natural language. Log in to your account to view your [_usage tracking dashboard_ ‚Å†(opens in a new window)](https://platform.openai.com/account/usage). This dashboard will show you how many tokens you‚Äôve used during the current and past billing cycles.
### How can I manage my spending on the API platform?
You can set a monthly budget in [_your billing settings‚Å†_ ‚Å†(opens in a new window)](https://platform.openai.com/settings/organization/limits), after which we‚Äôll stop serving your requests. There may be a delay in enforcing the limit, and you are responsible for any overage incurred. You can also configure an email notification threshold to receive an email alert once you cross that threshold each month. We recommend checking your [_usage tracking dashboard_ ‚Å†(opens in a new window)](https://platform.openai.com/account/usage) regularly to monitor your spend.
For customers managing work with Projects, you can [_set and manage billing restrictions per project_ ‚Å†(opens in a new window)](https://help.openai.com/en/articles/9186755-managing-your-work-in-the-api-platform-with-projects)‚Å† in the Dashboard.
### Is access to the API included in ChatGPT Plus, Business, Enterprise or Edu?
No, OpenAI APIs are billed separately from ChatGPT Plus, Business, Enterprise and Edu. ChatGPT subscription pricing can be found at [_openai.com/chatgpt/pricing/_ ‚Å†](http://openai.com/chatgpt/pricing/). 
### How is pricing calculated for images?
Images are converted into tokens and charged per token. Text models price image tokens at standard text token rates, while GPT Image and gpt-realtime uses a separate image token rate. Models like gpt-4.1-mini, gpt-4.1-nano, and o4-mini convert images into tokens differently. [Learn more in our docs‚Å†(opens in a new window)](https://platform.openai.com/docs/guides/images-vision?api-mode=chat#calculating-costs).
Pricing calculator
Set model
gpt-5 gpt-5.1 gpt-5.2 gpt-5-mini gpt-5-nano gpt-5-chat-latest gpt-4.1 gpt-4.1-mini gpt-4.1-nano o3 o3-deep-research o3-pro-2025-06-10 o4-mini o4-mini-deep-research o1 o1-pro gpt-4o gpt-4o-2024-05-13 gpt-4o-mini computer-use-preview gpt-4.5-preview codex-mini-latest gpt-5-codex
Set width
px
by
Set height
px
=$0.000263
Low resolution
=$0.000263
Price per 1M tokens (fixed) | $1.25  
---|---  
512 √ó 512 tiles | 1 √ó 1  
Total tiles | 1  
Base tokens | 70  
Tile tokens | 140 √ó 1 = 140  
Total tokens | 210  
Total price | $0.000263  
## Start creating with OpenAI‚Äôs powerful models.
[Get started(opens in a new window)](https://platform.openai.com/)[Contact sales](https://openai.com/contact-sales/)
Our Research
  * [Research Index](https://openai.com/research/index/)
  * [Research Overview](https://openai.com/research/)
  * [Research Residency](https://openai.com/residency/)
  * [OpenAI for Science](https://openai.com/science/)


Latest Advancements
  * [GPT-5](https://openai.com/gpt-5/)
  * [Codex](https://openai.com/index/introducing-gpt-5-3-codex/)
  * [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)
  * [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)
  * [GPT-4o](https://openai.com/index/gpt-4o-system-card/)
  * [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
  * [Sora](https://openai.com/index/sora-system-card/)


Safety
  * [Safety Approach](https://openai.com/safety/)
  * [Security & Privacy](https://openai.com/security-and-privacy/)
  * [Trust & Transparency](https://openai.com/trust-and-transparency/)


ChatGPT
  * [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Business](https://chatgpt.com/business/business-plan?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Education](https://chatgpt.com/business/education?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)
  * [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=173e537e-2653-4568-aaba-59b8ddc4fd73&openaicom_referred=true)


Sora
  * [Sora Overview](https://openai.com/sora/)
  * [Features](https://openai.com/sora/#features)
  * [Pricing](https://openai.com/sora/#pricing)
  * [Sora log in(opens in a new window)](https://sora.com/)


API Platform
  * [Platform Overview](https://openai.com/api/)
  * [Pricing](https://openai.com/api/pricing/)
  * [API log in(opens in a new window)](https://platform.openai.com/login)
  * [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)
  * [Developer Forum(opens in a new window)](https://community.openai.com/)


For Business
  * [Business Overview](https://openai.com/business/)
  * [Solutions](https://openai.com/solutions/)
  * [Contact Sales](https://openai.com/contact-sales/)


Company
  * [About Us](https://openai.com/about/)
  * [Our Charter](https://openai.com/charter/)
  * [Foundation](https://openai.com/foundation/)
  * [Careers](https://openai.com/careers/)
  * [Brand](https://openai.com/brand/)


Support
  * [Help Center(opens in a new window)](https://help.openai.com/)


More
  * [News](https://openai.com/news/)
  * [Stories](https://openai.com/stories/)
  * [Livestreams](https://openai.com/live/)
  * [Podcast](https://openai.com/podcast/)
  * [RSS](https://openai.com/news/rss.xml)


Terms & Policies
  * [Terms of Use](https://openai.com/policies/terms-of-use/)
  * [Privacy Policy](https://openai.com/policies/privacy-policy/)
  * [Other Policies ](https://openai.com/policies/)


[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)
OpenAI ¬© 2015‚Äì2026Manage Cookies
EnglishUnited States
We use cookies
We use cookies to help this site function, understand service usage, and support marketing efforts. Visit Manage Cookies to change preferences anytime. View our [Cookie Policy](https://openai.com/policies/cookie-policy/) for more info.
Manage CookiesReject non-essentialAccept all

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/api-reference/responses

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 2.24s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 0.13s 
[COMPLETE] ‚óè https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 2.38s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs/guides/text-generation)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
API Reference
[Introduction](https://platform.openai.com/docs/api-reference/introduction)
[Authentication](https://platform.openai.com/docs/api-reference/authentication)
[Debugging requests](https://platform.openai.com/docs/api-reference/debugging-requests)
[Backward compatibility](https://platform.openai.com/docs/api-reference/backward-compatibility)
Responses API
[Responses](https://platform.openai.com/docs/api-reference/responses)
[Create a model response](https://platform.openai.com/docs/api-reference/responses/create)
[Get a model response](https://platform.openai.com/docs/api-reference/responses/get)
[Delete a model response](https://platform.openai.com/docs/api-reference/responses/delete)
[Cancel a response](https://platform.openai.com/docs/api-reference/responses/cancel)
[Compact a response](https://platform.openai.com/docs/api-reference/responses/compact)
[List input items](https://platform.openai.com/docs/api-reference/responses/input-items)
[Get input token counts](https://platform.openai.com/docs/api-reference/responses/input-tokens)
[The response object](https://platform.openai.com/docs/api-reference/responses/object)
[The input item list](https://platform.openai.com/docs/api-reference/responses/list)
[The compacted response object](https://platform.openai.com/docs/api-reference/responses/compacted-object)
[Conversations](https://platform.openai.com/docs/api-reference/conversations)
[Streaming events](https://platform.openai.com/docs/api-reference/responses-streaming)
Webhooks
[Webhook Events](https://platform.openai.com/docs/api-reference/webhook-events)
Platform APIs
[Audio](https://platform.openai.com/docs/api-reference/audio)
[Videos](https://platform.openai.com/docs/api-reference/videos)
[Images](https://platform.openai.com/docs/api-reference/images)
[Image Streaming](https://platform.openai.com/docs/api-reference/images-streaming)
[Embeddings](https://platform.openai.com/docs/api-reference/embeddings)
[Evals](https://platform.openai.com/docs/api-reference/evals)
[Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning)
[Graders](https://platform.openai.com/docs/api-reference/graders)
[Batch](https://platform.openai.com/docs/api-reference/batch)
[Files](https://platform.openai.com/docs/api-reference/files)
[Uploads](https://platform.openai.com/docs/api-reference/uploads)
[Models](https://platform.openai.com/docs/api-reference/models)
[Moderations](https://platform.openai.com/docs/api-reference/moderations)
Vector stores
[Vector stores](https://platform.openai.com/docs/api-reference/vector-stores)
[Vector store files](https://platform.openai.com/docs/api-reference/vector-stores-files)
[Vector store file batches](https://platform.openai.com/docs/api-reference/vector-stores-file-batches)
ChatKit
Beta
[ChatKit](https://platform.openai.com/docs/api-reference/chatkit)
Containers
[Containers](https://platform.openai.com/docs/api-reference/containers)
[Container Files](https://platform.openai.com/docs/api-reference/container-files)
Realtime
[Realtime](https://platform.openai.com/docs/api-reference/realtime)
[Client secrets](https://platform.openai.com/docs/api-reference/realtime-sessions)
[Calls](https://platform.openai.com/docs/api-reference/realtime-calls)
[Client events](https://platform.openai.com/docs/api-reference/realtime-client-events)
[Server events](https://platform.openai.com/docs/api-reference/realtime-server-events)
Chat Completions
[Chat Completions](https://platform.openai.com/docs/api-reference/chat)
[Streaming](https://platform.openai.com/docs/api-reference/chat-streaming)
Assistants
[Assistants](https://platform.openai.com/docs/api-reference/assistants)
[Threads](https://platform.openai.com/docs/api-reference/threads)
[Messages](https://platform.openai.com/docs/api-reference/messages)
[Runs](https://platform.openai.com/docs/api-reference/runs)
[Run steps](https://platform.openai.com/docs/api-reference/run-steps)
[Streaming](https://platform.openai.com/docs/api-reference/assistants-streaming)
Administration
[Administration](https://platform.openai.com/docs/api-reference/administration)
[Admin API Keys](https://platform.openai.com/docs/api-reference/admin-api-keys)
[Invites](https://platform.openai.com/docs/api-reference/invite)
[Users](https://platform.openai.com/docs/api-reference/users)
[Groups](https://platform.openai.com/docs/api-reference/groups)
[Roles](https://platform.openai.com/docs/api-reference/roles)
[Role assignments](https://platform.openai.com/docs/api-reference/role-assignments)
[Projects](https://platform.openai.com/docs/api-reference/projects)
[Project users](https://platform.openai.com/docs/api-reference/project-users)
[Project groups](https://platform.openai.com/docs/api-reference/project-groups)
[Project service accounts](https://platform.openai.com/docs/api-reference/project-service-accounts)
[Project API keys](https://platform.openai.com/docs/api-reference/project-api-keys)
[Project rate limits](https://platform.openai.com/docs/api-reference/project-rate-limits)
[Audit logs](https://platform.openai.com/docs/api-reference/audit-logs)
[Usage](https://platform.openai.com/docs/api-reference/usage)
[Certificates](https://platform.openai.com/docs/api-reference/certificates)
Legacy
[Completions](https://platform.openai.com/docs/api-reference/completions)
[Realtime Beta](https://platform.openai.com/docs/api-reference/realtime_beta)
[Realtime Beta session tokens](https://platform.openai.com/docs/api-reference/realtime-beta-sessions)
[Realtime Beta client events](https://platform.openai.com/docs/api-reference/realtime-beta-client-events)
[Realtime Beta server events](https://platform.openai.com/docs/api-reference/realtime-beta-server-events)
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
## 
Responses
OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.
Related guides:
  * [Quickstart](https://platform.openai.com/docs/quickstart?api-mode=responses)
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text?api-mode=responses)
  * [Image inputs](https://platform.openai.com/docs/guides/images?api-mode=responses)
  * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses)
  * [Function calling](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)
  * [Conversation state](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)
  * [Extend the models with tools](https://platform.openai.com/docs/guides/tools?api-mode=responses)


## 
Create a model response
post https://api.openai.com/v1/responses
Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text) or [image](https://platform.openai.com/docs/guides/images) inputs to generate [text](https://platform.openai.com/docs/guides/text) or [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have the model call your own [custom code](https://platform.openai.com/docs/guides/function-calling) or use built-in [tools](https://platform.openai.com/docs/guides/tools) like [web search](https://platform.openai.com/docs/guides/tools-web-search) or [file search](https://platform.openai.com/docs/guides/tools-file-search) to use your own data as input for the model's response.
#### Request body
[](https://platform.openai.com/docs/api-reference/responses#responses_create-background)
background
boolean
Optional
Defaults to false
Whether to run the model response in the background. [Learn more](https://platform.openai.com/docs/guides/background).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-context_management)
context_management
array
Optional
Context management configuration for this request.
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-conversation)
conversation
string or object
Optional
Defaults to null
The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request. Input items and output items from this response are automatically added to this conversation after this response completes.
Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-include)
include
array
Optional
Specify additional output data to include in the model response. Currently supported values are:
  * `web_search_call.action.sources`: Include the sources of the web search tool call.
  * `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.
  * `computer_call_output.output.image_url`: Include image urls from the computer call output.
  * `file_search_call.results`: Include the search results of the file search tool call.
  * `message.input_image.image_url`: Include image urls from the input message.
  * `message.output_text.logprobs`: Include logprobs with assistant messages.
  * `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).


[](https://platform.openai.com/docs/api-reference/responses#responses_create-input)
input
string or array
Optional
Text, image, or file inputs to the model, used to generate a response.
Learn more:
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
  * [Image inputs](https://platform.openai.com/docs/guides/images)
  * [File inputs](https://platform.openai.com/docs/guides/pdf-files)
  * [Conversation state](https://platform.openai.com/docs/guides/conversation-state)
  * [Function calling](https://platform.openai.com/docs/guides/function-calling)


Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-instructions)
instructions
string
Optional
A system (or developer) message inserted into the model's context.
When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-max_output_tokens)
max_output_tokens
integer
Optional
An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-max_tool_calls)
max_tool_calls
integer
Optional
The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-metadata)
metadata
map
Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.
Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-model)
model
string
Optional
Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](https://platform.openai.com/docs/models) to browse and compare available models.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-parallel_tool_calls)
parallel_tool_calls
boolean
Optional
Defaults to true
Whether to allow the model to run tool calls in parallel.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-previous_response_id)
previous_response_id
string
Optional
The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt)
prompt
object
Optional
Reference to a prompt template and its variables. [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt_cache_key)
prompt_cache_key
string
Optional
Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt_cache_retention)
prompt_cache_retention
string
Optional
The retention policy for the prompt cache. Set to `24h` to enable extended prompt caching, which keeps cached prefixes active for longer, up to a maximum of 24 hours. [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-reasoning)
reasoning
object
Optional
**gpt-5 and o-series models only**
Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-safety_identifier)
safety_identifier
string
Optional
A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-service_tier)
service_tier
string
Optional
Defaults to auto
Specifies the processing type used for serving the request.
  * If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
  * If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
  * If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or '[priority](https://openai.com/api-priority-processing/)', then the request will be processed with the corresponding service tier.
  * When not set, the default behavior is 'auto'.


When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-store)
store
boolean
Optional
Defaults to true
Whether to store the generated model response for later retrieval via API.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-stream)
stream
boolean
Optional
Defaults to false
If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming) for more information.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-stream_options)
stream_options
object
Optional
Defaults to null
Options for streaming responses. Only set this when you set `stream: true`.
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-temperature)
temperature
number
Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-text)
text
object
Optional
Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
  * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)


Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-tool_choice)
tool_choice
string or object
Optional
How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.
Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-tools)
tools
array
Optional
An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.
We support the following categories of tools:
  * **Built-in tools** : Tools that are provided by OpenAI that extend the model's capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search) or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about [built-in tools](https://platform.openai.com/docs/guides/tools).
  * **MCP Tools** : Integrations with third-party systems via custom MCP servers or predefined connectors such as Google Drive and SharePoint. Learn more about [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).
  * **Function calls (custom tools)** : Functions that are defined by you, enabling the model to call your own code with strongly typed arguments and outputs. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use custom tools to call your own code.


Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-top_logprobs)
top_logprobs
integer
Optional
An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-top_p)
top_p
number
Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
We generally recommend altering this or `temperature` but not both.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-truncation)
truncation
string
Optional
Defaults to disabled
The truncation strategy to use for the model response.
  * `auto`: If the input to this Response exceeds the model's context window size, the model will truncate the response to fit the context window by dropping items from the beginni

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.claude.com/docs/en/about-claude/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 2.07s 
[SCRAPE].. ‚óÜ https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 0.04s 
[COMPLETE] ‚óè https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 2.12s 
### Cookie settings
We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).
CustomizeCustomize Cookie SettingsRejectReject All CookiesAcceptAccept All Cookies
[](https://platform.claude.com/docs/en/home)
  * [Developer Guide](https://platform.claude.com/docs/en/intro)
  * [API Reference](https://platform.claude.com/docs/en/api/overview)
  * [MCP](https://modelcontextprotocol.io)
  * [Resources](https://platform.claude.com/docs/en/resources/overview)
  * [Release Notes](https://platform.claude.com/docs/en/release-notes/overview)


English[Log in](https://platform.claude.com/login?returnTo=%2Fdocs%2Fen%2Fabout-claude%2Fpricing)
Search...
‚åòK
First steps
[Intro to Claude](https://platform.claude.com/docs/en/intro)[Quickstart](https://platform.claude.com/docs/en/get-started)
Models & pricing
[Models overview](https://platform.claude.com/docs/en/about-claude/models/overview)[Choosing a model](https://platform.claude.com/docs/en/about-claude/models/choosing-a-model)[What's new in Claude 4.6](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)[Migration guide](https://platform.claude.com/docs/en/about-claude/models/migration-guide)[Model deprecations](https://platform.claude.com/docs/en/about-claude/model-deprecations)[Pricing](https://platform.claude.com/docs/en/about-claude/pricing)
Build with Claude
[Features overview](https://platform.claude.com/docs/en/build-with-claude/overview)[Using the Messages API](https://platform.claude.com/docs/en/build-with-claude/working-with-messages)[Handling stop reasons](https://platform.claude.com/docs/en/build-with-claude/handling-stop-reasons)[Prompting best practices](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices)
Context management
[Context windows](https://platform.claude.com/docs/en/build-with-claude/context-windows)[Compaction](https://platform.claude.com/docs/en/build-with-claude/compaction)[Context editing](https://platform.claude.com/docs/en/build-with-claude/context-editing)
Capabilities
[Prompt caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching)[Extended thinking](https://platform.claude.com/docs/en/build-with-claude/extended-thinking)[Adaptive thinking](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)[Effort](https://platform.claude.com/docs/en/build-with-claude/effort)[Fast mode (research preview)](https://platform.claude.com/docs/en/build-with-claude/fast-mode)[Streaming Messages](https://platform.claude.com/docs/en/build-with-claude/streaming)[Batch processing](https://platform.claude.com/docs/en/build-with-claude/batch-processing)[Citations](https://platform.claude.com/docs/en/build-with-claude/citations)[Multilingual support](https://platform.claude.com/docs/en/build-with-claude/multilingual-support)[Token counting](https://platform.claude.com/docs/en/build-with-claude/token-counting)[Embeddings](https://platform.claude.com/docs/en/build-with-claude/embeddings)[Vision](https://platform.claude.com/docs/en/build-with-claude/vision)[PDF support](https://platform.claude.com/docs/en/build-with-claude/pdf-support)[Files API](https://platform.claude.com/docs/en/build-with-claude/files)[Search results](https://platform.claude.com/docs/en/build-with-claude/search-results)[Structured outputs](https://platform.claude.com/docs/en/build-with-claude/structured-outputs)
Tools
[Overview](https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview)[How to implement tool use](https://platform.claude.com/docs/en/agents-and-tools/tool-use/implement-tool-use)[Fine-grained tool streaming](https://platform.claude.com/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming)[Bash tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/bash-tool)[Code execution tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool)[Programmatic tool calling](https://platform.claude.com/docs/en/agents-and-tools/tool-use/programmatic-tool-calling)[Computer use tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/computer-use-tool)[Text editor tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool)[Web fetch tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-fetch-tool)[Web search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-search-tool)[Memory tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/memory-tool)[Tool search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)
Agent Skills
[Overview](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview)[Quickstart](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/quickstart)[Best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices)[Skills for enterprise](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/enterprise)[Using Skills with the API](https://platform.claude.com/docs/en/build-with-claude/skills-guide)
Agent SDK
[Overview](https://platform.claude.com/docs/en/agent-sdk/overview)[Quickstart](https://platform.claude.com/docs/en/agent-sdk/quickstart)[TypeScript SDK](https://platform.claude.com/docs/en/agent-sdk/typescript)[TypeScript V2 (preview)](https://platform.claude.com/docs/en/agent-sdk/typescript-v2-preview)[Python SDK](https://platform.claude.com/docs/en/agent-sdk/python)[Migration Guide](https://platform.claude.com/docs/en/agent-sdk/migration-guide)
Guides
MCP in the API
[MCP connector](https://platform.claude.com/docs/en/agents-and-tools/mcp-connector)[Remote MCP servers](https://platform.claude.com/docs/en/agents-and-tools/remote-mcp-servers)
Claude on 3rd-party platforms
[Amazon Bedrock](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock)[Microsoft Foundry](https://platform.claude.com/docs/en/build-with-claude/claude-in-microsoft-foundry)[Vertex AI](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai)
Prompt engineering
[Overview](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview)[Prompt generator](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-generator)[Use prompt templates](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-templates-and-variables)[Prompt improver](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-improver)[Be clear and direct](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)[Use examples (multishot prompting)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/multishot-prompting)[Let Claude think (CoT)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought)[Use XML tags](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags)[Give Claude a role (system prompts)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/system-prompts)[Chain complex prompts](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-prompts)[Long context tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/long-context-tips)[Extended thinking tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips)
Test & evaluate
[Define success criteria](https://platform.claude.com/docs/en/test-and-evaluate/define-success)[Develop test cases](https://platform.claude.com/docs/en/test-and-evaluate/develop-tests)[Using the Evaluation Tool](https://platform.claude.com/docs/en/test-and-evaluate/eval-tool)[Reducing latency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-latency)
Strengthen guardrails
[Reduce hallucinations](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-hallucinations)[Increase output consistency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/increase-consistency)[Mitigate jailbreaks](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)[Streaming refusals](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals)[Reduce prompt leak](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak)[Keep Claude in character](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/keep-claude-in-character)
Administration and monitoring
[Admin API overview](https://platform.claude.com/docs/en/build-with-claude/administration-api)[Data residency](https://platform.claude.com/docs/en/build-with-claude/data-residency)[Workspaces](https://platform.claude.com/docs/en/build-with-claude/workspaces)[Usage and Cost API](https://platform.claude.com/docs/en/build-with-claude/usage-cost-api)[Claude Code Analytics API](https://platform.claude.com/docs/en/build-with-claude/claude-code-analytics-api)[Zero Data Retention](https://platform.claude.com/docs/en/build-with-claude/zero-data-retention)
[Console](https://platform.claude.com/)
[Log in](https://platform.claude.com/login)
Models & pricingPricing
Models & pricing
# Pricing
Copy page
Learn about Anthropic's pricing structure for models and features
Copy page
This page provides detailed pricing information for Anthropic's models and features. All prices are in USD.
For the most current pricing information, please visit [claude.com/pricing](https://claude.com/pricing).
## 
Model pricing
The following table shows pricing for all Claude models across different usage tiers:
Model | Base Input Tokens | 5m Cache Writes | 1h Cache Writes | Cache Hits & Refreshes | Output Tokens  
---|---|---|---|---|---  
Claude Opus 4.6 | $5 / MTok | $6.25 / MTok | $10 / MTok | $0.50 / MTok | $25 / MTok  
Claude Opus 4.5 | $5 / MTok | $6.25 / MTok | $10 / MTok | $0.50 / MTok | $25 / MTok  
Claude Opus 4.1 | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Opus 4 | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Sonnet 4.5 | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Sonnet 4 | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Sonnet 3.7 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Haiku 4.5 | $1 / MTok | $1.25 / MTok | $2 / MTok | $0.10 / MTok | $5 / MTok  
Claude Haiku 3.5 | $0.80 / MTok | $1 / MTok | $1.6 / MTok | $0.08 / MTok | $4 / MTok  
Claude Opus 3 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Haiku 3 | $0.25 / MTok | $0.30 / MTok | $0.50 / MTok | $0.03 / MTok | $1.25 / MTok  
MTok = Million tokens. The "Base Input Tokens" column shows standard input pricing, "Cache Writes" and "Cache Hits" are specific to [prompt caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching), and "Output Tokens" shows output pricing. Prompt caching offers both 5-minute (default) and 1-hour cache durations to optimize costs for different use cases.
The table above reflects the following pricing multipliers for prompt caching:
  * 5-minute cache write tokens are 1.25 times the base input tokens price
  * 1-hour cache write tokens are 2 times the base input tokens price
  * Cache read tokens are 0.1 times the base input tokens price


## 
Third-party platform pricing
Claude models are available on [AWS Bedrock](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock), [Google Vertex AI](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai), and [Microsoft Foundry](https://platform.claude.com/docs/en/build-with-claude/claude-in-microsoft-foundry). For official pricing, visit:
  * [AWS Bedrock pricing](https://aws.amazon.com/bedrock/pricing/)
  * [Google Vertex AI pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing)
  * [Microsoft Foundry pricing](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing)


**Regional endpoint pricing for Claude 4.5 models and beyond**
Starting with Claude Sonnet 4.5 and Haiku 4.5, AWS Bedrock and Google Vertex AI offer two endpoint types:
  * **Global endpoints** : Dynamic routing across regions for maximum availability
  * **Regional endpoints** : Data routing guaranteed within specific geographic regions


Regional endpoints include a 10% premium over global endpoints. **The Claude API (1P) is global by default and unaffected by this change.** The Claude API is global-only (equivalent to the global endpoint offering and pricing from other providers).
**Scope** : This pricing structure applies to Claude Sonnet 4.5, Haiku 4.5, and all future models. Earlier models (Claude Sonnet 4, Opus 4, and prior releases) retain their existing pricing.
For implementation details and code examples:
  * [AWS Bedrock global vs regional endpoints](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock#global-vs-regional-endpoints)
  * [Google Vertex AI global vs regional endpoints](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai#global-vs-regional-endpoints)


## 
Feature-specific pricing
### 
Data residency pricing
For Claude Opus 4.6 and newer models, specifying US-only inference via the `inference_geo` parameter incurs a 1.1x multiplier on all token pricing categories, including input tokens, output tokens, cache writes, and cache reads. Global routing (the default) uses standard pricing.
This applies to the Claude API (1P) only. Third-party platforms have their own regional pricing. See [AWS Bedrock](https://aws.amazon.com/bedrock/pricing/), [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/pricing), and [Microsoft Foundry](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing) for details. Earlier models retain their existing pricing regardless of `inference_geo` settings.
For more information, see the [data residency documentation](https://platform.claude.com/docs/en/build-with-claude/data-residency).
### 
Fast mode pricing
[Fast mode](https://platform.claude.com/docs/en/build-with-claude/fast-mode) for Claude Opus 4.6 (resesarch preview) provides significantly faster output at premium pricing (6x standard rates). Currently supported on Opus 4.6:
Context window | Input | Output  
---|---|---  
‚â§ 200K input tokens | $30 / MTok | $150 / MTok  
> 200K input tokens | $60 / MTok | $225 / MTok  
Fast mode pricing stacks with other pricing modifiers:
  * [Prompt caching multipliers](https://platform.claude.com/docs/en/about-claude/pricing#model-pricing) apply on top of fast mode pricing
  * [Data residency](https://platform.claude.com/docs/en/build-with-claude/data-residency) multipliers apply on top of fast mode pricing


Fast mode is not available with the [Batch API](https://platform.claude.com/docs/en/about-claude/pricing#batch-processing).
For more information, see the [fast mode documentation](https://platform.claude.com/docs/en/build-with-claude/fast-mode).
### 
Batch processing
The Batch API allows asynchronous processing of large volumes of requests with a 50% discount on both input and output tokens.
Model | Batch input | Batch output  
---|---|---  
Claude Opus 4.6 | $2.50 / MTok | $12.50 / MTok  
Claude Opus 4.5 | $2.50 / MTok | $12.50 / MTok  
Claude Opus 4.1 | $7.50 / MTok | $37.50 / MTok  
Claude Opus 4 | $7.50 / MTok | $37.50 / MTok  
Claude Sonnet 4.5 | $1.50 / MTok | $7.50 / MTok  
Claude Sonnet 4 | $1.50 / MTok | $7.50 / MTok  
Claude Sonnet 3.7 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $1.50 / MTok | $7.50 / MTok  
Claude Haiku 4.5 | $0.50 / MTok | $2.50 / MTok  
Claude Haiku 3.5 | $0.40 / MTok | $2 / MTok  
Claude Opus 3 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $7.50 / MTok | $37.50 / MTok  
Claude Haiku 3 | $0.125 / MTok | $0.625 / MTok  
For more information about batch processing, see the [batch processing documentation](https://platform.claude.com/docs/en/build-with-claude/batch-processing).
### 
Long context pricing
When using Claude Opus 4.6, Sonnet 4.5, or Sonnet 4 with the [1M token context window enabled](https://platform.claude.com/docs/en/build-with-claude/context-windows#1m-token-context-window), requests that exceed 200K input tokens are automatically charged at premium long context rates:
The 1M token context window is currently in beta for organizations in [usage tier](https://platform.claude.com/docs/en/api/rate-limits) 4 and organizations with custom rate limits. The 1M token context window is only available for Claude Opus 4.6, Sonnet 4.5, and Sonnet 4.
Model | ‚â§ 200K input tokens | > 200K input tokens  
---|---|---  
Claude Opus 4.6 | Input: $5 / MTok | Input: $10 / MTok  
| Output: $25 / MTok | Output: $37.50 / MTok  
Claude Sonnet 4.5 / 4 | Input: $3 / MTok | Input: $6 / MTok  
| Output: $15 / MTok | Output: $22.50 / MTok  
Long context pricing stacks with other pricing modifiers:
  * The [Batch API 50% discount](https://platform.claude.com/docs/en/about-claude/pricing#batch-processing) applies to long context pricing
  * [Prompt caching multipliers](https://platform.claude.com/docs/en/about-claude/pricing#model-pricing) apply on top of long context pricing
  * The [data residency 1.1x multiplier](https://platform.claude.com/docs/en/about-claude/pricing#data-residency-pricing) applies on top of long context pricing


Even with the beta flag enabled, requests with fewer than 200K input tokens are charged at standard rates. If your request exceeds 200K input tokens, all tokens incur premium pricing.
The 200K threshold is based solely on input tokens (including cache reads/writes). Output token count does not affect pricing tier selection, though output tokens are charged at the higher rate when the input threshold is exceeded.
To check if your API request was charged at the 1M context window rates, examine the `usage` object in the API response:
```
{
  "usage": {
    "input_tokens": 250000,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "output_tokens": 500
  }
}
```

Calculate the total input tokens by summing:
  * `input_tokens`
  * `cache_creation_input_tokens` (if using prompt caching)
  * `cache_read_input_tokens` (if using prompt caching)


If the total exceeds 200,000 tokens, the entire request was billed at 1M context rates.
For more information about the `usage` object, see the [API response documentation](https://platform.claude.com/docs/en/api/messages#response-usage).
### 
Tool use pricing
Tool use requests are priced based on:
  1. The total number of input tokens sent to the model (including in the `tools` parameter)
  2. The number of output tokens generated
  3. For server-side tools, additional usage-based pricing (e.g., web search charges per search performed)


Client-side tools are priced the same as any other Claude API request, while server-side tools may incur additional charges based on their specific usage.
The additional tokens from tool use come from:
  * The `tools` parameter in API requests (tool names, descriptions, and schemas)
  * `tool_use` content blocks in API requests and responses
  * `tool_result` content blocks in API requests


When you use `tools`, we also automatically include a special system prompt for the model which enables tool use. The number of tool use tokens required for each model are listed below (excluding the additional tokens listed above). Note that the table assumes




>>>TOOL web_fetch
{"url":"https://openai.com/api/pricing/","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://openai.com/api/pricing/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 2.34s 
[SCRAPE].. ‚óÜ https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 0.04s 
[COMPLETE] ‚óè https://openai.com/api/pricing/                                    
| ‚úì | ‚è±: 2.39s 
[Skip to main content](https://openai.com/api/pricing/#main)
Log in
[](https://openai.com/)
Switch to
  * [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Sora(opens in a new window)](https://sora.com/)
  * [API Platform(opens in a new window)](https://platform.openai.com/)


[Home](https://openai.com/)
  * [API Platform](https://openai.com/api/)
  * [API Pricing](https://openai.com/api/pricing/)
  * [Agents](https://openai.com/agent-platform/)
  * [Codex](https://openai.com/codex/)
  * [Open Models](https://openai.com/open-models/)
  * [Community(opens in a new window)](https://community.openai.com/)


  * Research
Back to main menu
    * [Research Index](https://openai.com/research/index/)
    * [Research Overview](https://openai.com/research/)
    * [Research Residency](https://openai.com/residency/)
    * [OpenAI for Science](https://openai.com/science/)
    * Latest Advancements
    * [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)
    * [GPT-5.1](https://openai.com/index/gpt-5-1/)
    * [Sora 2](https://openai.com/index/sora-2/)
    * [GPT-5](https://openai.com/index/introducing-gpt-5/)
    * [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)
    * [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)
  * Safety
Back to main menu
    * [Safety Approach](https://openai.com/safety/)
    * [Security & Privacy](https://openai.com/security-and-privacy/)
  * For Business
Back to main menu
    * [Business Overview](https://openai.com/business/)
    * [Enterprise](https://openai.com/business/frontier/)
    * [Startups](https://openai.com/startups/)
    * [Solutions](https://openai.com/solutions/)
    * [Learn](https://openai.com/business/learn/)
    * [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)
    * [API Pricing](https://openai.com/api/pricing/)
    * [Contact Sales](https://openai.com/contact-sales/)
  * For Developers
Back to main menu
    * [API Platform](https://openai.com/api/)
    * [API Pricing](https://openai.com/api/pricing/)
    * [Agents](https://openai.com/agent-platform/)
    * [Codex](https://openai.com/codex/)
    * [Open Models](https://openai.com/open-models/)
    * [Community(opens in a new window)](https://community.openai.com/)
  * [ChatGPT](https://chatgpt.com/overview?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
Back to main menu
    * [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
    * [Business](https://chatgpt.com/for-business/team?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
    * [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
    * [Education](https://chatgpt.com/for-business/education?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
    * [Pricing](https://chatgpt.com/pricing?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
    * [Download](https://chatgpt.com/download?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Sora](https://openai.com/sora/)
  * [Codex](https://openai.com/codex/)
  * [Stories](https://openai.com/stories/)
  * Company
Back to main menu
    * [About Us](https://openai.com/about/)
    * [Our Charter](https://openai.com/charter/)
    * [Foundation](https://openai.com/foundation/)
    * [Careers](https://openai.com/careers/)
    * [Brand Guidelines](https://openai.com/brand/)
  * [News](https://openai.com/news/company-announcements/)


Log in
Pricing | OpenAI
# API Pricing
[Contact sales](https://openai.com/contact-sales/)
## Flagship models
Our frontier models are designed to spend more time thinking before producing a response, making them ideal for complex, multi-step problems.
## GPT-5.2
The best model for coding and agentic tasks across industries
### Price
Input:  
$1.750 / 1M tokens
Cached input:  
$0.175 / 1M tokens
Output:  
$14.000 / 1M tokens
## GPT-5.2 pro
The smartest and most precise model
### Price
Input:  
$21.00 / 1M tokens
Cached input:  
-
Output:  
$168.00 / 1M tokens
## GPT-5 mini
A faster, cheaper version of GPT-5 for well-defined tasks
### Price
Input:  
$0.250 / 1M tokens
Cached input:  
$0.025 / 1M tokens
Output:  
$2.000 / 1M tokens
Pricing reflects standard processing rates. To optimize cost and performance for different use cases, we also offer:
  * [**_Batch API‚Å†_** ‚Å†(opens in a new window)](https://platform.openai.com/docs/guides/batch): Save 50% on inputs and outputs with the Batch API and run tasks asynchronously over 24 hours.
  * [**_Priority processing_****‚Å†** ‚Å†](https://openai.com/api-priority-processing/): offers reliable, high-speed performance with the flexibility to pay-as-you-go.


### Fine-tuning our models
Customize our models to get even higher performance for your specific use cases.
## GPT-4.1
### Fine-tuning price
Input:  
$3.00 / 1M tokens
Cached input:  
$0.75 / 1M tokens
Output:  
$12.00 / 1M tokens
Training:  
$25.00 / 1M tokens
## GPT-4.1 mini
### Fine-tuning price
Input:  
$0.80 / 1M tokens
Cached input:  
$0.20 / 1M tokens
Output:  
$3.20 / 1M tokens
Training:  
$5.00 / 1M tokens
## GPT-4.1 nano
### Fine-tuning price
Input:  
$0.20 / 1M tokens
Cached input:  
$0.05 / 1M tokens
Output:  
$0.80 / 1M tokens
Training:  
$1.50 / 1M tokens
## o4-mini
### Reinforcement fine-tuning price
Input:  
$4.00 / 1M tokens
Cached input:  
$1.00 / 1M tokens
Output:  
$16.00 / 1M tokens
Training:  
$100.00 / training hour
  * [Explore detailed pricing(opens in a new window)](https://platform.openai.com/docs/pricing)


## Our APIs
## Realtime API
Build low-latency, multimodal experiences including speech-to-speech.
### Text
Text
gpt-realtime
$4.00 / 1M input tokens
$0.40 / 1M cached input tokens
$16.00 / 1M output tokens
gpt-realtime
$4.00 / 1M input tokens
$0.40 / 1M cached input tokens
$16.00 / 1M output tokens
gpt-realtime-mini
$0.60 / 1M input tokens
$0.06 / 1M cached input tokens
$2.40 / 1M output tokens
gpt-realtime-mini
$0.60 / 1M input tokens
$0.06 / 1M cached input tokens
$2.40 / 1M output tokens
### Audio
Audio
gpt-realtime
$32.00 / 1M input tokens
$0.40 / 1M cached input tokens
$64.00 / 1M output tokens
gpt-realtime
$32.00 / 1M input tokens
$0.40 / 1M cached input tokens
$64.00 / 1M output tokens
gpt-realtime-mini
$10.00 / 1M input tokens
$0.30 / 1M cached input tokens
$20.00 / 1M output tokens
gpt-realtime-mini
$10.00 / 1M input tokens
$0.30 / 1M cached input tokens
$20.00 / 1M output tokens
### Image
Image
gpt-realtime
$5.00 / 1M input tokens
$0.50 / 1M cached input tokens
-
gpt-realtime
$5.00 / 1M input tokens
$0.50 / 1M cached input tokens
-
gpt-realtime-mini
$0.80 / 1M input tokens
$0.08 / 1M cached input tokens
-
gpt-realtime-mini
$0.80 / 1M input tokens
$0.08 / 1M cached input tokens
-
## Sora Video API
Richly detailed, dynamic video generation and remixing with our latest generative model.
Models | Size | Price per second  
---|---|---  
sora-2 |  Portrait: 720 x 1280 Landscape: 1280 x 720 | $0.10  
sora-2-pro |  Portrait: 720 x 1280 Landscape: 1280 x 720 | $0.30  
sora-2-pro |  Portrait: 1024 x 1792 Landscape: 1792 x 1024 | $0.50  
## Image Generation API
Precise, high-fidelity image generation and editing with our latest multimodal model.
### Text
Text
GPT-image-1.5
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
$10.00 / 1M output tokens*
GPT-image-1.5
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
$10.00 / 1M output tokens*
GPT-image-1
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
-
GPT-image-1
$5.00 / 1M input tokens
$1.25 / 1M cached input tokens*
-
GPT-image-1-mini
$2.00 / 1M input tokens
$0.20 / 1M cached input tokens*
-
GPT-image-1-mini
$2.00 / 1M input tokens
$0.20 / 1M cached input tokens*
-
### Image
Image
GPT-image-1.5
$8.00 / 1M input tokens
$2.00 / 1M cached input tokens*
$32.00 / 1M output tokens
GPT-image-1.5
$8.00 / 1M input tokens
$2.00 / 1M cached input tokens*
$32.00 / 1M output tokens
GPT-image-1
$10.00 / 1M input tokens
$2.50 / 1M cached input tokens*
$40.00 / 1M output tokens
GPT-image-1
$10.00 / 1M input tokens
$2.50 / 1M cached input tokens*
$40.00 / 1M output tokens
GPT-image-1-mini
$2.50 / 1M input tokens
$0.25 / 1M cached input tokens*
$8.00 / 1M output tokens
GPT-image-1-mini
$2.50 / 1M input tokens
$0.25 / 1M cached input tokens*
$8.00 / 1M output tokens
Prompts are billed similarly to other GPT models. Image outputs cost approximately $0.01 (low), $0.04 (medium), and $0.17 (high) for square images.
*available via the Responses API
*text output tokens include model reasoning tokens
For detailed token usage by image quality and size, see the [docs](https://platform.openai.com/docs/pricing).
## Responses API
Our newest API combining the simplicity of Chat Completions with the built-in tool use of Assistants.
Price
Responses API is not priced separately. Tokens are billed at the chosen language model‚Äôs input and output rates.
## Chat Completions API
Build text-based conversational experiences.
Price
Chat Completions API is not priced separately. Tokens are billed at the chosen language model's input and output rates.
## Assistants API
Build assistant-like experiences with our tools.
Price
Assistants API is not priced separately. Tokens are billed at the chosen language model's input and output rates.
## Built-in tools
Extend model capabilities with built-in tools in the API Platform.
Tool
Cost
Code Interpreter
$0.03 / session
File Search Storage
$0.10 / GB of vector storage per day (first GB free)
File Search Tool Call   
(Responses API only)
$2.50 / 1k tool calls
Web Search Tool Call
There are two components that contribute to the cost of using the web search tool: (1) Tool calls and (2) Search content tokens.
  * Tool calls are billed per 1,000 calls, according to the tool version and model type.
  * Search content tokens are tokens retrieved from the search index and fed to the model alongside your prompt to generate an answer. These are billed at the model‚Äôs input token rate, unless otherwise specified.


Tool Version | Cost  
---|---  
Web search (all models) | $10.00 / 1K calls + search content tokens billed at model rates1  
Web search preview (reasoning models) | $10.00 / 1K calls + search content tokens billed at model rates  
Web search preview (non-reasoning models) | $25.00 / 1K calls + search content tokens are free  
1For gpt-4o-mini and gpt-4.1-mini with the web search non-preview tool, search content tokens are charged as a fixed block of 8,000 input tokens per call.
The billing dashboard will report gpt-4.1 and gpt-4.1-mini search line items as ‚Äòweb search tool calls | gpt-4o‚Äô and ‚Äòweb search tool calls | gpt-4o-mini‚Äô
GB refers to binary gigabytes of storage (also known as gibibyte), where 1GB is 2^30 bytes.
## AgentKit
Build, deploy, and optimize production-grade agents with Agent Builder, ChatKit, and Evals.
Billing
Begins on November 1, 2025 ‚Äî no charges will apply before then.
Usage meter
Storage for ChatKit File / Image Uploads.
Free tier (per account, per month)
1 GB
Price beyond free tier
$0.10 / GB-day
What‚Äôs always free
Agent Builder ‚Äì design and iterate with zero cost until you hit Run. Self-hosted ChatKit ‚Äì host a custom ChatKit backend and pay only normal model-token charges. Enterprise controls ‚Äì SSO, RBAC, and audit logs are included at no additional fee.
  * [Explore detailed pricing(opens in a new window)](https://platform.openai.com/docs/pricing)


Explore our offerings for Enterprise customers: [**_Priority processing_** ‚Å†](https://openai.com/api-priority-processing/), [**_Scale Tier_** _‚Å†_ ‚Å†](https://openai.com/api-scale-tier/) and [**_Reserved Capacity_** _‚Å†_ ‚Å†](https://openai.com/reserved-capacity/).
### FAQ
### Which model should I use?
We recommend that developers use our large and mini GPT models for everyday tasks. Our large GPT models generally perform better on a wide range of tasks, while our mini GPT models are fast and inexpensive for simpler tasks.
Our large and mini reasoning models are ideal for complex, multi-step tasks and STEM use cases that require deep thinking about tough problems. You can choose the mini reasoning model if you're looking for a faster, more inexpensive option.
We recommend experimenting with all of these models in the [Playground‚Å†‚Å†(opens in a new window)](https://platform.openai.com/playground) to explore which models provide the best price performance trade-off for your usage.
### Do you offer an enterprise package or SLAs?
We offer different tiers of access to our enterprise customers that include SLAs, lower latency, and more. Please [_contact our sales team_ ‚Å†](https://openai.com/contact-sales/) to learn more.
### Will I be charged for API usage in the Playground? 
Yes, we treat Playground usage the same as regular API usage. You will be billed at the per-token input and output prices mentioned above.
### How will I know how many tokens I‚Äôve used each month?
A token is a mathematical representation of natural language. Log in to your account to view your [_usage tracking dashboard_ ‚Å†(opens in a new window)](https://platform.openai.com/account/usage). This dashboard will show you how many tokens you‚Äôve used during the current and past billing cycles.
### How can I manage my spending on the API platform?
You can set a monthly budget in [_your billing settings‚Å†_ ‚Å†(opens in a new window)](https://platform.openai.com/settings/organization/limits), after which we‚Äôll stop serving your requests. There may be a delay in enforcing the limit, and you are responsible for any overage incurred. You can also configure an email notification threshold to receive an email alert once you cross that threshold each month. We recommend checking your [_usage tracking dashboard_ ‚Å†(opens in a new window)](https://platform.openai.com/account/usage) regularly to monitor your spend.
For customers managing work with Projects, you can [_set and manage billing restrictions per project_ ‚Å†(opens in a new window)](https://help.openai.com/en/articles/9186755-managing-your-work-in-the-api-platform-with-projects)‚Å† in the Dashboard.
### Is access to the API included in ChatGPT Plus, Business, Enterprise or Edu?
No, OpenAI APIs are billed separately from ChatGPT Plus, Business, Enterprise and Edu. ChatGPT subscription pricing can be found at [_openai.com/chatgpt/pricing/_ ‚Å†](http://openai.com/chatgpt/pricing/). 
### How is pricing calculated for images?
Images are converted into tokens and charged per token. Text models price image tokens at standard text token rates, while GPT Image and gpt-realtime uses a separate image token rate. Models like gpt-4.1-mini, gpt-4.1-nano, and o4-mini convert images into tokens differently. [Learn more in our docs‚Å†(opens in a new window)](https://platform.openai.com/docs/guides/images-vision?api-mode=chat#calculating-costs).
Pricing calculator
Set model
gpt-5 gpt-5.1 gpt-5.2 gpt-5-mini gpt-5-nano gpt-5-chat-latest gpt-4.1 gpt-4.1-mini gpt-4.1-nano o3 o3-deep-research o3-pro-2025-06-10 o4-mini o4-mini-deep-research o1 o1-pro gpt-4o gpt-4o-2024-05-13 gpt-4o-mini computer-use-preview gpt-4.5-preview codex-mini-latest gpt-5-codex
Set width
px
by
Set height
px
=$0.000263
Low resolution
=$0.000263
Price per 1M tokens (fixed) | $1.25  
---|---  
512 √ó 512 tiles | 1 √ó 1  
Total tiles | 1  
Base tokens | 70  
Tile tokens | 140 √ó 1 = 140  
Total tokens | 210  
Total price | $0.000263  
## Start creating with OpenAI‚Äôs powerful models.
[Get started(opens in a new window)](https://platform.openai.com/)[Contact sales](https://openai.com/contact-sales/)
Our Research
  * [Research Index](https://openai.com/research/index/)
  * [Research Overview](https://openai.com/research/)
  * [Research Residency](https://openai.com/residency/)
  * [OpenAI for Science](https://openai.com/science/)


Latest Advancements
  * [GPT-5](https://openai.com/gpt-5/)
  * [Codex](https://openai.com/index/introducing-gpt-5-3-codex/)
  * [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)
  * [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)
  * [GPT-4o](https://openai.com/index/gpt-4o-system-card/)
  * [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
  * [Sora](https://openai.com/index/sora-system-card/)


Safety
  * [Safety Approach](https://openai.com/safety/)
  * [Security & Privacy](https://openai.com/security-and-privacy/)
  * [Trust & Transparency](https://openai.com/trust-and-transparency/)


ChatGPT
  * [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Business](https://chatgpt.com/business/business-plan?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Education](https://chatgpt.com/business/education?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)
  * [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=869a9960-15e3-4a8a-8e65-bc37307cbe64&openaicom_referred=true)


Sora
  * [Sora Overview](https://openai.com/sora/)
  * [Features](https://openai.com/sora/#features)
  * [Pricing](https://openai.com/sora/#pricing)
  * [Sora log in(opens in a new window)](https://sora.com/)


API Platform
  * [Platform Overview](https://openai.com/api/)
  * [Pricing](https://openai.com/api/pricing/)
  * [API log in(opens in a new window)](https://platform.openai.com/login)
  * [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)
  * [Developer Forum(opens in a new window)](https://community.openai.com/)


For Business
  * [Business Overview](https://openai.com/business/)
  * [Solutions](https://openai.com/solutions/)
  * [Contact Sales](https://openai.com/contact-sales/)


Company
  * [About Us](https://openai.com/about/)
  * [Our Charter](https://openai.com/charter/)
  * [Foundation](https://openai.com/foundation/)
  * [Careers](https://openai.com/careers/)
  * [Brand](https://openai.com/brand/)


Support
  * [Help Center(opens in a new window)](https://help.openai.com/)


More
  * [News](https://openai.com/news/)
  * [Stories](https://openai.com/stories/)
  * [Livestreams](https://openai.com/live/)
  * [Podcast](https://openai.com/podcast/)
  * [RSS](https://openai.com/news/rss.xml)


Terms & Policies
  * [Terms of Use](https://openai.com/policies/terms-of-use/)
  * [Privacy Policy](https://openai.com/policies/privacy-policy/)
  * [Other Policies ](https://openai.com/policies/)


[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)
OpenAI ¬© 2015‚Äì2026Manage Cookies
EnglishUnited States
We use cookies
We use cookies to help this site function, understand service usage, and support marketing efforts. Visit Manage Cookies to change preferences anytime. View our [Cookie Policy](https://openai.com/policies/cookie-policy/) for more info.
Manage CookiesReject non-essentialAccept all


>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/api-reference/responses","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/models/gpt-4o","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/models/o1","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/models/o3","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/pricing                           
| ‚úì | ‚è±: 1.33s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/pricing                           
| ‚úì | ‚è±: 0.04s 
[COMPLETE] ‚óè https://platform.openai.com/docs/pricing                           
| ‚úì | ‚è±: 1.37s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
Get started
[Overview](https://platform.openai.com/docs/overview)
[Quickstart](https://platform.openai.com/docs/quickstart)
[Models](https://platform.openai.com/docs/models)
[Pricing](https://platform.openai.com/docs/pricing)
[Libraries](https://platform.openai.com/docs/libraries)
[Docs MCP](https://platform.openai.com/docs/docs-mcp)
[Latest: GPT-5.2](https://platform.openai.com/docs/guides/latest-model)
Core concepts
[Text generation](https://platform.openai.com/docs/guides/text)
[Code generation](https://platform.openai.com/docs/guides/code-generation)
[Images and vision](https://platform.openai.com/docs/guides/images-vision)
[Audio and speech](https://platform.openai.com/docs/guides/audio)
[Structured output](https://platform.openai.com/docs/guides/structured-outputs)
[Function calling](https://platform.openai.com/docs/guides/function-calling)
[Responses API](https://platform.openai.com/docs/guides/migrate-to-responses)
Agents
[Overview](https://platform.openai.com/docs/guides/agents)
Build agents
Deploy in your product
Optimize
[Voice agents](https://platform.openai.com/docs/guides/voice-agents)
Tools
[Using tools](https://platform.openai.com/docs/guides/tools)
[Connectors and MCP](https://platform.openai.com/docs/guides/tools-connectors-mcp)
[Web search](https://platform.openai.com/docs/guides/tools-web-search)
[Code interpreter](https://platform.openai.com/docs/guides/tools-code-interpreter)
File search and retrieval
More tools
Run and scale
[Conversation state](https://platform.openai.com/docs/guides/conversation-state)
[Background mode](https://platform.openai.com/docs/guides/background)
[Streaming](https://platform.openai.com/docs/guides/streaming-responses)
[Webhooks](https://platform.openai.com/docs/guides/webhooks)
[File inputs](https://platform.openai.com/docs/guides/pdf-files)
Prompting
Reasoning
Evaluation
[Getting started](https://platform.openai.com/docs/guides/evaluation-getting-started)
[Working with evals](https://platform.openai.com/docs/guides/evals)
[Prompt optimizer](https://platform.openai.com/docs/guides/prompt-optimizer)
[External models](https://platform.openai.com/docs/guides/external-models)
[Best practices](https://platform.openai.com/docs/guides/evaluation-best-practices)
Realtime API
[Overview](https://platform.openai.com/docs/guides/realtime)
Connect
Usage
Model optimization
[Optimization cycle](https://platform.openai.com/docs/guides/model-optimization)
Fine-tuning
[Graders](https://platform.openai.com/docs/guides/graders)
Specialized models
[Image generation](https://platform.openai.com/docs/guides/image-generation)
[Video generation](https://platform.openai.com/docs/guides/video-generation)
[Text to speech](https://platform.openai.com/docs/guides/text-to-speech)
[Speech to text](https://platform.openai.com/docs/guides/speech-to-text)
[Deep research](https://platform.openai.com/docs/guides/deep-research)
[Embeddings](https://platform.openai.com/docs/guides/embeddings)
[Moderation](https://platform.openai.com/docs/guides/moderation)
Coding agents
[Codex cloud](https://developers.openai.com/codex/cloud)
[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)
[Codex CLI](https://developers.openai.com/codex/cli)
[Codex IDE](https://developers.openai.com/codex/ide)
[Codex changelog](https://developers.openai.com/codex/changelog)
Going live
[Production best practices](https://platform.openai.com/docs/guides/production-best-practices)
Latency optimization
Cost optimization
[Accuracy optimization](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)
Safety
Legacy APIs
Assistants API
Resources
[Terms and policies](https://openai.com/policies)
[Changelog](https://platform.openai.com/docs/changelog)
[Your data](https://platform.openai.com/docs/guides/your-data)
[Permissions](https://platform.openai.com/docs/guides/rbac)
[Rate limits](https://platform.openai.com/docs/guides/rate-limits)
[Deprecations](https://platform.openai.com/docs/deprecations)
[MCP for deep research](https://platform.openai.com/docs/mcp)
[Developer mode](https://platform.openai.com/docs/guides/developer-mode)
ChatGPT Actions
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
# Pricing
Copy page
Text tokens
Prices per 1M tokens.
BatchFlexStandardPriority
Batch
Model | Input | Cached input | Output  
---|---|---|---  
gpt-5.2 | $0.875 | $0.0875 | $7.00  
gpt-5.1 | $0.625 | $0.0625 | $5.00  
gpt-5 | $0.625 | $0.0625 | $5.00  
gpt-5-mini | $0.125 | $0.0125 | $1.00  
gpt-5-nano | $0.025 | $0.0025 | $0.20  
gpt-5.2-pro | $10.50 | - | $84.00  
gpt-5-pro | $7.50 | - | $60.00  
gpt-4.1 | $1.00 | - | $4.00  
gpt-4.1-mini | $0.20 | - | $0.80  
gpt-4.1-nano | $0.05 | - | $0.20  
gpt-4o | $1.25 | - | $5.00  
gpt-4o-2024-05-13 | $2.50 | - | $7.50  
gpt-4o-mini | $0.075 | - | $0.30  
o1 | $7.50 | - | $30.00  
o1-pro | $75.00 | - | $300.00  
o3-pro | $10.00 | - | $40.00  
o3 | $1.00 | - | $4.00  
o3-deep-research | $5.00 | - | $20.00  
o4-mini | $0.55 | - | $2.20  
o4-mini-deep-research | $1.00 | - | $4.00  
o3-mini | $0.55 | - | $2.20  
o1-mini | $0.55 | - | $2.20  
computer-use-preview | $1.50 | - | $6.00  
Flex
Model | Input | Cached input | Output  
---|---|---|---  
gpt-5.2 | $0.875 | $0.0875 | $7.00  
gpt-5.1 | $0.625 | $0.0625 | $5.00  
gpt-5 | $0.625 | $0.0625 | $5.00  
gpt-5-mini | $0.125 | $0.0125 | $1.00  
gpt-5-nano | $0.025 | $0.0025 | $0.20  
o3 | $1.00 | $0.25 | $4.00  
o4-mini | $0.55 | $0.138 | $2.20  
Standard
Model | Input | Cached input | Output  
---|---|---|---  
gpt-5.2 | $1.75 | $0.175 | $14.00  
gpt-5.1 | $1.25 | $0.125 | $10.00  
gpt-5 | $1.25 | $0.125 | $10.00  
gpt-5-mini | $0.25 | $0.025 | $2.00  
gpt-5-nano | $0.05 | $0.005 | $0.40  
gpt-5.2-chat-latest | $1.75 | $0.175 | $14.00  
gpt-5.1-chat-latest | $1.25 | $0.125 | $10.00  
gpt-5-chat-latest | $1.25 | $0.125 | $10.00  
gpt-5.2-codex | $1.75 | $0.175 | $14.00  
gpt-5.1-codex-max | $1.25 | $0.125 | $10.00  
gpt-5.1-codex | $1.25 | $0.125 | $10.00  
gpt-5-codex | $1.25 | $0.125 | $10.00  
gpt-5.2-pro | $21.00 | - | $168.00  
gpt-5-pro | $15.00 | - | $120.00  
gpt-4.1 | $2.00 | $0.50 | $8.00  
gpt-4.1-mini | $0.40 | $0.10 | $1.60  
gpt-4.1-nano | $0.10 | $0.025 | $0.40  
gpt-4o | $2.50 | $1.25 | $10.00  
gpt-4o-2024-05-13 | $5.00 | - | $15.00  
gpt-4o-mini | $0.15 | $0.075 | $0.60  
gpt-realtime | $4.00 | $0.40 | $16.00  
gpt-realtime-mini | $0.60 | $0.06 | $2.40  
gpt-4o-realtime-preview | $5.00 | $2.50 | $20.00  
gpt-4o-mini-realtime-preview | $0.60 | $0.30 | $2.40  
gpt-audio | $2.50 | - | $10.00  
gpt-audio-mini | $0.60 | - | $2.40  
gpt-4o-audio-preview | $2.50 | - | $10.00  
gpt-4o-mini-audio-preview | $0.15 | - | $0.60  
o1 | $15.00 | $7.50 | $60.00  
o1-pro | $150.00 | - | $600.00  
o3-pro | $20.00 | - | $80.00  
o3 | $2.00 | $0.50 | $8.00  
o3-deep-research | $10.00 | $2.50 | $40.00  
o4-mini | $1.10 | $0.275 | $4.40  
o4-mini-deep-research | $2.00 | $0.50 | $8.00  
o3-mini | $1.10 | $0.55 | $4.40  
o1-mini | $1.10 | $0.55 | $4.40  
gpt-5.1-codex-mini | $0.25 | $0.025 | $2.00  
codex-mini-latest | $1.50 | $0.375 | $6.00  
gpt-5-search-api | $1.25 | $0.125 | $10.00  
gpt-4o-mini-search-preview | $0.15 | - | $0.60  
gpt-4o-search-preview | $2.50 | - | $10.00  
computer-use-preview | $3.00 | - | $12.00  
gpt-image-1.5 | $5.00 | $1.25 | $10.00  
chatgpt-image-latest | $5.00 | $1.25 | $10.00  
gpt-image-1 | $5.00 | $1.25 | -  
gpt-image-1-mini | $2.00 | $0.20 | -  
Priority
Model | Input | Cached input | Output  
---|---|---|---  
gpt-5.2 | $3.50 | $0.35 | $28.00  
gpt-5.1 | $2.50 | $0.25 | $20.00  
gpt-5 | $2.50 | $0.25 | $20.00  
gpt-5-mini | $0.45 | $0.045 | $3.60  
gpt-5.2-codex | $3.50 | $0.35 | $28.00  
gpt-5.1-codex-max | $2.50 | $0.25 | $20.00  
gpt-5.1-codex | $2.50 | $0.25 | $20.00  
gpt-5-codex | $2.50 | $0.25 | $20.00  
gpt-4.1 | $3.50 | $0.875 | $14.00  
gpt-4.1-mini | $0.70 | $0.175 | $2.80  
gpt-4.1-nano | $0.20 | $0.05 | $0.80  
gpt-4o | $4.25 | $2.125 | $17.00  
gpt-4o-2024-05-13 | $8.75 | - | $26.25  
gpt-4o-mini | $0.25 | $0.125 | $1.00  
o3 | $3.50 | $0.875 | $14.00  
o4-mini | $2.00 | $0.50 | $8.00  
For faster processing of API requests, try the [priority processing service tier](https://platform.openai.com/docs/guides/priority-processing). For lower prices with higher latency, try the [flex processing tier](https://platform.openai.com/docs/guides/flex-processing).
Large numbers of API requests which are not time-sensitive can use the [Batch API](https://platform.openai.com/docs/guides/batch) for additional savings as well.
While reasoning tokens are not visible via the API, they still occupy space in the model's context window and are billed as output tokens.
For gpt-image-1.5, Text output tokens include model reasoning tokens.
  

Image tokens
Prices per 1M tokens. Model | Input | Cached Input | Output  
---|---|---|---  
gpt-image-1.5 | $8.00 | $2.00 | $32.00  
chatgpt-image-latest | $8.00 | $2.00 | $32.00  
gpt-image-1 | $10.00 | $2.50 | $40.00  
gpt-image-1-mini | $2.50 | $0.25 | $8.00  
gpt-realtime | $5.00 | $0.50 | -  
gpt-realtime-mini | $0.80 | $0.08 | -  
  

Audio tokens
Prices per 1M tokens. Model | Input | Cached Input | Output  
---|---|---|---  
gpt-realtime | $32.00 | $0.40 | $64.00  
gpt-realtime-mini | $10.00 | $0.30 | $20.00  
gpt-4o-realtime-preview | $40.00 | $2.50 | $80.00  
gpt-4o-mini-realtime-preview | $10.00 | $0.30 | $20.00  
gpt-audio | $32.00 | - | $64.00  
gpt-audio-mini | $10.00 | - | $20.00  
gpt-4o-audio-preview | $40.00 | - | $80.00  
gpt-4o-mini-audio-preview | $10.00 | - | $20.00  
  

Video
Prices per second. Model | Size: Output resolution | Price per second  
---|---|---  
sora-2 | Portrait: 720x1280 Landscape: 1280x720 | $0.10  
sora-2-pro | Portrait: 720x1280 Landscape: 1280x720 | $0.30  
sora-2-pro | Portrait: 1024x1792 Landscape: 1792x1024 | $0.50  
  

Fine-tuning
Prices per 1M tokens.
BatchStandard
Batch
Model | Training | Input | Cached Input | Output  
---|---|---|---|---  
o4-mini-2025-04-16 | $100.00 / hour | $2.00 | $0.50 | $8.00  
o4-mini-2025-04-16  
with data sharing | $100.00 / hour | $1.00 | $0.25 | $4.00  
gpt-4.1-2025-04-14 | $25.00 | $1.50 | $0.50 | $6.00  
gpt-4.1-mini-2025-04-14 | $5.00 | $0.40 | $0.10 | $1.60  
gpt-4.1-nano-2025-04-14 | $1.50 | $0.10 | $0.025 | $0.40  
gpt-4o-2024-08-06 | $25.00 | $2.225 | $0.90 | $12.50  
gpt-4o-mini-2024-07-18 | $3.00 | $0.15 | $0.075 | $0.60  
gpt-3.5-turbo | $8.00 | $1.50 | - | $3.00  
davinci-002 | $6.00 | $6.00 | - | $6.00  
babbage-002 | $0.40 | $0.80 | - | $0.90  
Standard
Model | Training | Input | Cached Input | Output  
---|---|---|---|---  
o4-mini-2025-04-16 | $100.00 / hour | $4.00 | $1.00 | $16.00  
o4-mini-2025-04-16  
with data sharing | $100.00 / hour | $2.00 | $0.50 | $8.00  
gpt-4.1-2025-04-14 | $25.00 | $3.00 | $0.75 | $12.00  
gpt-4.1-mini-2025-04-14 | $5.00 | $0.80 | $0.20 | $3.20  
gpt-4.1-nano-2025-04-14 | $1.50 | $0.20 | $0.05 | $0.80  
gpt-4o-2024-08-06 | $25.00 | $3.75 | $1.875 | $15.00  
gpt-4o-mini-2024-07-18 | $3.00 | $0.30 | $0.15 | $1.20  
gpt-3.5-turbo | $8.00 | $3.00 | - | $6.00  
davinci-002 | $6.00 | $12.00 | - | $12.00  
babbage-002 | $0.40 | $1.60 | - | $1.60  
Tokens used for model grading in reinforcement fine-tuning are billed at that model's per-token rate. Inference discounts are available if you enable data sharing when creating the fine-tune job. [Learn more](https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h_c93188c569).
  

Built-in tools
Tool | Cost  
---|---  
Code Interpreter | 1 GB (default): $0.03 / container  
4 GB: $0.12 / container  
16 GB: $0.48 / container  
64 GB: $1.92 / container  
File search storage | $0.10 / GB per day (1GB free)  
File search tool call   
Responses API only | $2.50 / 1k calls  
Web search (all models)   
[1] | $10.00 / 1k calls + search content tokens billed at model rates  
Web search preview (reasoning models, including gpt-5, o-series)   
| $10.00 / 1k calls + search content tokens billed at model rates  
Web search preview (non-reasoning models)   
| $25.00 / 1k calls + search content tokens are free  
The tokens used for built-in tools are billed at the chosen model's per-token rates. GB refers to binary gigabytes of storage (also known as gibibyte), where 1GB is 2^30 bytes.
**Web search:** There are two components that contribute to the cost of using the web search tool: (1) tool calls and (2) search content tokens. Tool calls are billed per 1000 calls, according to the tool version and model type. The billing dashboard and invoices will report these line items as ‚Äúweb search tool calls.‚Äù
Search content tokens are tokens retrieved from the search index and fed to the model alongside your prompt to generate an answer. These are billed at the model‚Äôs input token rate, unless otherwise specified.
[1] For `gpt-4o-mini` and `gpt-4.1-mini` with the web search non-preview tool, search content tokens are charged as a fixed block of 8,000 input tokens per call.
  

AgentKit
Build, deploy, and optimize production-grade agents with Agent Builder, ChatKit, and Evals. You pay only for the compute and data you actually use.
Usage meter | Free tier (per account, per month) | Price beyond free tier  
---|---|---  
Storage for ChatKit File / Image Uploads | 1 GB | $0.10 / GB-day  
  

Transcription and speech generation
Prices per 1M tokens.
#### Text tokens
Model | Input | Output | Estimated cost  
---|---|---|---  
gpt-4o-mini-tts | $0.60 | - | $0.015 / minute  
gpt-4o-transcribe | $2.50 | $10.00 | $0.006 / minute  
gpt-4o-transcribe-diarize | $2.50 | $10.00 | $0.006 / minute  
gpt-4o-mini-transcribe | $1.25 | $5.00 | $0.003 / minute  
#### Audio tokens
Model | Input | Output | Estimated cost  
---|---|---|---  
gpt-4o-mini-tts | - | $12.00 | $0.015 / minute  
gpt-4o-transcribe | $6.00 | - | $0.006 / minute  
gpt-4o-transcribe-diarize | $6.00 | - | $0.006 / minute  
gpt-4o-mini-transcribe | $3.00 | - | $0.003 / minute  
#### Other models
Model | Use case | Cost  
---|---|---  
Whisper | Transcription | $0.006 / minute  
TTS | Speech generation | $15.00 / 1M characters  
TTS HD | Speech generation | $30.00 / 1M characters  
  

Image generation
Prices per image. Model | Quality | 1024 x 1024 | 1024 x 1536 | 1536 x 1024  
---|---|---|---|---  
GPT Image 1.5 | Low | $0.009 | $0.013 | $0.013  
Medium | $0.034 | $0.05 | $0.05  
High | $0.133 | $0.2 | $0.2  
GPT Image Latest | Low | $0.009 | $0.013 | $0.013  
Medium | $0.034 | $0.05 | $0.05  
High | $0.133 | $0.2 | $0.2  
GPT Image 1 | Low | $0.011 | $0.016 | $0.016  
Medium | $0.042 | $0.063 | $0.063  
High | $0.167 | $0.25 | $0.25  
GPT Image 1 Mini | Low | $0.005 | $0.006 | $0.006  
Medium | $0.011 | $0.015 | $0.015  
High | $0.036 | $0.052 | $0.052  
Model | Quality | 1024 x 1024 | 1024 x 1792 | 1792 x 1024  
DALL¬∑E 3 | Standard | $0.04 | $0.08 | $0.08  
HD | $0.08 | $0.12 | $0.12  
Model | Quality | 256 x 256 | 512 x 512 | 1024 x 1024  
DALL¬∑E 2 | Standard | $0.016 | $0.018 | $0.02  
  

Embeddings
Prices per 1M tokens. Model | Cost | Batch cost  
---|---|---  
text-embedding-3-small | $0.02 | $0.01  
text-embedding-3-large | $0.13 | $0.065  
text-embedding-ada-002 | $0.10 | $0.05  
  

### Moderation
Our `omni-moderation` models are made available free of charge ‚úåÔ∏è
  

Legacy models
Prices per 1M tokens.
BatchStandard
Batch
Model | Input | Output  
---|---|---  
gpt-4-turbo-2024-04-09 | $5.00 | $15.00  
gpt-4-0125-preview | $5.00 | $15.00  
gpt-4-1106-preview | $5.00 | $15.00  
gpt-4-1106-vision-preview | $5.00 | $15.00  
gpt-4-0613 | $15.00 | $30.00  
gpt-4-0314 | $15.00 | $30.00  
gpt-4-32k | $30.00 | $60.00  
gpt-3.5-turbo-0125 | $0.25 | $0.75  
gpt-3.5-turbo-1106 | $1.00 | $2.00  
gpt-3.5-turbo-0613 | $1.50 | $2.00  
gpt-3.5-0301 | $1.50 | $2.00  
gpt-3.5-turbo-16k-0613 | $1.50 | $2.00  
davinci-002 | $1.00 | $1.00  
babbage-002 | $0.20 | $0.20  
Standard
Model | Input | Output  
---|---|---  
chatgpt-4o-latest | $5.00 | $15.00  
gpt-4-turbo-2024-04-09 | $10.00 | $30.00  
gpt-4-0125-preview | $10.00 | $30.00  
gpt-4-1106-preview | $10.00 | $30.00  
gpt-4-1106-vision-preview | $10.00 | $30.00  
gpt-4-0613 | $30.00 | $60.00  
gpt-4-0314 | $30.00 | $60.00  
gpt-4-32k | $60.00 | $120.00  
gpt-3.5-turbo | $0.50 | $1.50  
gpt-3.5-turbo-0125 | $0.50 | $1.50  
gpt-3.5-turbo-1106 | $1.00 | $2.00  
gpt-3.5-turbo-0613 | $1.50 | $2.00  
gpt-3.5-0301 | $1.50 | $2.00  
gpt-3.5-turbo-instruct | $1.50 | $2.00  
gpt-3.5-turbo-16k-0613 | $3.00 | $4.00  
davinci-002 | $2.00 | $2.00  
babbage-002 | $0.40 | $0.40  
  * [Text tokensText tokens](https://platform.openai.com/docs/pricing#text-tokens)
  * [Image tokensImage tokens](https://platform.openai.com/docs/pricing#image-tokens)
  * [Audio tokensAudio tokens](https://platform.openai.com/docs/pricing#audio-tokens)
  * [Fine tuningFine tuning](https://platform.openai.com/docs/pricing#fine-tuning)
  * [Built-in toolsBuilt-in tools](https://platform.openai.com/docs/pricing#built-in-tools)
  * [Transcription and speech generationTranscription and speech generation](https://platform.openai.com/docs/pricing#transcription-and-speech)
  * [Image generationImage generation](https://platform.openai.com/docs/pricing#image-generation)
  * [EmbeddingsEmbeddings](https://platform.openai.com/docs/pricing#embeddings)
  * [ModerationModeration](https://platform.openai.com/docs/pricing#moderation)
  * [Legacy modelsLegacy models](https://platform.openai.com/docs/pricing#legacy-models)

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/api-reference/responses

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 1.76s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 0.15s 
[COMPLETE] ‚óè https://platform.openai.com/docs/api-reference/responses           
| ‚úì | ‚è±: 1.92s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs/guides/text-generation)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
API Reference
[Introduction](https://platform.openai.com/docs/api-reference/introduction)
[Authentication](https://platform.openai.com/docs/api-reference/authentication)
[Debugging requests](https://platform.openai.com/docs/api-reference/debugging-requests)
[Backward compatibility](https://platform.openai.com/docs/api-reference/backward-compatibility)
Responses API
[Responses](https://platform.openai.com/docs/api-reference/responses)
[Create a model response](https://platform.openai.com/docs/api-reference/responses/create)
[Get a model response](https://platform.openai.com/docs/api-reference/responses/get)
[Delete a model response](https://platform.openai.com/docs/api-reference/responses/delete)
[Cancel a response](https://platform.openai.com/docs/api-reference/responses/cancel)
[Compact a response](https://platform.openai.com/docs/api-reference/responses/compact)
[List input items](https://platform.openai.com/docs/api-reference/responses/input-items)
[Get input token counts](https://platform.openai.com/docs/api-reference/responses/input-tokens)
[The response object](https://platform.openai.com/docs/api-reference/responses/object)
[The input item list](https://platform.openai.com/docs/api-reference/responses/list)
[The compacted response object](https://platform.openai.com/docs/api-reference/responses/compacted-object)
[Conversations](https://platform.openai.com/docs/api-reference/conversations)
[Streaming events](https://platform.openai.com/docs/api-reference/responses-streaming)
Webhooks
[Webhook Events](https://platform.openai.com/docs/api-reference/webhook-events)
Platform APIs
[Audio](https://platform.openai.com/docs/api-reference/audio)
[Videos](https://platform.openai.com/docs/api-reference/videos)
[Images](https://platform.openai.com/docs/api-reference/images)
[Image Streaming](https://platform.openai.com/docs/api-reference/images-streaming)
[Embeddings](https://platform.openai.com/docs/api-reference/embeddings)
[Evals](https://platform.openai.com/docs/api-reference/evals)
[Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning)
[Graders](https://platform.openai.com/docs/api-reference/graders)
[Batch](https://platform.openai.com/docs/api-reference/batch)
[Files](https://platform.openai.com/docs/api-reference/files)
[Uploads](https://platform.openai.com/docs/api-reference/uploads)
[Models](https://platform.openai.com/docs/api-reference/models)
[Moderations](https://platform.openai.com/docs/api-reference/moderations)
Vector stores
[Vector stores](https://platform.openai.com/docs/api-reference/vector-stores)
[Vector store files](https://platform.openai.com/docs/api-reference/vector-stores-files)
[Vector store file batches](https://platform.openai.com/docs/api-reference/vector-stores-file-batches)
ChatKit
Beta
[ChatKit](https://platform.openai.com/docs/api-reference/chatkit)
Containers
[Containers](https://platform.openai.com/docs/api-reference/containers)
[Container Files](https://platform.openai.com/docs/api-reference/container-files)
Realtime
[Realtime](https://platform.openai.com/docs/api-reference/realtime)
[Client secrets](https://platform.openai.com/docs/api-reference/realtime-sessions)
[Calls](https://platform.openai.com/docs/api-reference/realtime-calls)
[Client events](https://platform.openai.com/docs/api-reference/realtime-client-events)
[Server events](https://platform.openai.com/docs/api-reference/realtime-server-events)
Chat Completions
[Chat Completions](https://platform.openai.com/docs/api-reference/chat)
[Streaming](https://platform.openai.com/docs/api-reference/chat-streaming)
Assistants
[Assistants](https://platform.openai.com/docs/api-reference/assistants)
[Threads](https://platform.openai.com/docs/api-reference/threads)
[Messages](https://platform.openai.com/docs/api-reference/messages)
[Runs](https://platform.openai.com/docs/api-reference/runs)
[Run steps](https://platform.openai.com/docs/api-reference/run-steps)
[Streaming](https://platform.openai.com/docs/api-reference/assistants-streaming)
Administration
[Administration](https://platform.openai.com/docs/api-reference/administration)
[Admin API Keys](https://platform.openai.com/docs/api-reference/admin-api-keys)
[Invites](https://platform.openai.com/docs/api-reference/invite)
[Users](https://platform.openai.com/docs/api-reference/users)
[Groups](https://platform.openai.com/docs/api-reference/groups)
[Roles](https://platform.openai.com/docs/api-reference/roles)
[Role assignments](https://platform.openai.com/docs/api-reference/role-assignments)
[Projects](https://platform.openai.com/docs/api-reference/projects)
[Project users](https://platform.openai.com/docs/api-reference/project-users)
[Project groups](https://platform.openai.com/docs/api-reference/project-groups)
[Project service accounts](https://platform.openai.com/docs/api-reference/project-service-accounts)
[Project API keys](https://platform.openai.com/docs/api-reference/project-api-keys)
[Project rate limits](https://platform.openai.com/docs/api-reference/project-rate-limits)
[Audit logs](https://platform.openai.com/docs/api-reference/audit-logs)
[Usage](https://platform.openai.com/docs/api-reference/usage)
[Certificates](https://platform.openai.com/docs/api-reference/certificates)
Legacy
[Completions](https://platform.openai.com/docs/api-reference/completions)
[Realtime Beta](https://platform.openai.com/docs/api-reference/realtime_beta)
[Realtime Beta session tokens](https://platform.openai.com/docs/api-reference/realtime-beta-sessions)
[Realtime Beta client events](https://platform.openai.com/docs/api-reference/realtime-beta-client-events)
[Realtime Beta server events](https://platform.openai.com/docs/api-reference/realtime-beta-server-events)
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
## 
Responses
OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.
Related guides:
  * [Quickstart](https://platform.openai.com/docs/quickstart?api-mode=responses)
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text?api-mode=responses)
  * [Image inputs](https://platform.openai.com/docs/guides/images?api-mode=responses)
  * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses)
  * [Function calling](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)
  * [Conversation state](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)
  * [Extend the models with tools](https://platform.openai.com/docs/guides/tools?api-mode=responses)


## 
Create a model response
post https://api.openai.com/v1/responses
Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text) or [image](https://platform.openai.com/docs/guides/images) inputs to generate [text](https://platform.openai.com/docs/guides/text) or [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have the model call your own [custom code](https://platform.openai.com/docs/guides/function-calling) or use built-in [tools](https://platform.openai.com/docs/guides/tools) like [web search](https://platform.openai.com/docs/guides/tools-web-search) or [file search](https://platform.openai.com/docs/guides/tools-file-search) to use your own data as input for the model's response.
#### Request body
[](https://platform.openai.com/docs/api-reference/responses#responses_create-background)
background
boolean
Optional
Defaults to false
Whether to run the model response in the background. [Learn more](https://platform.openai.com/docs/guides/background).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-context_management)
context_management
array
Optional
Context management configuration for this request.
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-conversation)
conversation
string or object
Optional
Defaults to null
The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request. Input items and output items from this response are automatically added to this conversation after this response completes.
Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-include)
include
array
Optional
Specify additional output data to include in the model response. Currently supported values are:
  * `web_search_call.action.sources`: Include the sources of the web search tool call.
  * `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.
  * `computer_call_output.output.image_url`: Include image urls from the computer call output.
  * `file_search_call.results`: Include the search results of the file search tool call.
  * `message.input_image.image_url`: Include image urls from the input message.
  * `message.output_text.logprobs`: Include logprobs with assistant messages.
  * `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).


[](https://platform.openai.com/docs/api-reference/responses#responses_create-input)
input
string or array
Optional
Text, image, or file inputs to the model, used to generate a response.
Learn more:
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
  * [Image inputs](https://platform.openai.com/docs/guides/images)
  * [File inputs](https://platform.openai.com/docs/guides/pdf-files)
  * [Conversation state](https://platform.openai.com/docs/guides/conversation-state)
  * [Function calling](https://platform.openai.com/docs/guides/function-calling)


Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-instructions)
instructions
string
Optional
A system (or developer) message inserted into the model's context.
When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-max_output_tokens)
max_output_tokens
integer
Optional
An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-max_tool_calls)
max_tool_calls
integer
Optional
The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-metadata)
metadata
map
Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.
Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-model)
model
string
Optional
Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](https://platform.openai.com/docs/models) to browse and compare available models.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-parallel_tool_calls)
parallel_tool_calls
boolean
Optional
Defaults to true
Whether to allow the model to run tool calls in parallel.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-previous_response_id)
previous_response_id
string
Optional
The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt)
prompt
object
Optional
Reference to a prompt template and its variables. [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt_cache_key)
prompt_cache_key
string
Optional
Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-prompt_cache_retention)
prompt_cache_retention
string
Optional
The retention policy for the prompt cache. Set to `24h` to enable extended prompt caching, which keeps cached prefixes active for longer, up to a maximum of 24 hours. [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-reasoning)
reasoning
object
Optional
**gpt-5 and o-series models only**
Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-safety_identifier)
safety_identifier
string
Optional
A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
[](https://platform.openai.com/docs/api-reference/responses#responses_create-service_tier)
service_tier
string
Optional
Defaults to auto
Specifies the processing type used for serving the request.
  * If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
  * If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
  * If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or '[priority](https://openai.com/api-priority-processing/)', then the request will be processed with the corresponding service tier.
  * When not set, the default behavior is 'auto'.


When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-store)
store
boolean
Optional
Defaults to true
Whether to store the generated model response for later retrieval via API.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-stream)
stream
boolean
Optional
Defaults to false
If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming) for more information.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-stream_options)
stream_options
object
Optional
Defaults to null
Options for streaming responses. Only set this when you set `stream: true`.
Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-temperature)
temperature
number
Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-text)
text
object
Optional
Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:
  * [Text inputs and outputs](https://platform.openai.com/docs/guides/text)
  * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)


Show properties
[](https://platform.openai.com/docs/api-reference/responses#responses_create-tool_choice)
tool_choice
string or object
Optional
How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.
Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-tools)
tools
array
Optional
An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.
We support the following categories of tools:
  * **Built-in tools** : Tools that are provided by OpenAI that extend the model's capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search) or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about [built-in tools](https://platform.openai.com/docs/guides/tools).
  * **MCP Tools** : Integrations with third-party systems via custom MCP servers or predefined connectors such as Google Drive and SharePoint. Learn more about [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).
  * **Function calls (custom tools)** : Functions that are defined by you, enabling the model to call your own code with strongly typed arguments and outputs. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use custom tools to call your own code.


Show possible types
[](https://platform.openai.com/docs/api-reference/responses#responses_create-top_logprobs)
top_logprobs
integer
Optional
An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-top_p)
top_p
number
Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
We generally recommend altering this or `temperature` but not both.
[](https://platform.openai.com/docs/api-reference/responses#responses_create-truncation)
truncation
string
Optional
Defaults to disabled
The truncation strategy to use for the model response.
  * `auto`: If the input to this Response exceeds the model's context window size, the model will truncate the response to fit the context window by dropping items from the beginni

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/models/gpt-4o

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/models/gpt-4o                     
| ‚úì | ‚è±: 1.03s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/models/gpt-4o                     
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://platform.openai.com/docs/models/gpt-4o                     
| ‚úì | ‚è±: 1.05s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Signing in...
Search`‚åò``K`
Get started
[Overview](https://platform.openai.com/docs/overview)
[Quickstart](https://platform.openai.com/docs/quickstart)
[Models](https://platform.openai.com/docs/models)
[Pricing](https://platform.openai.com/docs/pricing)
[Libraries](https://platform.openai.com/docs/libraries)
[Docs MCP](https://platform.openai.com/docs/docs-mcp)
[Latest: GPT-5.2](https://platform.openai.com/docs/guides/latest-model)
Core concepts
[Text generation](https://platform.openai.com/docs/guides/text)
[Code generation](https://platform.openai.com/docs/guides/code-generation)
[Images and vision](https://platform.openai.com/docs/guides/images-vision)
[Audio and speech](https://platform.openai.com/docs/guides/audio)
[Structured output](https://platform.openai.com/docs/guides/structured-outputs)
[Function calling](https://platform.openai.com/docs/guides/function-calling)
[Responses API](https://platform.openai.com/docs/guides/migrate-to-responses)
Agents
[Overview](https://platform.openai.com/docs/guides/agents)
Build agents
Deploy in your product
Optimize
[Voice agents](https://platform.openai.com/docs/guides/voice-agents)
Tools
[Using tools](https://platform.openai.com/docs/guides/tools)
[Connectors and MCP](https://platform.openai.com/docs/guides/tools-connectors-mcp)
[Web search](https://platform.openai.com/docs/guides/tools-web-search)
[Code interpreter](https://platform.openai.com/docs/guides/tools-code-interpreter)
File search and retrieval
More tools
Run and scale
[Conversation state](https://platform.openai.com/docs/guides/conversation-state)
[Background mode](https://platform.openai.com/docs/guides/background)
[Streaming](https://platform.openai.com/docs/guides/streaming-responses)
[Webhooks](https://platform.openai.com/docs/guides/webhooks)
[File inputs](https://platform.openai.com/docs/guides/pdf-files)
Prompting
Reasoning
Evaluation
[Getting started](https://platform.openai.com/docs/guides/evaluation-getting-started)
[Working with evals](https://platform.openai.com/docs/guides/evals)
[Prompt optimizer](https://platform.openai.com/docs/guides/prompt-optimizer)
[External models](https://platform.openai.com/docs/guides/external-models)
[Best practices](https://platform.openai.com/docs/guides/evaluation-best-practices)
Realtime API
[Overview](https://platform.openai.com/docs/guides/realtime)
Connect
Usage
Model optimization
[Optimization cycle](https://platform.openai.com/docs/guides/model-optimization)
Fine-tuning
[Graders](https://platform.openai.com/docs/guides/graders)
Specialized models
[Image generation](https://platform.openai.com/docs/guides/image-generation)
[Video generation](https://platform.openai.com/docs/guides/video-generation)
[Text to speech](https://platform.openai.com/docs/guides/text-to-speech)
[Speech to text](https://platform.openai.com/docs/guides/speech-to-text)
[Deep research](https://platform.openai.com/docs/guides/deep-research)
[Embeddings](https://platform.openai.com/docs/guides/embeddings)
[Moderation](https://platform.openai.com/docs/guides/moderation)
Coding agents
[Codex cloud](https://developers.openai.com/codex/cloud)
[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)
[Codex CLI](https://developers.openai.com/codex/cli)
[Codex IDE](https://developers.openai.com/codex/ide)
[Codex changelog](https://developers.openai.com/codex/changelog)
Going live
[Production best practices](https://platform.openai.com/docs/guides/production-best-practices)
Latency optimization
Cost optimization
[Accuracy optimization](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)
Safety
Legacy APIs
Assistants API
Resources
[Terms and policies](https://openai.com/policies)
[Changelog](https://platform.openai.com/docs/changelog)
[Your data](https://platform.openai.com/docs/guides/your-data)
[Permissions](https://platform.openai.com/docs/guides/rbac)
[Rate limits](https://platform.openai.com/docs/guides/rate-limits)
[Deprecations](https://platform.openai.com/docs/deprecations)
[MCP for deep research](https://platform.openai.com/docs/mcp)
[Developer mode](https://platform.openai.com/docs/guides/developer-mode)
ChatGPT Actions
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
[](https://platform.openai.com/docs/models)
![gpt-4o](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o.png)
GPT-4o
Default
Fast, intelligent, flexible GPT model
Fast, intelligent, flexible GPT model
CompareTry in Playground
Intelligence
High
Speed
Medium
Price
$2.5‚Ä¢$10
Input‚Ä¢Output
Input
Text, image
Output
Text
Prompt example
Math Tutor
Prompt example
Travel Assistant
Prompt example
Clothing Recommendation
Prompt example
Recipe Generation
GPT-4o (‚Äúo‚Äù for ‚Äúomni‚Äù) is our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.
128,000 context window
16,384 max output tokens
Oct 01, 2023 knowledge cutoff
Pricing
Pricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there‚Äôs a fee per tool call. See details in the [pricing page](https://platform.openai.com/docs/pricing).
Text tokens
Per 1M tokens
‚àô
Batch API price
Input
$2.50
Cached input
$1.25
Output
$10.00
Quick comparison
Input
Cached input
Output
GPT-4o
$2.50
o3-mini
$1.10
GPT-4o mini
$0.15
Modalities
Text
Input and output
Image
Input only
Audio
Not supported
Video
Not supported
Endpoints
Chat Completions
v1/chat/completions
Responses
v1/responses
Realtime
v1/realtime
Assistants
v1/assistants
Batch
v1/batch
Fine-tuning
v1/fine-tuning
Embeddings
v1/embeddings
Image generation
v1/images/generations
Videos
v1/videos
Image edit
v1/images/edits
Speech generation
v1/audio/speech
Transcription
v1/audio/transcriptions
Translation
v1/audio/translations
Moderation
v1/moderations
Completions (legacy)
v1/completions
Features
Streaming
Supported
Function calling
Supported
Structured outputs
Supported
Fine-tuning
Supported
Distillation
Supported
Predicted outputs
Supported
Snapshots
Snapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for GPT-4o.
![gpt-4o](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o.png)
gpt-4o
gpt-4o-2024-08-06
Rate limits
Rate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.
Tier | RPM | TPM | Batch queue limit  
---|---|---|---  
Free | Not supported  
Tier 1 | 500 | 30,000 | 90,000  
Tier 2 | 5,000 | 450,000 | 1,350,000  
Tier 3 | 5,000 | 800,000 | 50,000,000  
Tier 4 | 10,000 | 2,000,000 | 200,000,000  
Tier 5 | 10,000 | 30,000,000 | 5,000,000,000

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/models/o1

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/models/o1                         
| ‚úì | ‚è±: 1.17s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/models/o1                         
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://platform.openai.com/docs/models/o1                         
| ‚úì | ‚è±: 1.19s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
Get started
[Overview](https://platform.openai.com/docs/overview)
[Quickstart](https://platform.openai.com/docs/quickstart)
[Models](https://platform.openai.com/docs/models)
[Pricing](https://platform.openai.com/docs/pricing)
[Libraries](https://platform.openai.com/docs/libraries)
[Docs MCP](https://platform.openai.com/docs/docs-mcp)
[Latest: GPT-5.2](https://platform.openai.com/docs/guides/latest-model)
Core concepts
[Text generation](https://platform.openai.com/docs/guides/text)
[Code generation](https://platform.openai.com/docs/guides/code-generation)
[Images and vision](https://platform.openai.com/docs/guides/images-vision)
[Audio and speech](https://platform.openai.com/docs/guides/audio)
[Structured output](https://platform.openai.com/docs/guides/structured-outputs)
[Function calling](https://platform.openai.com/docs/guides/function-calling)
[Responses API](https://platform.openai.com/docs/guides/migrate-to-responses)
Agents
[Overview](https://platform.openai.com/docs/guides/agents)
Build agents
Deploy in your product
Optimize
[Voice agents](https://platform.openai.com/docs/guides/voice-agents)
Tools
[Using tools](https://platform.openai.com/docs/guides/tools)
[Connectors and MCP](https://platform.openai.com/docs/guides/tools-connectors-mcp)
[Web search](https://platform.openai.com/docs/guides/tools-web-search)
[Code interpreter](https://platform.openai.com/docs/guides/tools-code-interpreter)
File search and retrieval
More tools
Run and scale
[Conversation state](https://platform.openai.com/docs/guides/conversation-state)
[Background mode](https://platform.openai.com/docs/guides/background)
[Streaming](https://platform.openai.com/docs/guides/streaming-responses)
[Webhooks](https://platform.openai.com/docs/guides/webhooks)
[File inputs](https://platform.openai.com/docs/guides/pdf-files)
Prompting
Reasoning
Evaluation
[Getting started](https://platform.openai.com/docs/guides/evaluation-getting-started)
[Working with evals](https://platform.openai.com/docs/guides/evals)
[Prompt optimizer](https://platform.openai.com/docs/guides/prompt-optimizer)
[External models](https://platform.openai.com/docs/guides/external-models)
[Best practices](https://platform.openai.com/docs/guides/evaluation-best-practices)
Realtime API
[Overview](https://platform.openai.com/docs/guides/realtime)
Connect
Usage
Model optimization
[Optimization cycle](https://platform.openai.com/docs/guides/model-optimization)
Fine-tuning
[Graders](https://platform.openai.com/docs/guides/graders)
Specialized models
[Image generation](https://platform.openai.com/docs/guides/image-generation)
[Video generation](https://platform.openai.com/docs/guides/video-generation)
[Text to speech](https://platform.openai.com/docs/guides/text-to-speech)
[Speech to text](https://platform.openai.com/docs/guides/speech-to-text)
[Deep research](https://platform.openai.com/docs/guides/deep-research)
[Embeddings](https://platform.openai.com/docs/guides/embeddings)
[Moderation](https://platform.openai.com/docs/guides/moderation)
Coding agents
[Codex cloud](https://developers.openai.com/codex/cloud)
[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)
[Codex CLI](https://developers.openai.com/codex/cli)
[Codex IDE](https://developers.openai.com/codex/ide)
[Codex changelog](https://developers.openai.com/codex/changelog)
Going live
[Production best practices](https://platform.openai.com/docs/guides/production-best-practices)
Latency optimization
Cost optimization
[Accuracy optimization](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)
Safety
Legacy APIs
Assistants API
Resources
[Terms and policies](https://openai.com/policies)
[Changelog](https://platform.openai.com/docs/changelog)
[Your data](https://platform.openai.com/docs/guides/your-data)
[Permissions](https://platform.openai.com/docs/guides/rbac)
[Rate limits](https://platform.openai.com/docs/guides/rate-limits)
[Deprecations](https://platform.openai.com/docs/deprecations)
[MCP for deep research](https://platform.openai.com/docs/mcp)
[Developer mode](https://platform.openai.com/docs/guides/developer-mode)
ChatGPT Actions
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
[](https://platform.openai.com/docs/models)
![o1](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1.png)
o1
Default
Previous full o-series reasoning model
Previous full o-series reasoning model
CompareTry in Playground
Reasoning
Higher
Speed
Slowest
Price
$15‚Ä¢$60
Input‚Ä¢Output
Input
Text, image
Output
Text
The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user.
200,000 context window
100,000 max output tokens
Oct 01, 2023 knowledge cutoff
Reasoning token support
Pricing
Pricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there‚Äôs a fee per tool call. See details in the [pricing page](https://platform.openai.com/docs/pricing).
Text tokens
Per 1M tokens
‚àô
Batch API price
Input
$15.00
Cached input
$7.50
Output
$60.00
Quick comparison
Input
Cached input
Output
o1
$15.00
o1-mini
$1.10
o3-mini
$1.10
Modalities
Text
Input and output
Image
Input only
Audio
Not supported
Video
Not supported
Endpoints
Chat Completions
v1/chat/completions
Responses
v1/responses
Realtime
v1/realtime
Assistants
v1/assistants
Batch
v1/batch
Fine-tuning
v1/fine-tuning
Embeddings
v1/embeddings
Image generation
v1/images/generations
Videos
v1/videos
Image edit
v1/images/edits
Speech generation
v1/audio/speech
Transcription
v1/audio/transcriptions
Translation
v1/audio/translations
Moderation
v1/moderations
Completions (legacy)
v1/completions
Features
Streaming
Supported
Function calling
Supported
Structured outputs
Supported
Fine-tuning
Not supported
Distillation
Not supported
Predicted outputs
Not supported
Snapshots
Snapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for o1.
![o1](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1.png)
o1
o1-2024-12-17
![o1-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-preview.png)
o1-preview
o1-preview-2024-09-12
Deprecated
Rate limits
Rate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.
Tier | RPM | TPM | Batch queue limit  
---|---|---|---  
Free | Not supported  
Tier 1 | 500 | 30,000 | 90,000  
Tier 2 | 5,000 | 450,000 | 1,350,000  
Tier 3 | 5,000 | 800,000 | 50,000,000  
Tier 4 | 10,000 | 2,000,000 | 200,000,000  
Tier 5 | 10,000 | 30,000,000 | 5,000,000,000

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/models/o3

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/models/o3                         
| ‚úì | ‚è±: 1.12s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/models/o3                         
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://platform.openai.com/docs/models/o3                         
| ‚úì | ‚è±: 1.14s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
Get started
[Overview](https://platform.openai.com/docs/overview)
[Quickstart](https://platform.openai.com/docs/quickstart)
[Models](https://platform.openai.com/docs/models)
[Pricing](https://platform.openai.com/docs/pricing)
[Libraries](https://platform.openai.com/docs/libraries)
[Docs MCP](https://platform.openai.com/docs/docs-mcp)
[Latest: GPT-5.2](https://platform.openai.com/docs/guides/latest-model)
Core concepts
[Text generation](https://platform.openai.com/docs/guides/text)
[Code generation](https://platform.openai.com/docs/guides/code-generation)
[Images and vision](https://platform.openai.com/docs/guides/images-vision)
[Audio and speech](https://platform.openai.com/docs/guides/audio)
[Structured output](https://platform.openai.com/docs/guides/structured-outputs)
[Function calling](https://platform.openai.com/docs/guides/function-calling)
[Responses API](https://platform.openai.com/docs/guides/migrate-to-responses)
Agents
[Overview](https://platform.openai.com/docs/guides/agents)
Build agents
Deploy in your product
Optimize
[Voice agents](https://platform.openai.com/docs/guides/voice-agents)
Tools
[Using tools](https://platform.openai.com/docs/guides/tools)
[Connectors and MCP](https://platform.openai.com/docs/guides/tools-connectors-mcp)
[Web search](https://platform.openai.com/docs/guides/tools-web-search)
[Code interpreter](https://platform.openai.com/docs/guides/tools-code-interpreter)
File search and retrieval
More tools
Run and scale
[Conversation state](https://platform.openai.com/docs/guides/conversation-state)
[Background mode](https://platform.openai.com/docs/guides/background)
[Streaming](https://platform.openai.com/docs/guides/streaming-responses)
[Webhooks](https://platform.openai.com/docs/guides/webhooks)
[File inputs](https://platform.openai.com/docs/guides/pdf-files)
Prompting
Reasoning
Evaluation
[Getting started](https://platform.openai.com/docs/guides/evaluation-getting-started)
[Working with evals](https://platform.openai.com/docs/guides/evals)
[Prompt optimizer](https://platform.openai.com/docs/guides/prompt-optimizer)
[External models](https://platform.openai.com/docs/guides/external-models)
[Best practices](https://platform.openai.com/docs/guides/evaluation-best-practices)
Realtime API
[Overview](https://platform.openai.com/docs/guides/realtime)
Connect
Usage
Model optimization
[Optimization cycle](https://platform.openai.com/docs/guides/model-optimization)
Fine-tuning
[Graders](https://platform.openai.com/docs/guides/graders)
Specialized models
[Image generation](https://platform.openai.com/docs/guides/image-generation)
[Video generation](https://platform.openai.com/docs/guides/video-generation)
[Text to speech](https://platform.openai.com/docs/guides/text-to-speech)
[Speech to text](https://platform.openai.com/docs/guides/speech-to-text)
[Deep research](https://platform.openai.com/docs/guides/deep-research)
[Embeddings](https://platform.openai.com/docs/guides/embeddings)
[Moderation](https://platform.openai.com/docs/guides/moderation)
Coding agents
[Codex cloud](https://developers.openai.com/codex/cloud)
[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)
[Codex CLI](https://developers.openai.com/codex/cli)
[Codex IDE](https://developers.openai.com/codex/ide)
[Codex changelog](https://developers.openai.com/codex/changelog)
Going live
[Production best practices](https://platform.openai.com/docs/guides/production-best-practices)
Latency optimization
Cost optimization
[Accuracy optimization](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)
Safety
Legacy APIs
Assistants API
Resources
[Terms and policies](https://openai.com/policies)
[Changelog](https://platform.openai.com/docs/changelog)
[Your data](https://platform.openai.com/docs/guides/your-data)
[Permissions](https://platform.openai.com/docs/guides/rbac)
[Rate limits](https://platform.openai.com/docs/guides/rate-limits)
[Deprecations](https://platform.openai.com/docs/deprecations)
[MCP for deep research](https://platform.openai.com/docs/mcp)
[Developer mode](https://platform.openai.com/docs/guides/developer-mode)
ChatGPT Actions
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
[](https://platform.openai.com/docs/models)
![o3](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3.png)
o3
Default
Reasoning model for complex tasks, succeeded by GPT-5
Reasoning model for complex tasks, succeeded by GPT-5
CompareTry in Playground
Reasoning
Highest
Speed
Slowest
Price
$2‚Ä¢$8
Input‚Ä¢Output
Input
Text, image
Output
Text
o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images.
o3 is succeeded by [GPT-5](https://platform.openai.com/docs/models/gpt-5).
Learn more about how to use our reasoning models in our [reasoning](https://platform.openai.com/docs/guides/reasoning?api-mode=responses) guide.
200,000 context window
100,000 max output tokens
Jun 01, 2024 knowledge cutoff
Reasoning token support
Pricing
Pricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there‚Äôs a fee per tool call. See details in the [pricing page](https://platform.openai.com/docs/pricing).
Text tokens
Per 1M tokens
‚àô
Batch API price
Input
$2.00
Cached input
$0.50
Output
$8.00
Quick comparison
Input
Cached input
Output
o1
$15.00
o3
$2.00
o4-mini
$1.10
Text tokens
Per 1M tokens
Input
$1.00
Cached input
$0.25
Output
$4.00
Modalities
Text
Input and output
Image
Input only
Audio
Not supported
Video
Not supported
Endpoints
Chat Completions
v1/chat/completions
Responses
v1/responses
Realtime
v1/realtime
Assistants
v1/assistants
Batch
v1/batch
Fine-tuning
v1/fine-tuning
Embeddings
v1/embeddings
Image generation
v1/images/generations
Videos
v1/videos
Image edit
v1/images/edits
Speech generation
v1/audio/speech
Transcription
v1/audio/transcriptions
Translation
v1/audio/translations
Moderation
v1/moderations
Completions (legacy)
v1/completions
Features
Streaming
Supported
Function calling
Supported
Structured outputs
Supported
Fine-tuning
Not supported
Distillation
Not supported
Predicted outputs
Not supported
Snapshots
Snapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for o3.
![o3](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3.png)
o3
o3-2025-04-16
Rate limits
Rate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.
Tier | RPM | TPM | Batch queue limit  
---|---|---|---  
Free | Not supported  
Tier 1 | 500 | 30,000 | 90,000  
Tier 2 | 5,000 | 450,000 | 1,350,000  
Tier 3 | 5,000 | 800,000 | 50,000,000  
Tier 4 | 10,000 | 2,000,000 | 200,000,000  
Tier 5 | 10,000 | 30,000,000 | 5,000,000,000


>>>TOOL web_fetch
{"url":"https://platform.openai.com/docs/models/gpt-4.5-preview","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.claude.com/docs/en/about-claude/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://ai.google.dev/gemini-api/docs/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.moonshot.ai/docs/pricing/chat","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://groq.com/pricing/","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.openai.com/docs/models/gpt-4.5-preview

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.openai.com/docs/models/gpt-4.5-preview            
| ‚úì | ‚è±: 1.64s 
[SCRAPE].. ‚óÜ https://platform.openai.com/docs/models/gpt-4.5-preview            
| ‚úì | ‚è±: 0.03s 
[COMPLETE] ‚óè https://platform.openai.com/docs/models/gpt-4.5-preview            
| ‚úì | ‚è±: 1.68s 
[](https://platform.openai.com/docs/overview)
[DocsDocs](https://platform.openai.com/docs)[API referenceAPI](https://platform.openai.com/docs/api-reference/introduction)
Log in[Sign up](https://platform.openai.com/signup)
Search`‚åò``K`
Get started
[Overview](https://platform.openai.com/docs/overview)
[Quickstart](https://platform.openai.com/docs/quickstart)
[Models](https://platform.openai.com/docs/models)
[Pricing](https://platform.openai.com/docs/pricing)
[Libraries](https://platform.openai.com/docs/libraries)
[Docs MCP](https://platform.openai.com/docs/docs-mcp)
[Latest: GPT-5.2](https://platform.openai.com/docs/guides/latest-model)
Core concepts
[Text generation](https://platform.openai.com/docs/guides/text)
[Code generation](https://platform.openai.com/docs/guides/code-generation)
[Images and vision](https://platform.openai.com/docs/guides/images-vision)
[Audio and speech](https://platform.openai.com/docs/guides/audio)
[Structured output](https://platform.openai.com/docs/guides/structured-outputs)
[Function calling](https://platform.openai.com/docs/guides/function-calling)
[Responses API](https://platform.openai.com/docs/guides/migrate-to-responses)
Agents
[Overview](https://platform.openai.com/docs/guides/agents)
Build agents
Deploy in your product
Optimize
[Voice agents](https://platform.openai.com/docs/guides/voice-agents)
Tools
[Using tools](https://platform.openai.com/docs/guides/tools)
[Connectors and MCP](https://platform.openai.com/docs/guides/tools-connectors-mcp)
[Web search](https://platform.openai.com/docs/guides/tools-web-search)
[Code interpreter](https://platform.openai.com/docs/guides/tools-code-interpreter)
File search and retrieval
More tools
Run and scale
[Conversation state](https://platform.openai.com/docs/guides/conversation-state)
[Background mode](https://platform.openai.com/docs/guides/background)
[Streaming](https://platform.openai.com/docs/guides/streaming-responses)
[Webhooks](https://platform.openai.com/docs/guides/webhooks)
[File inputs](https://platform.openai.com/docs/guides/pdf-files)
Prompting
Reasoning
Evaluation
[Getting started](https://platform.openai.com/docs/guides/evaluation-getting-started)
[Working with evals](https://platform.openai.com/docs/guides/evals)
[Prompt optimizer](https://platform.openai.com/docs/guides/prompt-optimizer)
[External models](https://platform.openai.com/docs/guides/external-models)
[Best practices](https://platform.openai.com/docs/guides/evaluation-best-practices)
Realtime API
[Overview](https://platform.openai.com/docs/guides/realtime)
Connect
Usage
Model optimization
[Optimization cycle](https://platform.openai.com/docs/guides/model-optimization)
Fine-tuning
[Graders](https://platform.openai.com/docs/guides/graders)
Specialized models
[Image generation](https://platform.openai.com/docs/guides/image-generation)
[Video generation](https://platform.openai.com/docs/guides/video-generation)
[Text to speech](https://platform.openai.com/docs/guides/text-to-speech)
[Speech to text](https://platform.openai.com/docs/guides/speech-to-text)
[Deep research](https://platform.openai.com/docs/guides/deep-research)
[Embeddings](https://platform.openai.com/docs/guides/embeddings)
[Moderation](https://platform.openai.com/docs/guides/moderation)
Coding agents
[Codex cloud](https://developers.openai.com/codex/cloud)
[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)
[Codex CLI](https://developers.openai.com/codex/cli)
[Codex IDE](https://developers.openai.com/codex/ide)
[Codex changelog](https://developers.openai.com/codex/changelog)
Going live
[Production best practices](https://platform.openai.com/docs/guides/production-best-practices)
Latency optimization
Cost optimization
[Accuracy optimization](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)
Safety
Legacy APIs
Assistants API
Resources
[Terms and policies](https://openai.com/policies)
[Changelog](https://platform.openai.com/docs/changelog)
[Your data](https://platform.openai.com/docs/guides/your-data)
[Permissions](https://platform.openai.com/docs/guides/rbac)
[Rate limits](https://platform.openai.com/docs/guides/rate-limits)
[Deprecations](https://platform.openai.com/docs/deprecations)
[MCP for deep research](https://platform.openai.com/docs/mcp)
[Developer mode](https://platform.openai.com/docs/guides/developer-mode)
ChatGPT Actions
[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)
[](https://platform.openai.com/docs/models)
![gpt-4.5-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.5-preview.png)
GPT-4.5 Preview (Deprecated)
Default
Deprecated large model.
Deprecated large model.
CompareTry in Playground
Intelligence
Higher
Speed
Medium
Price
$75‚Ä¢$150
Input‚Ä¢Output
Input
Text, image
Output
Text
Deprecated - a research preview of GPT-4.5. We recommend using gpt-4.1 or o3 models instead for most use cases
128,000 context window
16,384 max output tokens
Oct 01, 2023 knowledge cutoff
Pricing
Pricing is based on the number of tokens used, or other metrics based on the model type. For tool-specific models, like search and computer use, there‚Äôs a fee per tool call. See details in the [pricing page](https://platform.openai.com/docs/pricing).
Text tokens
Per 1M tokens
‚àô
Batch API price
Input
$75.00
Cached input
$37.50
Output
$150.00
Quick comparison
Input
Cached input
Output
GPT-4.5 Preview (Deprecated)
$75.00
GPT-4.1
$2.00
o3
$2.00
Modalities
Text
Input and output
Image
Input only
Audio
Not supported
Video
Not supported
Endpoints
Chat Completions
v1/chat/completions
Responses
v1/responses
Realtime
v1/realtime
Assistants
v1/assistants
Batch
v1/batch
Fine-tuning
v1/fine-tuning
Embeddings
v1/embeddings
Image generation
v1/images/generations
Videos
v1/videos
Image edit
v1/images/edits
Speech generation
v1/audio/speech
Transcription
v1/audio/transcriptions
Translation
v1/audio/translations
Moderation
v1/moderations
Completions (legacy)
v1/completions
Features
Streaming
Supported
Function calling
Supported
Structured outputs
Supported
Fine-tuning
Not supported
Distillation
Not supported
Predicted outputs
Not supported
Snapshots
Snapshots let you lock in a specific version of the model so that performance and behavior remain consistent. Below is a list of all available snapshots and aliases for GPT-4.5 Preview (Deprecated).
![gpt-4.5-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.5-preview.png)
gpt-4.5-preview
gpt-4.5-preview-2025-02-27
Rate limits
Rate limits ensure fair and reliable access to the API by placing specific caps on requests or tokens used within a given time period. Your usage tier determines how high these limits are set and automatically increases as you send more requests and spend more on the API.
Tier | RPM | TPM | Batch queue limit  
---|---|---|---  
Free | Not supported  
Tier 1 | 1,000 | 125,000 | 50,000  
Tier 2 | 5,000 | 250,000 | 500,000  
Tier 3 | 5,000 | 500,000 | 50,000,000  
Tier 4 | 10,000 | 1,000,000 | 100,000,000  
Tier 5 | 10,000 | 2,000,000 | 5,000,000,000  
We use cookies and similar technologies to deliver, maintain, improve our services and for security purposes. Check our [Cookie Policy](https://openai.com/policies/cookie-policy) for details. Click 'Accept all' to let OpenAI and partners use cookies for these purposes. Click 'Reject all' to say no to cookies, except those that are strictly necessary. Choose 'Manage Cookies' to pick specific cookies you're okay with or to change your preferences.
Reject allAccept all

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.claude.com/docs/en/about-claude/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 2.24s 
[SCRAPE].. ‚óÜ https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 0.05s 
[COMPLETE] ‚óè https://platform.claude.com/docs/en/about-claude/pricing           
| ‚úì | ‚è±: 2.30s 
### Cookie settings
We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).
CustomizeCustomize Cookie SettingsRejectReject All CookiesAcceptAccept All Cookies
[](https://platform.claude.com/docs/en/home)
  * [Developer Guide](https://platform.claude.com/docs/en/intro)
  * [API Reference](https://platform.claude.com/docs/en/api/overview)
  * [MCP](https://modelcontextprotocol.io)
  * [Resources](https://platform.claude.com/docs/en/resources/overview)
  * [Release Notes](https://platform.claude.com/docs/en/release-notes/overview)


English[Log in](https://platform.claude.com/login?returnTo=%2Fdocs%2Fen%2Fabout-claude%2Fpricing)
Search...
‚åòK
First steps
[Intro to Claude](https://platform.claude.com/docs/en/intro)[Quickstart](https://platform.claude.com/docs/en/get-started)
Models & pricing
[Models overview](https://platform.claude.com/docs/en/about-claude/models/overview)[Choosing a model](https://platform.claude.com/docs/en/about-claude/models/choosing-a-model)[What's new in Claude 4.6](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)[Migration guide](https://platform.claude.com/docs/en/about-claude/models/migration-guide)[Model deprecations](https://platform.claude.com/docs/en/about-claude/model-deprecations)[Pricing](https://platform.claude.com/docs/en/about-claude/pricing)
Build with Claude
[Features overview](https://platform.claude.com/docs/en/build-with-claude/overview)[Using the Messages API](https://platform.claude.com/docs/en/build-with-claude/working-with-messages)[Handling stop reasons](https://platform.claude.com/docs/en/build-with-claude/handling-stop-reasons)[Prompting best practices](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices)
Context management
[Context windows](https://platform.claude.com/docs/en/build-with-claude/context-windows)[Compaction](https://platform.claude.com/docs/en/build-with-claude/compaction)[Context editing](https://platform.claude.com/docs/en/build-with-claude/context-editing)
Capabilities
[Prompt caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching)[Extended thinking](https://platform.claude.com/docs/en/build-with-claude/extended-thinking)[Adaptive thinking](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)[Effort](https://platform.claude.com/docs/en/build-with-claude/effort)[Fast mode (research preview)](https://platform.claude.com/docs/en/build-with-claude/fast-mode)[Streaming Messages](https://platform.claude.com/docs/en/build-with-claude/streaming)[Batch processing](https://platform.claude.com/docs/en/build-with-claude/batch-processing)[Citations](https://platform.claude.com/docs/en/build-with-claude/citations)[Multilingual support](https://platform.claude.com/docs/en/build-with-claude/multilingual-support)[Token counting](https://platform.claude.com/docs/en/build-with-claude/token-counting)[Embeddings](https://platform.claude.com/docs/en/build-with-claude/embeddings)[Vision](https://platform.claude.com/docs/en/build-with-claude/vision)[PDF support](https://platform.claude.com/docs/en/build-with-claude/pdf-support)[Files API](https://platform.claude.com/docs/en/build-with-claude/files)[Search results](https://platform.claude.com/docs/en/build-with-claude/search-results)[Structured outputs](https://platform.claude.com/docs/en/build-with-claude/structured-outputs)
Tools
[Overview](https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview)[How to implement tool use](https://platform.claude.com/docs/en/agents-and-tools/tool-use/implement-tool-use)[Fine-grained tool streaming](https://platform.claude.com/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming)[Bash tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/bash-tool)[Code execution tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool)[Programmatic tool calling](https://platform.claude.com/docs/en/agents-and-tools/tool-use/programmatic-tool-calling)[Computer use tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/computer-use-tool)[Text editor tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool)[Web fetch tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-fetch-tool)[Web search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-search-tool)[Memory tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/memory-tool)[Tool search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)
Agent Skills
[Overview](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview)[Quickstart](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/quickstart)[Best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices)[Skills for enterprise](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/enterprise)[Using Skills with the API](https://platform.claude.com/docs/en/build-with-claude/skills-guide)
Agent SDK
[Overview](https://platform.claude.com/docs/en/agent-sdk/overview)[Quickstart](https://platform.claude.com/docs/en/agent-sdk/quickstart)[TypeScript SDK](https://platform.claude.com/docs/en/agent-sdk/typescript)[TypeScript V2 (preview)](https://platform.claude.com/docs/en/agent-sdk/typescript-v2-preview)[Python SDK](https://platform.claude.com/docs/en/agent-sdk/python)[Migration Guide](https://platform.claude.com/docs/en/agent-sdk/migration-guide)
Guides
MCP in the API
[MCP connector](https://platform.claude.com/docs/en/agents-and-tools/mcp-connector)[Remote MCP servers](https://platform.claude.com/docs/en/agents-and-tools/remote-mcp-servers)
Claude on 3rd-party platforms
[Amazon Bedrock](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock)[Microsoft Foundry](https://platform.claude.com/docs/en/build-with-claude/claude-in-microsoft-foundry)[Vertex AI](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai)
Prompt engineering
[Overview](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview)[Prompt generator](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-generator)[Use prompt templates](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-templates-and-variables)[Prompt improver](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-improver)[Be clear and direct](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)[Use examples (multishot prompting)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/multishot-prompting)[Let Claude think (CoT)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought)[Use XML tags](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags)[Give Claude a role (system prompts)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/system-prompts)[Chain complex prompts](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-prompts)[Long context tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/long-context-tips)[Extended thinking tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips)
Test & evaluate
[Define success criteria](https://platform.claude.com/docs/en/test-and-evaluate/define-success)[Develop test cases](https://platform.claude.com/docs/en/test-and-evaluate/develop-tests)[Using the Evaluation Tool](https://platform.claude.com/docs/en/test-and-evaluate/eval-tool)[Reducing latency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-latency)
Strengthen guardrails
[Reduce hallucinations](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-hallucinations)[Increase output consistency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/increase-consistency)[Mitigate jailbreaks](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)[Streaming refusals](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals)[Reduce prompt leak](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak)[Keep Claude in character](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/keep-claude-in-character)
Administration and monitoring
[Admin API overview](https://platform.claude.com/docs/en/build-with-claude/administration-api)[Data residency](https://platform.claude.com/docs/en/build-with-claude/data-residency)[Workspaces](https://platform.claude.com/docs/en/build-with-claude/workspaces)[Usage and Cost API](https://platform.claude.com/docs/en/build-with-claude/usage-cost-api)[Claude Code Analytics API](https://platform.claude.com/docs/en/build-with-claude/claude-code-analytics-api)[Zero Data Retention](https://platform.claude.com/docs/en/build-with-claude/zero-data-retention)
[Console](https://platform.claude.com/)
[Log in](https://platform.claude.com/login)
Models & pricingPricing
Models & pricing
# Pricing
Copy page
Learn about Anthropic's pricing structure for models and features
Copy page
This page provides detailed pricing information for Anthropic's models and features. All prices are in USD.
For the most current pricing information, please visit [claude.com/pricing](https://claude.com/pricing).
## 
Model pricing
The following table shows pricing for all Claude models across different usage tiers:
Model | Base Input Tokens | 5m Cache Writes | 1h Cache Writes | Cache Hits & Refreshes | Output Tokens  
---|---|---|---|---|---  
Claude Opus 4.6 | $5 / MTok | $6.25 / MTok | $10 / MTok | $0.50 / MTok | $25 / MTok  
Claude Opus 4.5 | $5 / MTok | $6.25 / MTok | $10 / MTok | $0.50 / MTok | $25 / MTok  
Claude Opus 4.1 | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Opus 4 | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Sonnet 4.5 | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Sonnet 4 | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Sonnet 3.7 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $3 / MTok | $3.75 / MTok | $6 / MTok | $0.30 / MTok | $15 / MTok  
Claude Haiku 4.5 | $1 / MTok | $1.25 / MTok | $2 / MTok | $0.10 / MTok | $5 / MTok  
Claude Haiku 3.5 | $0.80 / MTok | $1 / MTok | $1.6 / MTok | $0.08 / MTok | $4 / MTok  
Claude Opus 3 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $15 / MTok | $18.75 / MTok | $30 / MTok | $1.50 / MTok | $75 / MTok  
Claude Haiku 3 | $0.25 / MTok | $0.30 / MTok | $0.50 / MTok | $0.03 / MTok | $1.25 / MTok  
MTok = Million tokens. The "Base Input Tokens" column shows standard input pricing, "Cache Writes" and "Cache Hits" are specific to [prompt caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching), and "Output Tokens" shows output pricing. Prompt caching offers both 5-minute (default) and 1-hour cache durations to optimize costs for different use cases.
The table above reflects the following pricing multipliers for prompt caching:
  * 5-minute cache write tokens are 1.25 times the base input tokens price
  * 1-hour cache write tokens are 2 times the base input tokens price
  * Cache read tokens are 0.1 times the base input tokens price


## 
Third-party platform pricing
Claude models are available on [AWS Bedrock](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock), [Google Vertex AI](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai), and [Microsoft Foundry](https://platform.claude.com/docs/en/build-with-claude/claude-in-microsoft-foundry). For official pricing, visit:
  * [AWS Bedrock pricing](https://aws.amazon.com/bedrock/pricing/)
  * [Google Vertex AI pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing)
  * [Microsoft Foundry pricing](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing)


**Regional endpoint pricing for Claude 4.5 models and beyond**
Starting with Claude Sonnet 4.5 and Haiku 4.5, AWS Bedrock and Google Vertex AI offer two endpoint types:
  * **Global endpoints** : Dynamic routing across regions for maximum availability
  * **Regional endpoints** : Data routing guaranteed within specific geographic regions


Regional endpoints include a 10% premium over global endpoints. **The Claude API (1P) is global by default and unaffected by this change.** The Claude API is global-only (equivalent to the global endpoint offering and pricing from other providers).
**Scope** : This pricing structure applies to Claude Sonnet 4.5, Haiku 4.5, and all future models. Earlier models (Claude Sonnet 4, Opus 4, and prior releases) retain their existing pricing.
For implementation details and code examples:
  * [AWS Bedrock global vs regional endpoints](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock#global-vs-regional-endpoints)
  * [Google Vertex AI global vs regional endpoints](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai#global-vs-regional-endpoints)


## 
Feature-specific pricing
### 
Data residency pricing
For Claude Opus 4.6 and newer models, specifying US-only inference via the `inference_geo` parameter incurs a 1.1x multiplier on all token pricing categories, including input tokens, output tokens, cache writes, and cache reads. Global routing (the default) uses standard pricing.
This applies to the Claude API (1P) only. Third-party platforms have their own regional pricing. See [AWS Bedrock](https://aws.amazon.com/bedrock/pricing/), [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/pricing), and [Microsoft Foundry](https://azure.microsoft.com/en-us/pricing/details/ai-foundry/#pricing) for details. Earlier models retain their existing pricing regardless of `inference_geo` settings.
For more information, see the [data residency documentation](https://platform.claude.com/docs/en/build-with-claude/data-residency).
### 
Fast mode pricing
[Fast mode](https://platform.claude.com/docs/en/build-with-claude/fast-mode) for Claude Opus 4.6 (resesarch preview) provides significantly faster output at premium pricing (6x standard rates). Currently supported on Opus 4.6:
Context window | Input | Output  
---|---|---  
‚â§ 200K input tokens | $30 / MTok | $150 / MTok  
> 200K input tokens | $60 / MTok | $225 / MTok  
Fast mode pricing stacks with other pricing modifiers:
  * [Prompt caching multipliers](https://platform.claude.com/docs/en/about-claude/pricing#model-pricing) apply on top of fast mode pricing
  * [Data residency](https://platform.claude.com/docs/en/build-with-claude/data-residency) multipliers apply on top of fast mode pricing


Fast mode is not available with the [Batch API](https://platform.claude.com/docs/en/about-claude/pricing#batch-processing).
For more information, see the [fast mode documentation](https://platform.claude.com/docs/en/build-with-claude/fast-mode).
### 
Batch processing
The Batch API allows asynchronous processing of large volumes of requests with a 50% discount on both input and output tokens.
Model | Batch input | Batch output  
---|---|---  
Claude Opus 4.6 | $2.50 / MTok | $12.50 / MTok  
Claude Opus 4.5 | $2.50 / MTok | $12.50 / MTok  
Claude Opus 4.1 | $7.50 / MTok | $37.50 / MTok  
Claude Opus 4 | $7.50 / MTok | $37.50 / MTok  
Claude Sonnet 4.5 | $1.50 / MTok | $7.50 / MTok  
Claude Sonnet 4 | $1.50 / MTok | $7.50 / MTok  
Claude Sonnet 3.7 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $1.50 / MTok | $7.50 / MTok  
Claude Haiku 4.5 | $0.50 / MTok | $2.50 / MTok  
Claude Haiku 3.5 | $0.40 / MTok | $2 / MTok  
Claude Opus 3 ([deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations)) | $7.50 / MTok | $37.50 / MTok  
Claude Haiku 3 | $0.125 / MTok | $0.625 / MTok  
For more information about batch processing, see the [batch processing documentation](https://platform.claude.com/docs/en/build-with-claude/batch-processing).
### 
Long context pricing
When using Claude Opus 4.6, Sonnet 4.5, or Sonnet 4 with the [1M token context window enabled](https://platform.claude.com/docs/en/build-with-claude/context-windows#1m-token-context-window), requests that exceed 200K input tokens are automatically charged at premium long context rates:
The 1M token context window is currently in beta for organizations in [usage tier](https://platform.claude.com/docs/en/api/rate-limits) 4 and organizations with custom rate limits. The 1M token context window is only available for Claude Opus 4.6, Sonnet 4.5, and Sonnet 4.
Model | ‚â§ 200K input tokens | > 200K input tokens  
---|---|---  
Claude Opus 4.6 | Input: $5 / MTok | Input: $10 / MTok  
| Output: $25 / MTok | Output: $37.50 / MTok  
Claude Sonnet 4.5 / 4 | Input: $3 / MTok | Input: $6 / MTok  
| Output: $15 / MTok | Output: $22.50 / MTok  
Long context pricing stacks with other pricing modifiers:
  * The [Batch API 50% discount](https://platform.claude.com/docs/en/about-claude/pricing#batch-processing) applies to long context pricing
  * [Prompt caching multipliers](https://platform.claude.com/docs/en/about-claude/pricing#model-pricing) apply on top of long context pricing
  * The [data residency 1.1x multiplier](https://platform.claude.com/docs/en/about-claude/pricing#data-residency-pricing) applies on top of long context pricing


Even with the beta flag enabled, requests with fewer than 200K input tokens are charged at standard rates. If your request exceeds 200K input tokens, all tokens incur premium pricing.
The 200K threshold is based solely on input tokens (including cache reads/writes). Output token count does not affect pricing tier selection, though output tokens are charged at the higher rate when the input threshold is exceeded.
To check if your API request was charged at the 1M context window rates, examine the `usage` object in the API response:
```
{
  "usage": {
    "input_tokens": 250000,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "output_tokens": 500
  }
}
```

Calculate the total input tokens by summing:
  * `input_tokens`
  * `cache_creation_input_tokens` (if using prompt caching)
  * `cache_read_input_tokens` (if using prompt caching)


If the total exceeds 200,000 tokens, the entire request was billed at 1M context rates.
For more information about the `usage` object, see the [API response documentation](https://platform.claude.com/docs/en/api/messages#response-usage).
### 
Tool use pricing
Tool use requests are priced based on:
  1. The total number of input tokens sent to the model (including in the `tools` parameter)
  2. The number of output tokens generated
  3. For server-side tools, additional usage-based pricing (e.g., web search charges per search performed)


Client-side tools are priced the same as any other Claude API request, while server-side tools may incur additional charges based on their specific usage.
The additional tokens from tool use come from:
  * The `tools` parameter in API requests (tool names, descriptions, and schemas)
  * `tool_use` content blocks in API requests and responses
  * `tool_result` content blocks in API requests


When you use `tools`, we also automatically include a special system prompt for the model which enables tool use. The number of tool use tokens required for each model are listed below (excluding the additional tokens listed above). Note that the table assumes

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://ai.google.dev/gemini-api/docs/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://ai.google.dev/gemini-api/docs/pricing                      
| ‚úì | ‚è±: 2.16s 
[SCRAPE].. ‚óÜ https://ai.google.dev/gemini-api/docs/pricing                      
| ‚úì | ‚è±: 0.06s 
[COMPLETE] ‚óè https://ai.google.dev/gemini-api/docs/pricing                      
| ‚úì | ‚è±: 2.22s 
[ Skip to main content ](https://ai.google.dev/gemini-api/docs/pricing#main-content)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
`/`
  * English
  * Deutsch
  * Espa√±ol ‚Äì Am√©rica Latina
  * Fran√ßais
  * Indonesia
  * Italiano
  * Polski
  * Portugu√™s ‚Äì Brasil
  * Shqip
  * Ti√™ÃÅng Vi√™Ã£t
  * T√ºrk√ße
  * –†—É—Å—Å–∫–∏–π
  * ◊¢◊ë◊®◊ô◊™
  * ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©
  * ŸÅÿßÿ±ÿ≥€å
  * ‡§π‡§ø‡§Ç‡§¶‡•Ä
  * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
  * ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
  * ‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì
  * ‰∏≠Êñá ‚Äì ÁπÅÈ´î
  * Êó•Êú¨Ë™û
  * ÌïúÍµ≠Ïñ¥

[ Get API key ](https://aistudio.google.com/apikey) [ Cookbook ](https://github.com/google-gemini/cookbook) [ Community ](https://discuss.ai.google.dev/c/gemini-api/) Sign in
[ Docs ](https://ai.google.dev/gemini-api/docs) [ API reference ](https://ai.google.dev/api)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
  * [ Gemini API  ](https://ai.google.dev/gemini-api/docs)
    * [ Docs  ](https://ai.google.dev/gemini-api/docs)
    * [ API reference  ](https://ai.google.dev/api)
  * [ Get API key  ](https://aistudio.google.com/apikey)
  * [ Cookbook  ](https://github.com/google-gemini/cookbook)
  * [ Community  ](https://discuss.ai.google.dev/c/gemini-api/)


  * Get started
  * [Overview](https://ai.google.dev/gemini-api/docs)
  * [Quickstart](https://ai.google.dev/gemini-api/docs/quickstart)
  * [API keys](https://ai.google.dev/gemini-api/docs/api-key)
  * [Libraries](https://ai.google.dev/gemini-api/docs/libraries)
  * [Interactions API](https://ai.google.dev/gemini-api/docs/interactions)
  * Models
  * [Gemini](https://ai.google.dev/gemini-api/docs/models)
  * [Gemini 3](https://ai.google.dev/gemini-api/docs/gemini-3)
  * [Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation)
  * [Veo](https://ai.google.dev/gemini-api/docs/video)
  * [Lyria](https://ai.google.dev/gemini-api/docs/music-generation)
  * [Imagen](https://ai.google.dev/gemini-api/docs/imagen)
  * [Embeddings](https://ai.google.dev/gemini-api/docs/embeddings)
  * [Robotics](https://ai.google.dev/gemini-api/docs/robotics-overview)
  * [Text-to-speech](https://ai.google.dev/gemini-api/docs/speech-generation)
  * [Pricing](https://ai.google.dev/gemini-api/docs/pricing)
  * [Rate limits](https://ai.google.dev/gemini-api/docs/rate-limits)
  * Core capabilities
  * [Text](https://ai.google.dev/gemini-api/docs/text-generation)
  * Image
    * [Image generation üçå](https://ai.google.dev/gemini-api/docs/image-generation)
    * [Image understanding](https://ai.google.dev/gemini-api/docs/image-understanding)
  * Video
    * [Video generation](https://ai.google.dev/gemini-api/docs/video)
    * [Video understanding](https://ai.google.dev/gemini-api/docs/video-understanding)
  * [Documents](https://ai.google.dev/gemini-api/docs/document-processing)
  * Speech and audio
    * [Speech generation](https://ai.google.dev/gemini-api/docs/speech-generation)
    * [Audio understanding](https://ai.google.dev/gemini-api/docs/audio)
  * Thinking
    * [Thinking](https://ai.google.dev/gemini-api/docs/thinking)
    * [Thought signatures](https://ai.google.dev/gemini-api/docs/thought-signatures)
  * [Structured outputs](https://ai.google.dev/gemini-api/docs/structured-output)
  * [Function calling](https://ai.google.dev/gemini-api/docs/function-calling)
  * [Long context](https://ai.google.dev/gemini-api/docs/long-context)
  * Tools and agents
  * [Overview](https://ai.google.dev/gemini-api/docs/tools)
  * [Deep Research](https://ai.google.dev/gemini-api/docs/deep-research)
  * [Google Search](https://ai.google.dev/gemini-api/docs/google-search)
  * [Google Maps](https://ai.google.dev/gemini-api/docs/maps-grounding)
  * [Code execution](https://ai.google.dev/gemini-api/docs/code-execution)
  * [URL context](https://ai.google.dev/gemini-api/docs/url-context)
  * [Computer Use](https://ai.google.dev/gemini-api/docs/computer-use)
  * [File Search](https://ai.google.dev/gemini-api/docs/file-search)
  * Live API
  * [Get started](https://ai.google.dev/gemini-api/docs/live)
  * [Capabilities](https://ai.google.dev/gemini-api/docs/live-guide)
  * [Tool use](https://ai.google.dev/gemini-api/docs/live-tools)
  * [Session management](https://ai.google.dev/gemini-api/docs/live-session)
  * [Ephemeral tokens](https://ai.google.dev/gemini-api/docs/ephemeral-tokens)
  * Guides
  * [Batch API](https://ai.google.dev/gemini-api/docs/batch-api)
  * File input
    * [Input methods](https://ai.google.dev/gemini-api/docs/file-input-methods)
    * [Files API](https://ai.google.dev/gemini-api/docs/files)
  * [Context caching](https://ai.google.dev/gemini-api/docs/caching)
  * [OpenAI compatibility](https://ai.google.dev/gemini-api/docs/openai)
  * [Media resolution](https://ai.google.dev/gemini-api/docs/media-resolution)
  * [Token counting](https://ai.google.dev/gemini-api/docs/tokens)
  * [Prompt engineering](https://ai.google.dev/gemini-api/docs/prompting-strategies)
  * Logs and datasets
    * [Get started with logs](https://ai.google.dev/gemini-api/docs/logs-datasets)
    * [Data logging and sharing](https://ai.google.dev/gemini-api/docs/logs-policy)
  * Safety
    * [Safety settings](https://ai.google.dev/gemini-api/docs/safety-settings)
    * [Safety guidance](https://ai.google.dev/gemini-api/docs/safety-guidance)
  * Frameworks
    * [LangChain & LangGraph](https://ai.google.dev/gemini-api/docs/langgraph-example)
    * [CrewAI](https://ai.google.dev/gemini-api/docs/crewai-example)
    * [LlamaIndex](https://ai.google.dev/gemini-api/docs/llama-index)
    * [Vercel AI SDK](https://ai.google.dev/gemini-api/docs/vercel-ai-sdk-example)
  * Resources
  * [Migrate to Gen AI SDK](https://ai.google.dev/gemini-api/docs/migrate)
  * [Release notes](https://ai.google.dev/gemini-api/docs/changelog)
  * [Deprecations](https://ai.google.dev/gemini-api/docs/deprecations)
  * [API troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshooting)
  * [Billing info](https://ai.google.dev/gemini-api/docs/billing)
  * [Partner and library integrations](https://ai.google.dev/gemini-api/docs/partner-integration)
  * Google AI Studio
    * [Quickstart](https://ai.google.dev/gemini-api/docs/ai-studio-quickstart)
    * [Vibe code in Build mode](https://ai.google.dev/gemini-api/docs/aistudio-build-mode)
    * [Try out LearnLM](https://ai.google.dev/gemini-api/docs/learnlm)
    * [Troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio)
    * [Access for Workspace users](https://ai.google.dev/gemini-api/docs/workspace)
  * Google Cloud Platform
    * [VertexAI Gemini API](https://ai.google.dev/gemini-api/docs/migrate-to-cloud)
    * [OAuth authentication](https://ai.google.dev/gemini-api/docs/oauth)
  * Policies
  * [Terms of service](https://ai.google.dev/gemini-api/terms)
  * [Available regions](https://ai.google.dev/gemini-api/docs/available-regions)
  * [Additional usage polices](https://ai.google.dev/gemini-api/docs/usage-policies)


  * [ Home ](https://ai.google.dev/)
  * [ Gemini API ](https://ai.google.dev/gemini-api)
  * [ Docs ](https://ai.google.dev/gemini-api/docs)


#  Gemini Developer API pricing
Start building free of charge with generous limits, then scale up with pay-as-you-go pricing for your production ready applications.
### Free
For developers and small projects getting started with the Gemini API.
  * check_circleLimited access to certain models
  * check_circleFree input & output tokens
  * check_circleGoogle AI Studio access
  * check_circleContent used to improve our products[*](https://ai.google.dev/gemini-api/terms)

[Get started for Free](https://aistudio.google.com)
### Paid
For production applications that require higher volumes and advanced features.
  * check_circleHigher rate limits for production deployments
  * check_circleAccess to Context caching
  * check_circleBatch API (50% cost reduction)
  * check_circleAccess to Google's most advanced models
  * check_circleContent **not** used to improve our products[*](https://ai.google.dev/gemini-api/terms)

[Upgrade to Paid](https://aistudio.google.com/api-keys)
### Enterprise
For large-scale deployments with custom needs for security, support, and compliance, powered by [Vertex AI](https://cloud.google.com/vertex-ai).
  * check_circleAll features in Paid, plus optional access to:
  * check_circleDedicated support channels
  * check_circleAdvanced security & compliance
  * check_circleProvisioned throughput
  * check_circleVolume-based discounts (based on usage)
  * check_circleML ops, model garden and more

[Contact Sales](https://cloud.google.com/contact)
## Gemini 3 Pro Preview
_`gemini-3-pro-preview`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-3-pro-preview)
The best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $2.00, prompts <= 200k tokens  
$4.00, prompts > 200k tokens  
Output price (including thinking tokens) | Not available | $12.00, prompts <= 200k tokens  
$18.00, prompts > 200k  
Context caching price | Not available | $0.20, prompts <= 200k tokens  
$0.40, prompts > 200k  
$4.50 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search* | Not available | 5,000 prompts per month (free), then $14 / 1,000 search queries  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $1.00, prompts <= 200k tokens  
$2.00, prompts > 200k tokens  
Output price (including thinking tokens) | Not available | $6.00, prompts <= 200k tokens  
$9.00, prompts > 200k  
Context caching price | Not available | $0.20, prompts <= 200k tokens  
$0.40, prompts > 200k  
$4.50 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search* | Not available | 1,500 RPD (free), then $14 / 1,000 search queries  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
* A customer-submitted request to Gemini may result in one or more queries to Google Search. You will be charged for each individual search query performed.
## Gemini 3 Flash Preview
_`gemini-3-flash-preview`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-3-flash-preview)
Our most intelligent model built for speed, combining frontier intelligence with superior search and grounding.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Free of charge | $0.50 (text / image / video)  
$1.00 (audio)  
Output price (including thinking tokens) | Free of charge | $3.00  
Context caching price | Free of charge | $0.05 (text / image / video)  
$0.10 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search* | Not available | 5,000 prompts per month (free), then $14 / 1,000 search queries  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $0.25 (text / image / video)  
$0.50 (audio)  
Output price (including thinking tokens) | Not available | $1.50  
Context caching price | Not available |  _Same as Standard, Batch pricing not yet implemented_  
$0.05 (text / image / video)  
$0.10 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)   
Grounding with Google Search* | Not available | 1,500 RPD (free), then $14 / 1,000 search queries  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
* A customer-submitted request to Gemini may result in one or more queries to Google Search. You will be charged for each individual search query performed.
## Gemini 3 Pro Image Preview üçå
_`gemini-3-pro-image-preview`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-3-pro-image-preview)
Our native image generation model, optimized for speed, flexibility, and contextual understanding. **Text input and output** is priced the same as [Gemini 3 Pro](https://ai.google.dev/gemini-api/docs/pricing#gemini-3-pro-preview).
Preview models may change before becoming stable and have more restrictive rate limits.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $2.00 (text/image),  
equivalent to $0.0011 per image*  
Output price | Not available | $12.00 (text and thinking)  
$120.00 (images)  
equivalent to $0.134 per 1K/2K image**  
and $0.24 per 4K image**  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $1.00 (text),  
$0.0006 (image)*  
Output price | Not available | $6.00 (text and thinking)  
$0.067 per 1K/2K image**  
$0.12 per 4K image**  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
* Image input is set at 560 tokens or $0.0011 per image.
** Image output is priced at $120 per 1,000,000 tokens. Output images from 1024x1024px (1K) and up to 2048x2048px (2K) consume 1120 tokens and are equivalent to $0.134 per image. Output images up to 4096x4096px (4K) consume 2000 tokens and are equivalent to $0.24 per image.
## Gemini 2.5 Pro
_`gemini-2.5-pro`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-pro)
Our state-of-the-art multipurpose model, which excels at coding and complex reasoning tasks.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Free of charge | $1.25, prompts <= 200k tokens  
$2.50, prompts > 200k tokens  
Output price (including thinking tokens) | Free of charge | $10.00, prompts <= 200k tokens  
$15.00, prompts > 200k  
Context caching price | Not available | $0.125, prompts <= 200k tokens  
$0.25, prompts > 200k  
$4.50 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Not available | 1,500 RPD (free), then $35 / 1,000 grounded prompts  
Grounding with Google Maps | Not available | 10,000 RPD (free), then $25 / 1,000 grounded prompts  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $0.625, prompts <= 200k tokens  
$1.25, prompts > 200k tokens  
Output price (including thinking tokens) | Not available | $5.00, prompts <= 200k tokens  
$7.50, prompts > 200k  
Context caching price | Not available | $0.125, prompts <= 200k tokens  
$0.25, prompts > 200k  
$4.50 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Not available | 1,500 RPD (free), then $35 / 1,000 grounded prompts  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
## Gemini 2.5 Flash
_`gemini-2.5-flash`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash)
Our first hybrid reasoning model which supports a 1M token context window and has thinking budgets.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Free of charge | $0.30 (text / image / video)  
$1.00 (audio)  
Output price (including thinking tokens) | Free of charge | $2.50  
Context caching price | Not available | $0.03 (text / image / video)  
$0.1 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash-Lite RPD) | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts  
Grounding with Google Maps | 500 RPD | 1,500 RPD (free), then $25 / 1,000 grounded prompts  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $0.15 (text / image / video)  
$0.50 (audio)  
Output price (including thinking tokens) | Not available | $1.25  
Context caching price | Not available | $0.03 (text / image / video)  
$0.1 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts  
Grounding with Google Maps | Not available | Not available  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
## Gemini 2.5 Flash Preview
_`gemini-2.5-flash-preview-09-2025`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-preview-09-2025)
The latest model based on the 2.5 Flash model. 2.5 Flash Preview is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Free of charge | $0.30 (text / image / video)  
$1.00 (audio)  
Output price (including thinking tokens) | Free of charge | $2.50  
Context caching price | Not available | $0.03 (text / image / video)  
$0.1 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash-Lite RPD) | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price | Not available | $0.15 (text / image / video)  
$0.50 (audio)  
Output price (including thinking tokens) | Not available | $1.25  
Context caching price | Not available | $0.03 (text / image / video)  
$0.1 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Not available | 1,500 RPD (free, limit shared with Flash-Lite RPD), then $35 / 1,000 grounded prompts  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
## Gemini 2.5 Flash-Lite
_`gemini-2.5-flash-lite`_
[Try it in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite)
Our smallest and most cost effective model, built for at scale usage.
### Standard
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price (text, image, video) | Free of charge | $0.10 (text / image / video)  
$0.30 (audio)  
Output price (including thinking tokens) | Free of charge | $0.40  
Context caching price | Not available | $0.01 (text / image / video)  
$0.03 (audio)  
$1.00 / 1,000,000 tokens per hour (storage price)  
Grounding with Google Search | Free of charge, up to 500 RPD (limit shared with Flash RPD) | 1,500 RPD (free, limit shared with Flash RPD), then $35 / 1,000 grounded prompts  
Grounding with Google Maps | 500 RPD | 1,500 RPD (free), then $25 / 1,000 grounded prompts  
Used to improve our products | [Yes](https://ai.google.dev/gemini-api/terms) | [No](https://ai.google.dev/gemini-api/terms)  
### Batch
| Free Tier | Paid Tier, per 1M tokens in USD  
---|---|---  
Input price (text, image, video) | Not available | $0.05 (text / image / video)  
$0.15 (audio)  
Output price (including thinking tokens) | Not available |

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.moonshot.ai/docs/pricing/chat

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.moonshot.ai/docs/pricing/chat                     
| ‚úì | ‚è±: 1.15s 
[SCRAPE].. ‚óÜ https://platform.moonshot.ai/docs/pricing/chat                     
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://platform.moonshot.ai/docs/pricing/chat                     
| ‚úì | ‚è±: 1.17s 
üéâ New kimi k2.5 Multi-modal Model released! Now supports multimodal understanding and processing. [Limited-time top-up bonus is live](https://platform.moonshot.ai/docs/promotion)!
[Platform](https://platform.moonshot.ai/)[Contact Sales](https://platform.moonshot.ai/contact-sales)[Blog](https://platform.moonshot.ai/blog)[Docs](https://platform.moonshot.ai/docs/overview)[Playground](https://platform.moonshot.ai/playground)[Console](https://platform.moonshot.ai/console)
`CTRL K`
`CTRL K`
  * [Welcome](https://platform.moonshot.ai/docs/overview)
  * [User Manual](https://platform.moonshot.ai/docs/introduction)
  * API Reference
    * [Chat](https://platform.moonshot.ai/docs/api/chat)
    * [Tool Use](https://platform.moonshot.ai/docs/api/tool-use)
    * [Partial Mode](https://platform.moonshot.ai/docs/api/partial)
    * [Files](https://platform.moonshot.ai/docs/api/files)
    * [Estimate Token](https://platform.moonshot.ai/docs/api/estimate)
    * [Check Balance](https://platform.moonshot.ai/docs/api/balance)
  * [üéâ Promotions](https://platform.moonshot.ai/docs/promotion)
  * Product Pricing
    * [Chat Pricing](https://platform.moonshot.ai/docs/pricing/chat)
    * [WebSearch Pricing](https://platform.moonshot.ai/docs/pricing/tools)
    * [Recharge and Rate Limiting](https://platform.moonshot.ai/docs/pricing/limits)
    * [FAQ](https://platform.moonshot.ai/docs/pricing/faq)
  * Getting Started Guide
    * [Kimi K2.5 Multi-modal Model](https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart)
    * [Kimi K2](https://platform.moonshot.ai/docs/guide/kimi-k2-quickstart)
    * [Using Thinking Models](https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model)
    * [Quickstart with Kimi API](https://platform.moonshot.ai/docs/guide/start-using-kimi-api)
    * [Use Kimi K2.5 in OpenClaw](https://platform.moonshot.ai/docs/guide/use-kimi-in-openclaw)
    * [Switch from OpenAI to Kimi API](https://platform.moonshot.ai/docs/guide/migrating-from-openai-to-kimi)
    * [Use the API Debugging Tool](https://platform.moonshot.ai/docs/guide/use-moonpalace)
    * [Conduct Multi-turn Chat with Kimi API](https://platform.moonshot.ai/docs/guide/engage-in-multi-turn-conversations-using-kimi-api)
    * [Use the Kimi Vision Model](https://platform.moonshot.ai/docs/guide/use-kimi-vision-model)
    * [Automatic Reconnection](https://platform.moonshot.ai/docs/guide/auto-reconnect)
    * [Use the Streaming Feature of the Kimi API](https://platform.moonshot.ai/docs/guide/utilize-the-streaming-output-feature-of-kimi-api)
    * [Use Tool Calls with Kimi API](https://platform.moonshot.ai/docs/guide/use-kimi-api-to-complete-tool-calls)
    * [Use the Web Search Tool](https://platform.moonshot.ai/docs/guide/use-web-search)
    * [Use JSON Mode with Kimi API](https://platform.moonshot.ai/docs/guide/use-json-mode-feature-of-kimi-api)
    * [Use Partial Mode with Kimi API](https://platform.moonshot.ai/docs/guide/use-partial-mode-feature-of-kimi-api)
    * [Use Kimi API for File-Based Q&A](https://platform.moonshot.ai/docs/guide/use-kimi-api-for-file-based-qa)
    * [Use Playground to Debug the Model](https://platform.moonshot.ai/docs/guide/use-playground-to-debug-the-model)
    * [Use kimi-k2 Model in ClaudeCode/Cline/RooCode](https://platform.moonshot.ai/docs/guide/agent-support)
    * [Configure ModelScope MCP Server in Playground](https://platform.moonshot.ai/docs/guide/configure-the-modelscope-mcp-server)
    * [Use Official Tools in Kimi API](https://platform.moonshot.ai/docs/guide/use-official-tools)
    * [Use Kimi CLI to Call Kimi Model](https://platform.moonshot.ai/docs/guide/kimi-cli-support)
    * [Use Kimi K2 Model to Setup Agent](https://platform.moonshot.ai/docs/guide/use-kimi-k2-to-setup-agent)
    * [Best Practices for Benchmarking](https://platform.moonshot.ai/docs/guide/benchmark-best-practice)
    * [Best Practices for Prompts](https://platform.moonshot.ai/docs/guide/prompt-best-practice)
    * [Best Practices for Organization Management](https://platform.moonshot.ai/docs/guide/org-best-practice)
    * [Frequently Asked Questions and Solutions](https://platform.moonshot.ai/docs/guide/faq)
  * Terms and Agreement
    * [Terms of Service for Kimi OpenPlatform](https://platform.moonshot.ai/docs/agreement/modeluse)
    * [Kimi OpenPlatform Privacy Policy](https://platform.moonshot.ai/docs/agreement/userprivacy)


  * [Moonshot‚Üó (opens in a new tab)](https://www.moonshot.ai/)
  * [Forum‚Üó (opens in a new tab)](https://forum.moonshot.ai/)
  * [Discord‚Üó (opens in a new tab)](https://discord.gg/TYU2fdJykW)
  * Contact Us Via Email‚Üó (opens in a new tab)
  * [‰∏≠ÂõΩÁ´ô | platform.moonshot.cn‚Üó (opens in a new tab)](https://platform.moonshot.cn/)


Outline
  * [Concepts](https://platform.moonshot.ai/docs/pricing/chat#concepts)
  * [Billing Unit](https://platform.moonshot.ai/docs/pricing/chat#billing-unit)
  * [Product Pricing](https://platform.moonshot.ai/docs/pricing/chat#product-pricing)
  * [Multi-modal Model kimi-k2.5 ](https://platform.moonshot.ai/docs/pricing/chat#multi-modal-model-kimi-k25-)
  * [Generation Model kimi-k2](https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2)
  * [Generation Model Moonshot-v1](https://platform.moonshot.ai/docs/pricing/chat#generation-model-moonshot-v1)


Back to top
Docs
Product Pricing
Chat Pricing
# Model Inference Pricing Explanation
##  Concepts[](https://platform.moonshot.ai/docs/pricing/chat#concepts)
###  Billing Unit[](https://platform.moonshot.ai/docs/pricing/chat#billing-unit)
Token: A token represents a common sequence of characters. The number of tokens used for each English character may vary. For example, a single character like "antidisestablishmentarianism" might be broken down into several tokens, while a short and common phrase like "word" might use just one token.Generally speaking, for a typical English text, 1 token is roughly equivalent to 3-4 English characters. The exact number of tokens generated by each call can be obtained through the [Token Calculation API](https://platform.moonshot.ai/docs/api/misc#%E8%AE%A1%E7%AE%97-token).
####  Billing Logic[](https://platform.moonshot.ai/docs/pricing/chat#billing-logic)
Chat Completion API charges: We bill both the Input and Output based on usage. If you upload and extract content from a document and then pass the extracted content as Input to the model, the document content will also be billed based on usage.File-related interfaces (file content extraction/file storage) are **temporarily free**. In other words, if you only upload and extract a document, this API itself will not incur any charges.
##  Product Pricing[](https://platform.moonshot.ai/docs/pricing/chat#product-pricing)
**ExplanationÔºöThe prices listed below are all inclusive of tax.**
###  Multi-modal Model kimi-k2.5 [Recharge](https://platform.moonshot.ai/console/pay)[](https://platform.moonshot.ai/docs/pricing/chat#multi-modal-model-kimi-k25-)
Model | Unit | Input Price  
ÔºàCache HitÔºâ | Input Price  
ÔºàCache MissÔºâ | Output Price | Context Window  
---|---|---|---|---|---  
kimi-k2.5 | 1M tokens | $0.10 | $0.60 | $3.00 | 262,144 tokens  
  * kimi-k2.5 is Kimi's most versatile model to date, featuring a native multimodal architecture that supports both visual and text input, thinking and non-thinking modes, and dialogue and agent tasks.
  * Context length 256k, supports long thinking and deep reasoning.
  * Supports automatic context caching functionality, ToolCalls, JSON Mode, Partial Mode, and internet search functionality.


###  Generation Model kimi-k2[](https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2)
Model | Unit | Input Price  
ÔºàCache HitÔºâ | Input Price  
ÔºàCache MissÔºâ | Output Price | Context Window  
---|---|---|---|---|---  
kimi-k2-0905-preview | 1M tokens | $0.15 | $0.60 | $2.50 | 262,144 tokens  
kimi-k2-0711-preview | 1M tokens | $0.15 | $0.60 | $2.50 | 131,072 tokens  
kimi-k2-turbo-previewRecommended | 1M tokens | $0.15 | $1.15 | $8.00 | 262,144 tokens  
kimi-k2-thinking | 1M tokens | $0.15 | $0.60 | $2.50 | 262,144 tokens  
kimi-k2-thinking-turbo | 1M tokens | $0.15 | $1.15 | $8.00 | 262,144 tokens  
  * kimi-k2 is a Mixture-of-Experts (MoE) foundation model with exceptional coding and agent capabilities, featuring 1 trillion total parameters and 32 billion activated parameters. In benchmark evaluations covering general knowledge reasoning, programming, mathematics, and agent-related tasks, the K2 model outperforms other leading open-source models
  * kimi-k2-0905-preview: Context length 256k. Based on kimi-k2-0711-preview, with enhanced agentic coding abilities, improved frontend code quality and practicality, and better context understanding
  * kimi-k2-turbo-preview: Context length 256k. High-speed version of kimi-k2, always aligned with the latest kimi-k2 (kimi-k2-0905-preview). Same model parameters as kimi-k2, output speed up to 60 tokens/sec (max 100 tokens/sec)
  * kimi-k2-0711-preview: Context length 128k
  * kimi-k2-thinking: Context length 256k. A thinking model with general agentic and reasoning capabilities, specializing in deep reasoning tasks [Usage Notes](https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model)
  * kimi-k2-thinking-turbo: Context length 256k. High-speed version of kimi-k2-thinking, suitable for scenarios requiring both deep reasoning and extremely fast responses
  * Supports ToolCalls, JSON Mode, Partial Mode, and internet search functionality
  * Does not support vision functionality
  * Supports automatic context caching functionality. Cached tokens are charged at the input price (cache hit) rate. You can view "context caching" type cost details in the [console](https://platform.moonshot.ai/console)


###  Generation Model Moonshot-v1[](https://platform.moonshot.ai/docs/pricing/chat#generation-model-moonshot-v1)
Model | Unit | Input Price | Output Price | Context Window  
---|---|---|---|---  
moonshot-v1-8k | 1M tokens | $0.20 | $2.00 | 8,192 tokens  
moonshot-v1-32k | 1M tokens | $1.00 | $3.00 | 32,768 tokens  
moonshot-v1-128k | 1M tokens | $2.00 | $5.00 | 131,072 tokens  
moonshot-v1-8k-vision-preview | 1M tokens | $0.20 | $2.00 | 8,192 tokens  
moonshot-v1-32k-vision-preview | 1M tokens | $1.00 | $3.00 | 32,768 tokens  
moonshot-v1-128k-vision-preview | 1M tokens | $2.00 | $5.00 | 131,072 tokens  
Here, 1M = 1,000,000. The prices in the table represent the cost per 1M tokens consumed.
Last updated on February 2, 2026
[](https://platform.moonshot.ai/docs/promotion "üéâ Promotions")[WebSearch Pricing](https://platform.moonshot.ai/docs/pricing/tools "WebSearch Pricing")


>>>TOOL web_fetch
{"url":"https://groq.com/pricing/","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_search
{"query":"Zhipu AI GLM-4 API pricing context window endpoint open.bigmodel.cn api","max_results":5}
>>>END
>>>TOOL web_search
{"query":"Mistral API pricing context window endpoint api.mistral.ai v1 chat/completions","max_results":5}
>>>END
>>>TOOL web_search
{"query":"DeepSeek API pricing context window endpoint api.deepseek.com v1 chat completions","max_results":5}
>>>END
>>>TOOL web_search
{"query":"Gemini 2.0 Flash pricing per 1M tokens context window model name gemini-2.0-flash","max_results":5}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://groq.com/pricing/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://groq.com/pricing/                                          
| ‚úì | ‚è±: 1.62s 
[SCRAPE].. ‚óÜ https://groq.com/pricing/                                          
| ‚úì | ‚è±: 0.04s 
[COMPLETE] ‚óè https://groq.com/pricing/                                          
| ‚úì | ‚è±: 1.66s 
[skip to content](https://groq.com/pricing#main)
[Groq](https://groq.com/)
  * Platform Arrow pointing down
    * [GroqCloud](https://groq.com/groqcloud)
    * [LPU Architecture](https://groq.com/lpu-architecture)
    * [See Pricing](https://groq.com/pricing)
  * Solutions Arrow pointing down
    * [Industries & Use Cases](https://groq.com/industry-solutions)
    * [Customer Stories](https://groq.com/customer-stories)
    * [Demos](https://groq.com/demos)
  * Learn Arrow pointing down
    * [Blog](https://groq.com/blog)
    * [Changelog](https://groq.com/changelog)
    * [Whitepapers](https://groq.com/papers)
    * [Subscribe](https://groq.com/subscribe)
  * [Pricing](https://groq.com/pricing)
  * About Arrow pointing down
    * [About Groq](https://groq.com/about-groq)
    * [Newsroom](https://groq.com/newsroom)
    * [Careers at Groq](https://groq.com/careers-at-groq)
    * [Contact Us](https://groq.com/contact)


  * Developers Arrow pointing down
    * [Free API key](https://console.groq.com/keys)
    * [Community](https://community.groq.com/)
    * [Docs](https://console.groq.com/docs/overview)
  * [Enterprises](https://groq.com/enterprise-access)


  * [Start Building](https://console.groq.com/?utm_source=website&utm_medium=outbound_link&utm_campaign=dev_console_click)

MenuToggle Main Navigation
Close iconClose mobile navigation
  * PlatformArrow pointing down
    * [GroqCloud](https://groq.com/groqcloud)
    * [LPU Architecture](https://groq.com/lpu-architecture)
    * [See Pricing](https://groq.com/pricing)
  * SolutionsArrow pointing down
    * [Industries & Use Cases](https://groq.com/industry-solutions)
    * [Customer Stories](https://groq.com/customer-stories)
    * [Demos](https://groq.com/demos)
  * LearnArrow pointing down
    * [Blog](https://groq.com/blog)
    * [Changelog](https://groq.com/changelog)
    * [Whitepapers](https://groq.com/papers)
    * [Subscribe](https://groq.com/subscribe)
  * [Pricing](https://groq.com/pricing)
  * AboutArrow pointing down
    * [About Groq](https://groq.com/about-groq)
    * [Newsroom](https://groq.com/newsroom)
    * [Careers at Groq](https://groq.com/careers-at-groq)
    * [Contact Us](https://groq.com/contact)
  * DevelopersArrow pointing down
    * [Free API key](https://console.groq.com/keys)
    * [Community](https://community.groq.com/)
    * [Docs](https://console.groq.com/docs/overview)
  * [Enterprises](https://groq.com/enterprise-access)


  * [Groq Community](https://community.groq.com/)
  * [Discord](https://discord.gg/e6cj7aA4Ts)
  * [Twitter](https://x.com/groqinc)
  * [YouTube](https://www.youtube.com/c/GroqInc)
  * [Thread](https://www.threads.net/@groqinc)
  * [LinkedIn](https://www.linkedin.com/company/groq)
  * [Instagram](https://instagram.com/groqinc)


Smart, Fast, and Affordable
# Unmatched Price Performance
Fast responses, scalable performance, and costs you can plan for.
[Start Building](https://console.groq.com/)
* * *
## Large Language Models
*Approximate number of tokens per $ AI Model |  Current Speed(Tokens per Second) |  Input Token Price(Per Million Tokens) |  Output Token Price(Per Million Tokens)  
---|---|---|---  
AI Model GPT OSS 20B 128k |  Current Speed 1,000 TPS |  Input Token Price(Per Million Tokens) $0.075(13.3M / $1)* |  Output Token Price(Per Million Tokens) $0.30(3.33M / $1)* |  [Try Now](https://console.groq.com/playground?model=openai/gpt-oss-120b)[Model Card](https://console.groq.com/docs/model/openai/gpt-oss-20b)  
AI Model GPT OSS Safeguard 20B |  Current Speed 1,000 TPS |  Input Token Price(Per Million Tokens) $0.075(13.3M / $1)* |  Output Token Price(Per Million Tokens) $0.30(3.33M / $1)* |  [Try Now](https://console.groq.com/playground?model=openai/gpt-oss-safeguard-20b)[Model Card](https://console.groq.com/docs/content-moderation)  
AI Model GPT OSS 120B 128k |  Current Speed 500 TPS |  Input Token Price(Per Million Tokens) $0.15(6.67M / $1)* |  Output Token Price(Per Million Tokens) $0.60(1.66M / $1)* |  [Try Now](https://console.groq.com/playground?model=openai/gpt-oss-120b)[Model Card](https://console.groq.com/docs/model/openai/gpt-oss-120b)  
AI Model Kimi K2-0905 1T 256k |  Current Speed 200 TPS |  Input Token Price(Per Million Tokens) $1.00(1M / $1)* |  Output Token Price(Per Million Tokens) $3.00(333,333 / $1)* |  [Try Now](https://console.groq.com/playground?model=moonshotai/kimi-k2-instruct)[Model Card](https://console.groq.com/docs/model/moonshotai/kimi-k2-instruct-0905)  
AI Model Llama 4 Scout (17Bx16E) 128k |  Current Speed 594 TPS |  Input Token Price(Per Million Tokens) $0.11(9.09M / $1)* |  Output Token Price(Per Million Tokens) $0.34(2.94M / $1)* |  [Try Now](https://console.groq.com/playground?model=meta-llama/llama-4-scout-17b-16e-instruct)[Model Card](https://console.groq.com/docs/model/meta-llama/llama-4-scout-17b-16e-instruct)  
AI Model Llama 4 Maverick (17Bx128E) 128k |  Current Speed 562 TPS |  Input Token Price(Per Million Tokens) $0.20(5M / $1)* |  Output Token Price(Per Million Tokens) $0.60(1.6M / $1)* |  [Try Now](https://console.groq.com/playground?model=meta-llama/llama-4-maverick-17b-128e-instruct)[Model Card](https://console.groq.com/docs/model/meta-llama/llama-4-maverick-17b-128e-instruct)  
AI Model Llama Guard 4 12B 128k |  Current Speed 325 TPS |  Input Token Price(Per Million Tokens) $0.20(5M / $1)* |  Output Token Price(Per Million Tokens) $0.20(5M / $1)* |  [Try Now](https://console.groq.com/playground?model=meta-llama/llama-guard-4-12b)[Model Card](https://console.groq.com/docs/model/meta-llama/llama-guard-4-12b)  
AI Model Qwen3 32B 131k  |  Current Speed 662 TPS |  Input Token Price(Per Million Tokens) $0.29(3.44M / $1)* |  Output Token Price(Per Million Tokens) $0.59(1.69M / $1)* |  [Try Now](https://console.groq.com/playground?model=qwen/qwen3-32b)[Model Card](https://console.groq.com/docs/model/qwen/qwen3-32b)  
AI Model Llama 3.3 70B Versatile 128k |  Current Speed 394 TPS |  Input Token Price(Per Million Tokens) $0.59(1.69M / $1)* |  Output Token Price(Per Million Tokens) $0.79(1.27M / $1)* |  [Try Now](https://console.groq.com/playground?model=llama-3.3-70b-versatile)[Model Card](https://console.groq.com/docs/model/llama-3.3-70b-versatile)  
AI Model Llama 3.1 8B Instant 128k |  Current Speed 840 TPS |  Input Token Price(Per Million Tokens) $0.05(20M / $1)* |  Output Token Price(Per Million Tokens) $0.08(12.5M / $1)* |  [Try Now](https://console.groq.com/playground?model=llama-3.1-8b-instant)[Model Card](https://console.groq.com/docs/model/llama-3.1-8b-instant)  
## Text-to-Speech Models
AI Model | Characters /s |  PricePrice (Per M Characters)  
---|---|---  
AI Model Canopy Labs Orpheus English |  Characters /s 100 |  Price $22.00 |  [Try Now](https://console.groq.com/playground?model=canopylabs/orpheus-v1-english)[Model Card](https://console.groq.com/docs/model/canopylabs/orpheus-v1-english)  
AI Model Canopy Labs Orpheus Arabic Saudi |  Characters /s 100 |  Price $40.00 |  [Try Now](https://console.groq.com/playground?model=canopylabs/orpheus-arabic-saudi)[Model Card](https://console.groq.com/docs/model/canopylabs/orpheus-arabic-saudi)  
## Automatic Speech Recognition (ASR) Models
*Audio is billed at a minimum of 10s per request.  AI Model | Speed Factor |  Price(Per Hour Transcribed)  
---|---|---  
AI Model Whisper V3 Large |  Speed Factor 217x |  Price $0.111* |  [Try Now](https://console.groq.com/playground?model=whisper-large-v3)[Model Card](https://console.groq.com/docs/model/whisper-large-v3)  
AI Model Whisper Large v3 Turbo |  Speed Factor 228x |  Price $0.04* |  [Try Now](https://console.groq.com/playground?model=whisper-large-v3-turbo)[Model Card](https://console.groq.com/docs/model/whisper-large-v3-turbo)  
## Prompt Caching
Note: No extra fee for the caching feature itself. The discount only applies when a cache hit occurs. Model | Uncached Input Tokens (Per M Tokens) | Cached Input Tokens (Per M Tokens) | Output Tokens (Per M Tokens)  
---|---|---|---  
Model moonshotai/kimi-k2-instruct-0905 |  Uncached Input Tokens (Per M Tokens) $1.00 |  Cached Input Tokens (Per M Tokens) $0.50 |  Output Tokens (Per M Tokens) $3.00  
Model openai/gpt-oss-120b |  Uncached Input Tokens (Per M Tokens) $0.15 |  Cached Input Tokens (Per M Tokens) $0.075 |  Output Tokens (Per M Tokens) $0.60  
Model openai/gpt-oss-20b |  Uncached Input Tokens (Per M Tokens) $0.075 |  Cached Input Tokens (Per M Tokens) $0.0375 |  Output Tokens (Per M Tokens) $0.30  
## Built-In Tools (Compound)
Tool | Price | Parameter  
---|---|---  
Tool Basic Search |  Price $5 / 1000 requests |  Parameter web_search  
Tool Advanced Search |  Price $8 / 1000 requests |  Parameter web_search  
Tool Visit Website |  Price $1 / 1000 requests |  Parameter visit_website  
Tool Code Execution |  Price $0.18 / hour |  Parameter code_interpreter  
Tool Browser Automation |  Price $0.08 / hour |  Parameter browser_automation  
## Built-In Tools (GPT-OSS)
Tool | Price | Parameter  
---|---|---  
Tool Browser Search - Basic Search |  Price $5 / 1000 requests |  Parameter browser_search - browser.search  
Tool Browser Search - Visit Website |  Price $1 / 1000 requests |  Parameter browser_search - browser.open  
Tool Code Execution - Python |  Price $0.18 / hour |  Parameter code_interpreter - python  
## About Our Pricing
No Surprise Inference Bills
Other inference providers spike costs without warning. Some hide behind elastic pricing. Groq pricing is linear and predictable, with no hidden costs or idle infrastructure. Every new user is growth, not risk, and you can keep margins secure.
[Get started for free](https://console.groq.com/) and upgrade as your needs grow. View the pricing of our core models above and note all prices are in USD. Other models are available for specific customer requests including fine tuned models. Send us your inquiries [here](https://groq.com/enterprise-access).
[Get Started](https://console.groq.com/)
## Compound Systems
Intelligent Tool Selection Across Multiple Models
Compound AI systems are powered by multiple openly-available models already supported in GroqCloud to intelligently and selectively use tools to answer user queries, starting first with web search and code execution.Pricing is passed through to the underlying models and server side tools that are part of the compound AI system. 
[Read Documentation](https://console.groq.com/docs/compound/systems/compound-beta)
## Batch API
Process Large-Scale Workloads Asynchronously
Batch processing lets you run thousands of API requests at scale by submitting your workload as an asynchronous batch of requests to Groq with 50% lower cost, no impact to your standard rate limits, and 24-hour to 7 day processing window.
For enterprise API solutions or on-prem deployments, please fill out the form on our [Enterprise Access Page](https://groq.com/enterprise-access).
[Learn More](https://groq.com/enterprise-access)
## Build Fast
Seamlessly integrate Groq starting with just a few lines of code
[Try Groq for Free](https://console.groq.com/?utm_source=website&utm_medium=outbound_link&utm_campaign=dev_console_click)
[Groq](https://groq.com/)
Groq was established in 2016 for one thing: inference.
## Groq Footer Links
### Platform & Solutions
  * [GroqCloud](https://groq.com/groqcloud)
  * [LPU Architecture](https://groq.com/lpu-architecture)
  * [See Pricing](https://groq.com/pricing)
  * [Customer Stories](https://groq.com/customer-stories)
  * [Demos](https://groq.com/demos)
  * [Enterprise Inquiry](https://groq.com/enterprise-access)


### Learn
  * [Blog](https://groq.com/blog)
  * [Whitepapers](https://groq.com/papers)
  * [Subscribe](https://groq.com/subscribe)


### About
  * [About Groq](https://groq.com/about-groq)
  * [Newsroom](https://groq.com/newsroom)
  * [Careers at Groq](https://groq.com/careers-at-groq)
  * [Contact Us](https://groq.com/contact)


### Developers
  * [Free API key](https://console.groq.com/keys)
  * [Community](https://community.groq.com/)
  * [Docs](https://console.groq.com/docs/overview)


### Terms & Policies
  * [Website Terms of Use](https://groq.com/terms-of-use)
  * [Privacy Policy](https://groq.com/privacy-policy)
  * [Groq Trust Center](https://trust.groq.com/faq)
  * [Cookie Notice](https://groq.com/cookie-policy)
  * [Groq Privacy Portal](https://privacy.groq.com/)
  * [GroqCloud Terms](https://console.groq.com/docs/legal)
  * [Groq Services Agreement](https://console.groq.com/docs/legal/services-agreement)
  * [Security](https://groq.com/security)
  * [Trademark Policy](https://groq.com/trademark-policy)
  * [Photography and Filming Policy](https://groq.com/photography-and-filming-policy)


¬© 2026 Groq, Inc., All rights reserved.
Manage cookies
  * [Groq Community](https://community.groq.com/)
  * [Discord](https://discord.gg/e6cj7aA4Ts)
  * [Twitter](https://x.com/groqinc)
  * [YouTube](https://www.youtube.com/c/GroqInc)
  * [Thread](https://www.threads.net/@groqinc)
  * [LinkedIn](https://www.linkedin.com/company/groq)
  * [Instagram](https://instagram.com/groqinc)

---

[web_search]
üîç DuckDuckGo results for "Zhipu AI GLM-4 API pricing context window endpoint open.bigmodel.cn api" (5 results):

1. **ZHIPU AI OPEN PLATFORM - bigmodel**
   https://bigmodel.cn/pricing
   The GLM-4.6V series is a comprehensive upgrade of GLM-4.5V, retaining the 106B/12B MOE architecture and SOTA visual understanding capabilities. It adds Function Call for automated multi-modal task orchestration, extends the context window to 128k to handle long documents, multi-page images, and continuous video, balances reasoning depth and efficiency, and demonstrates superior stability and ...

2. **GLM-4.6: Complete Guide, Pricing, Context Window, and API Access**
   https://llm-stats.com/blog/research/glm-4-6-launch
   A comprehensive look at GLM-4.6 - Zhipu AI&#x27;s latest release with 128k context window, agentic capabilities, pricing, API details, benchmarks, and what it means for developers and enterprises.

3. **GLM-4.7 - Overview - Z.AI DEVELOPER DOCUMENT**
   https://docs.z.ai/guides/llm/glm-4.7
   The GLM Coding Plan is a subscription package designed specifically for AI-powered coding. GLM-4.7 is now available in top coding tools, starting at just $3/month ‚Äî powering Claude Code, Cline, OpenCode, Roo Code and more. The package is designed to make coding faster, smarter, and more reliable.

4. **GLM-4.7 - Pricing, Context Window Size, and Benchmark Data**
   https://automatio.ai/models/glm-4-7
   GLM-4.7 is the latest flagship AI model from Zhipu AI, representing a significant leap in open-weight intelligence. This massive 358-billion parameter Mixture-of-Experts (MoE) model is specifically engineered for advanced reasoning, coding automation, and complex agentic workflows.

5. **GLM 4.6 API Deployment Guide: Local &amp; Cloud Setup**
   https://www.digitalapplied.com/blog/glm-4-6-api-deployment-guide
   Deploy Zhipu AI GLM 4.6 with Z.ai API, OpenRouter, or local vLLM. Complete setup guide with code examples, pricing &amp; integration patterns.

---

[web_search]
üîç DuckDuckGo results for "Mistral API pricing context window endpoint api.mistral.ai v1 chat/completions" (5 results):

1. **API Specs - Mistral**
   https://docs.mistral.ai/api
   Complete Mistral AI API Specifications

2. **Mistral AI API: Ultimate Guide to Access, Models &amp; Pricing**
   https://iamistral.com/api/
   Unlock Mistral AI&#x27;s powerful LLMs! This 2025 guide covers API key access, all models (Large, Codestral, Small), latest pricing, endpoints &amp; SDKs.

3. **Pricing - Mistral AI**
   https://mistral.ai/pricing
   Compare Le Chat and Mistral AI Studio plans. Transparent pricing, scalable solutions‚Äîchoose your AI power today.

4. **Mistral AI Pricing - Mistral AI**
   https://iamistral.com/pricing/
   Mistral AI price starts at $0 for hobbyists, scales to custom six-figure enterprise contracts, and remains one of the best $/token values in the LLM market thanks to super-efficient models such as Mistral Medium 3.

5. **Mistral Large - Mistral | Token Calculator**
   https://www.token-calculator.com/models/mistral-large
   Learn about Mistral Large by Mistral. Top-tier reasoning for high-complexity tasks Compare token costs, context window, and capabilities.

---

[web_search]
üîç DuckDuckGo results for "DeepSeek API pricing context window endpoint api.deepseek.com v1 chat completions" (5 results):

1. **Models &amp; Pricing | DeepSeek API Docs**
   https://api-docs.deepseek.com/quick_start/pricing/
   Models &amp; Pricing The prices listed below are in units of per 1M tokens. A token, the smallest unit of text that the model recognizes, can be a word, a number, or even a punctuation mark. We will bill based on the total number of input and output tokens by the model. Model Details ... Deduction Rules The expense = number of tokens √ó price.

2. **DeepSeek API Pricing Calculator &amp; Cost Guide (Feb 2026)**
   https://costgoat.com/pricing/deepseek-api
   The DeepSeek API provides programmatic access to DeepSeek&#x27;s V3.2 model in two modes: non-thinking (deepseek-chat) for general tasks and thinking mode (deepseek-reasoner) for advanced reasoning. DeepSeek offers exceptional value - up to 95% cheaper than GPT-5 while maintaining competitive performance. Both modes feature automatic context caching that reduces costs for repeated prompts ...

3. **DeepSeek API Pricing 2026 | Models, Token Cost &amp; Calculator**
   https://aipricing.org/brands/deepseek
   DeepSeek API pricing: 22 models from $0.03 to $0.70/1M input tokens. Compare DeepSeek models, calculate costs, and find the best option for your use case.

4. **DeepSeek API Docs - OpenAI Compatible API for Chat, Code &amp; Reasoning**
   https://deepseeksr1.com/api-docs/
   Explore the DeepSeek API Docs to integrate deepseek-chat and deepseek-reasoner into your apps with an OpenAI compatible interface. Learn models, pricing, endpoints, and best practices for building chatbots, code assistants, and reasoning heavy AI agents.

5. **DeepSeek API Pricing: How Much Does It Cost? (03/2025)**
   https://openaidiscovery.com/deepseek-api-pricing/
   DeepSeek-V3 (deepseek-chat) ‚Äî The most advanced model, ideal for content generation, text analysis, and natural language conversations. DeepSeek-R1 (deepseek-reasoner) ‚Äî A budget-friendly option designed for basic chatbots, data extraction, and text classification.

---

[web_search]
üîç DuckDuckGo results for "Gemini 2.0 Flash pricing per 1M tokens context window model name gemini-2.0-flash" (5 results):

1. **Gemini 2.0 Flash Pricing &amp; Specs | AI Models | CloudPrice**
   https://cloudprice.net/models/gemini-2.0-flash
   Compare Gemini 2.0 Flash AI model pricing, specifications, and capabilities. View input/output token costs, context window, and supported features.

2. **Gemini Developer API pricing - Google AI for Developers**
   https://ai.google.dev/gemini-api/docs/pricing
   Gemini Developer API pricing On this page Gemini 3 Pro Preview Gemini 3 Flash Preview Gemini 3 Pro Image Preview üçå Gemini 2.5 Pro Gemini 2.5 Flash

3. **Gemini 2.0 Flash Model Specs, Costs &amp; Benchmarks (February 2026)**
   https://blog.galaxy.ai/model/gemini-2-0-flash-001
   Gemini 2.0 Flash, developed by Google, features a context window of 1M tokens. The model costs $0.10 per million tokens for input and $0.40 per million tokens for output. It was released on February 5, 2025, and has achieved impressive scores in various benchmarks.

4. **Gemini API Pricing Calculator &amp; Cost Guide (Feb 2026)**
   https://costgoat.com/pricing/gemini-api
   Calculate Gemini API costs instantly. Compare Pro, Flash, and Flash-Lite pricing per token with free tiers, batch API, and context caching discounts.

5. **Free Gemini 2.0 Flash Calculator - Instant Cost (2025)**
   https://langcopilot.com/gemini-2.0-flash-token-calculator
   Estimate Google Gemini 2.0 Flash API usage in dollars before you send a single request. Standard pricing is $ 0.10 per million input tokens and $ 0.40 per million output tokens with a 1M token context window.




>>>TOOL web_fetch
{"url":"https://api-docs.deepseek.com/quick_start/pricing/","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://api-docs.deepseek.com/quick_start/quick_start/","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://docs.mistral.ai/api/","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://mistral.ai/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://bigmodel.cn/pricing","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://api-docs.deepseek.com/quick_start/pricing/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://api-docs.deepseek.com/quick_start/pricing/                 
| ‚úì | ‚è±: 0.89s 
[SCRAPE].. ‚óÜ https://api-docs.deepseek.com/quick_start/pricing/                 
| ‚úì | ‚è±: 0.01s 
[COMPLETE] ‚óè https://api-docs.deepseek.com/quick_start/pricing/                 
| ‚úì | ‚è±: 0.91s 
[Skip to main content](https://api-docs.deepseek.com/quick_start/pricing/#__docusaurus_skipToContent_fallback)
[ ![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png)![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png) **DeepSeek API Docs**](https://api-docs.deepseek.com/)
[](https://api-docs.deepseek.com/quick_start/pricing/#)
  * [English](https://api-docs.deepseek.com/quick_start/pricing)
  * [‰∏≠ÊñáÔºà‰∏≠ÂõΩÔºâ](https://api-docs.deepseek.com/zh-cn/quick_start/pricing)


[DeepSeek Platform](https://platform.deepseek.com/)
  * [Quick Start](https://api-docs.deepseek.com/)
    * [Your First API Call](https://api-docs.deepseek.com/)
    * [Models & Pricing](https://api-docs.deepseek.com/quick_start/pricing)
    * [The Temperature Parameter](https://api-docs.deepseek.com/quick_start/parameter_settings)
    * [Token & Token Usage](https://api-docs.deepseek.com/quick_start/token_usage)
    * [Rate Limit](https://api-docs.deepseek.com/quick_start/rate_limit)
    * [Error Codes](https://api-docs.deepseek.com/quick_start/error_codes)
  * [News](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2 Release 2025/12/01](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2-Exp Release 2025/09/29](https://api-docs.deepseek.com/news/news250929)
    * [DeepSeek V3.1 Update 2025/09/22](https://api-docs.deepseek.com/news/news250922)
    * [DeepSeek V3.1 Release 2025/08/21](https://api-docs.deepseek.com/news/news250821)
    * [DeepSeek-R1-0528 Release 2025/05/28](https://api-docs.deepseek.com/news/news250528)
    * [DeepSeek-V3-0324 Release 2025/03/25](https://api-docs.deepseek.com/news/news250325)
    * [DeepSeek-R1 Release 2025/01/20](https://api-docs.deepseek.com/news/news250120)
    * [DeepSeek APP 2025/01/15](https://api-docs.deepseek.com/news/news250115)
    * [Introducing DeepSeek-V3 2024/12/26](https://api-docs.deepseek.com/news/news1226)
    * [DeepSeek-V2.5-1210 Release 2024/12/10](https://api-docs.deepseek.com/news/news1210)
    * [DeepSeek-R1-Lite Release 2024/11/20](https://api-docs.deepseek.com/news/news1120)
    * [DeepSeek-V2.5 Release 2024/09/05](https://api-docs.deepseek.com/news/news0905)
    * [Context Caching is Available 2024/08/02](https://api-docs.deepseek.com/news/news0802)
    * [New API Features 2024/07/25](https://api-docs.deepseek.com/news/news0725)
  * [API Reference](https://api-docs.deepseek.com/api/deepseek-api)
  * [API Guides](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Thinking Mode](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Multi-round Conversation](https://api-docs.deepseek.com/guides/multi_round_chat)
    * [Chat Prefix Completion (Beta)](https://api-docs.deepseek.com/guides/chat_prefix_completion)
    * [FIM Completion (Beta)](https://api-docs.deepseek.com/guides/fim_completion)
    * [JSON Output](https://api-docs.deepseek.com/guides/json_mode)
    * [Tool Calls](https://api-docs.deepseek.com/guides/tool_calls)
    * [Context Caching](https://api-docs.deepseek.com/guides/kv_cache)
    * [Anthropic API](https://api-docs.deepseek.com/guides/anthropic_api)
  * [Other Resources](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [Integrations](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [API Status Page](https://status.deepseek.com/)
  * [FAQ](https://api-docs.deepseek.com/faq)
  * [Change Log](https://api-docs.deepseek.com/updates)


  * [](https://api-docs.deepseek.com/)
  * Quick Start
  * Models & Pricing


On this page
# Models & Pricing
The prices listed below are in units of per 1M tokens. A token, the smallest unit of text that the model recognizes, can be a word, a number, or even a punctuation mark. We will bill based on the total number of input and output tokens by the model.
## Model Details[‚Äã](https://api-docs.deepseek.com/quick_start/pricing/#model-details "Direct link to Model Details")
** MODEL | deepseek-chat | deepseek-reasoner  
---|---|---  
BASE URL | <https://api.deepseek.com>  
MODEL VERSION | DeepSeek-V3.2  
(Non-thinking Mode) | DeepSeek-V3.2  
(Thinking Mode)  
CONTEXT LENGTH | 128K  
MAX OUTPUT | DEFAULT: 4K  
MAXIMUM: 8K | DEFAULT: 32K  
MAXIMUM: 64K  
FEATURES | [Json Output](https://api-docs.deepseek.com/guides/json_mode) | ‚úì | ‚úì  
[Tool Calls](https://api-docs.deepseek.com/guides/tool_calls) | ‚úì | ‚úì  
[Chat Prefix CompletionÔºàBetaÔºâ](https://api-docs.deepseek.com/guides/chat_prefix_completion) | ‚úì | ‚úì  
[FIM CompletionÔºàBetaÔºâ](https://api-docs.deepseek.com/guides/fim_completion) | ‚úì | ‚úó  
PRICING | 1M INPUT TOKENS (CACHE HIT) | $0.028  
1M INPUT TOKENS (CACHE MISS) | $0.28  
1M OUTPUT TOKENS | $0.42  
**
* * *
## Deduction Rules[‚Äã](https://api-docs.deepseek.com/quick_start/pricing/#deduction-rules "Direct link to Deduction Rules")
The expense = number of tokens √ó price. The corresponding fees will be directly deducted from your topped-up balance or granted balance, with a preference for using the granted balance first when both balances are available.
Product prices may vary and DeepSeek reserves the right to adjust them. We recommend topping up based on your actual usage and regularly checking this page for the most recent pricing information.
[Previous Your First API Call](https://api-docs.deepseek.com/)[Next The Temperature Parameter](https://api-docs.deepseek.com/quick_start/parameter_settings)
  * [Model Details](https://api-docs.deepseek.com/quick_start/pricing/#model-details)
  * [Deduction Rules](https://api-docs.deepseek.com/quick_start/pricing/#deduction-rules)


WeChat Official Account
  * ![WeChat QRcode](https://cdn.deepseek.com/official_account.jpg)


Community
  * Email
  * [Discord](https://discord.gg/Tc7c45Zzu5)
  * [Twitter](https://twitter.com/deepseek_ai)


More
  * [GitHub](https://github.com/deepseek-ai)


Copyright ¬© 2026 DeepSeek, Inc.

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://api-docs.deepseek.com/quick_start/quick_start/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://api-docs.deepseek.com/quick_start/quick_start/             
| ‚úì | ‚è±: 1.62s 
[SCRAPE].. ‚óÜ https://api-docs.deepseek.com/quick_start/quick_start/             
| ‚úì | ‚è±: 0.00s 
[COMPLETE] ‚óè https://api-docs.deepseek.com/quick_start/quick_start/             
| ‚úì | ‚è±: 1.63s 
[Skip to main content](https://api-docs.deepseek.com/quick_start/quick_start/#__docusaurus_skipToContent_fallback)
[![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png) **DeepSeek API Docs**](https://api-docs.deepseek.com/)
[](https://api-docs.deepseek.com/quick_start/quick_start/#)
  * [English](https://api-docs.deepseek.com/404)
  * [‰∏≠ÊñáÔºà‰∏≠ÂõΩÔºâ](https://api-docs.deepseek.com/zh-cn/404)


[DeepSeek Platform](https://platform.deepseek.com/)
# Page Not Found
We could not find what you were looking for.
Please contact the owner of the site that linked you to the original URL and let them know their link is broken.
WeChat Official Account
  * ![WeChat QRcode](https://cdn.deepseek.com/official_account.jpg)


Community
  * Email
  * [Discord](https://discord.gg/Tc7c45Zzu5)
  * [Twitter](https://twitter.com/deepseek_ai)


More
  * [GitHub](https://github.com/deepseek-ai)


Copyright ¬© 2026 DeepSeek, Inc.

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://docs.mistral.ai/api/

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://docs.mistral.ai/api/                                       
| ‚úì | ‚è±: 1.21s 
[SCRAPE].. ‚óÜ https://docs.mistral.ai/api/                                       
| ‚úì | ‚è±: 0.10s 
[COMPLETE] ‚óè https://docs.mistral.ai/api/                                       
| ‚úì | ‚è±: 1.32s 
[](https://docs.mistral.ai/)Docs & API
Search docs
‚åòK
[Docs](https://docs.mistral.ai/)[API](https://docs.mistral.ai/api)[Cookbooks](https://docs.mistral.ai/cookbooks)[Ambassadors](https://docs.mistral.ai/ambassadors)
Toggle theme[Reach out](https://mistral.ai/contact?utm_source=docs&utm_medium=header_cta&utm_campaign=studio_trial)[Try Studio ](https://console.mistral.ai?utm_source=docs&utm_medium=header_cta&utm_campaign=studio_trial)
Search docs
‚åòK
[](https://docs.mistral.ai/openapi.yaml)
Getting Started
  * [Chat](https://docs.mistral.ai/api/endpoint/chat)
    * [postChat Completion](https://docs.mistral.ai/api/endpoint/chat#operation-chat_completion_v1_chat_completions_post)
  * [Fim](https://docs.mistral.ai/api/endpoint/fim)
  * [Agents](https://docs.mistral.ai/api/endpoint/agents)
  * [Embeddings](https://docs.mistral.ai/api/endpoint/embeddings)
  * [Classifiers](https://docs.mistral.ai/api/endpoint/classifiers)
  * [Files](https://docs.mistral.ai/api/endpoint/files)
  * [Fine Tuning](https://docs.mistral.ai/api/endpoint/fine-tuning)
  * [Models](https://docs.mistral.ai/api/endpoint/models)
  * [Batch](https://docs.mistral.ai/api/endpoint/batch)
  * [Ocr](https://docs.mistral.ai/api/endpoint/ocr)
  * [Audio Transcriptions](https://docs.mistral.ai/api/endpoint/audio/transcriptions)


Beta
  * [Beta Agents](https://docs.mistral.ai/api/endpoint/beta/agents)
  * [Beta Conversations](https://docs.mistral.ai/api/endpoint/beta/conversations)
  * [Beta Libraries](https://docs.mistral.ai/api/endpoint/beta/libraries)
  * [Beta Libraries Accesses](https://docs.mistral.ai/api/endpoint/beta/libraries/accesses)
  * [Beta Libraries Documents](https://docs.mistral.ai/api/endpoint/beta/libraries/documents)


  1. [](https://docs.mistral.ai/api)
  2. [Getting Started](https://docs.mistral.ai/api/endpoint/chat)
  3. Chat


![Tree BG 1](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftree_bg_1.b9f8245b.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Tree](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftree_bg_1.b9f8245b.png&w=2048&q=75&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Tree](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftree_bg_2.09077b6d.png&w=2048&q=75&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Tree](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftree_1.c6ea95c8.png&w=2048&q=75&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Leaves](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fleaves.fa5cdaf8.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Tree](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftree_2.ca9173eb.png&w=2048&q=75&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Leaves](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fleaves.fa5cdaf8.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Cat Idle](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcat_idle.da6d14d2.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Grass](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgrass_tile.ce50c332.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Grass](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgrass_tile.ce50c332.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Rock](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frock.c36c5495.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Rock](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frock.c36c5495.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Fireflies](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffireflies.7a626bd6.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
# Chat Endpoints
Chat Completion API.
Toggle theme
![Wall Assets](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fwall_assets.fb9d0a95.png&w=828&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Cat Frame](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcat_frame.7cd1d4d0.png&w=828&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Lamp](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flamp.21a6e807.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Cat Toy](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcat_toy.99105b1f.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Lamp Light](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookshelf.2e04e5b9.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Desk](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdesk.11413025.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Chair](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fchair.e01257f7.png&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Orange Cat Idle](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Forange_cat_idle.a5f0da13.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
![Lamp Light](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flamp_light.5135bc3d.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Screen](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fanimated_screen.50ea99f4.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Screen Light](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fscreen_light.649888f0.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)![Lamp Light Large](https://docs.mistral.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbig_light.12d015c4.gif&w=2048&q=100&dpl=dpl_Cbi8GjeWrfk2dGEnsGux1N6ndstd)
### Examples
Real world code examples
Chat Completion
##  **POST** /v1/chat/completions
### Request Body
application/json
##### frequency_penalty
number
_Default Value:_ `0`
The `frequency_penalty` penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition.
##### max_tokens
integer|null
The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
##### messages
*array<[SystemMessage](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_messages_systemmessage)|[UserMessage](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_messages_usermessage)|[AssistantMessage](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_messages_assistantmessage)|[ToolMessage](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_messages_toolmessage)>
The prompt(s) to generate completions for, encoded as a list of dict with role and content.
##### metadata
map<any>|null
##### model
*string
ID of the model to use. You can use the [List Available Models](https://docs.mistral.ai/api#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](https://docs.mistral.ai/models) for model descriptions.
##### n
integer|null
Number of completions to return for each request, input tokens are only billed once.
##### parallel_tool_calls
boolean
_Default Value:_ `true`
Whether to enable parallel function calling during tool use, when enabled the model can call multiple tools in parallel.
##### prediction
[Prediction](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_prediction_prediction)|null
Enable users to specify an expected completion, optimizing response times by leveraging known or predictable content.
##### presence_penalty
number
_Default Value:_ `0`
The `presence_penalty` determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.
##### prompt_mode
"reasoning"
Available options to the prompt_mode argument on the chat completion endpoint. Values represent high-level intent. Assignment to actual SPs is handled internally. System prompt may include knowledge cutoff date, model capabilities, tone to use, safety guidelines, etc.
##### random_seed
integer|null
The seed to use for random sampling. If set, different calls will generate deterministic results.
##### response_format
[ResponseFormat](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_response_format_responseformat)|null
Specify the format that the model must output. By default it will use `\{ "type": "text" \}`. Setting to `\{ "type": "json_object" \}` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message. Setting to `\{ "type": "json_schema" \}` enables JSON schema mode, which guarantees the message the model generates is in JSON and follows the schema you provide.
##### safe_prompt
boolean
_Default Value:_ `false`
Whether to inject a safety prompt before all conversations.
##### stop
string|array<string>
Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
##### stream
boolean
_Default Value:_ `false`
Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.
##### temperature
number|null
What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value.
##### tool_choice
[ToolChoice](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_tool_choice_toolchoice)|"auto"|"none"|"any"|"required"
Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `any` or `required` means the model must call one or more tools. Specifying a particular tool via `\{"type": "function", "function": \{"name": "my_function"\}\}` forces the model to call that tool.
##### tools
[array](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_tools_tool)<[Tool](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_request_tools_tool)>|null
A list of tools the model may call. Use this to provide a list of functions the model may generate JSON inputs for.
##### top_p
number
_Default Value:_ `1`
Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both.
200 (application/json)
200 (text/event-stream)
Successful Response
##### choices
*[array](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_responses_200_application-json_choices_chatcompletionchoice)<[ChatCompletionChoice](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_responses_200_application-json_choices_chatcompletionchoice)>
##### created
*integer
##### id
*string
##### model
*string
##### object
*string
##### usage
*[UsageInfo](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_responses_200_application-json_usage_usageinfo)
Response Type
[event-stream](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_responses_completionevent)<[CompletionEvent](https://docs.mistral.ai/api#operation-chat_completion_v1_chat_completions_post_responses_completionevent)>
Successful Response
#### CompletionEvent
{object}
#### Playground
Test the endpoints **live**
TypeScript
Python
cURL
```
import { Mistral } from "@mistralai/mistralai";

const mistral = new Mistral({
  apiKey: "MISTRAL_API_KEY",
});

async function run() {
  const result = await mistral.chat.complete({
    model: "mistral-small-latest",
    messages: [
      {
        content: "Who is the best French painter? Answer in one short sentence.",
        role: "user",
      },
    ],
  });

  console.log(result);
}

run();

```

```
import { Mistral } from "@mistralai/mistralai";

const mistral = new Mistral({
  apiKey: "MISTRAL_API_KEY",
});

async function run() {
  const result = await mistral.chat.complete({
    model: "mistral-small-latest",
    messages: [
      {
        content: "Who is the best French painter? Answer in one short sentence.",
        role: "user",
      },
    ],
  });

  console.log(result);
}

run();

```

```
from mistralai import Mistral
import os


with Mistral(
    api_key=os.getenv("MISTRAL_API_KEY", ""),
) as mistral:

    res = mistral.chat.complete(model="mistral-small-latest", messages=[
        {
            "content": "Who is the best French painter? Answer in one short sentence.",
            "role": "user",
        },
    ], stream=False)

    # Handle response
    print(res)


```

```
from mistralai import Mistral
import os


with Mistral(
    api_key=os.getenv("MISTRAL_API_KEY", ""),
) as mistral:

    res = mistral.chat.complete(model="mistral-small-latest", messages=[
        {
            "content": "Who is the best French painter? Answer in one short sentence.",
            "role": "user",
        },
    ], stream=False)

    # Handle response
    print(res)


```

```
curl https://api.mistral.ai/v1/chat/completions \
 -X POST \
 -H 'Authorization: Bearer YOUR_APIKEY_HERE' \
 -H 'Content-Type: application/json' \
 -d '{
  "messages": [
    {
      "content": "ipsum eiusmod"
    }
  ],
  "model": "mistral-large-latest"
}'
```

```
curl https://api.mistral.ai/v1/chat/completions \
 -X POST \
 -H 'Authorization: Bearer YOUR_APIKEY_HERE' \
 -H 'Content-Type: application/json' \
 -d '{
  "messages": [
    {
      "content": "ipsum eiusmod"
    }
  ],
  "model": "mistral-large-latest"
}'
```

200 (application/json)
200 (text/event-stream)
```
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": "0",
      "message": {}
    }
  ],
  "created": "1702256327",
  "id": "cmpl-e5cc70bb28c444948073e77776eb30ef",
  "model": "mistral-small-latest",
  "object": "chat.completion",
  "usage": {}
}
```

```
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": "0",
      "message": {}
    }
  ],
  "created": "1702256327",
  "id": "cmpl-e5cc70bb28c444948073e77776eb30ef",
  "model": "mistral-small-latest",
  "object": "chat.completion",
  "usage": {}
}
```

```
null
```

```
null
```

[Fim](https://docs.mistral.ai/api/endpoint/fim)

### WHY MISTRAL
[About us](https://mistral.ai/about)[Our customers](https://mistral.ai/customers)[Careers](https://mistral.ai/careers)[Contact us](https://mistral.ai/contact)
### EXPLORE
[AI Solutions](https://mistral.ai/solutions)[Partners](https://mistral.ai/partners)[Research](https://mistral.ai/news?category=Research)
### DOCUMENTATION
[Documentation](https://docs.mistral.ai/)[Contributing](https://docs.mistral.ai/ambassadors)[Cookbooks](https://docs.mistral.ai/cookbooks)
### BUILD
[AI Studio](https://mistral.ai/products/la-plateforme)[Le Chat](https://mistral.ai/products/le-chat)[Mistral Code](https://mistral.ai/products/mistral-code)[Mistral Compute](https://mistral.ai/products/mistral-compute)[Try the API](https://docs.mistral.ai/api)
### LEGAL
[Terms of service](https://mistral.ai/terms)[Privacy policy](https://mistral.ai/terms#privacy-policy)[Legal notice](https://mistral.ai/legal)Privacy Choices[Brand](https://mistral.ai/brand)
### COMMUNITY
[Discord‚Üó](https://discord.gg/mistralai)[X‚Üó](https://x.com/mistralai)[Github‚Üó](https://github.com/mistralai)[LinkedIn‚Üó](https://linkedin.com/company/mistralai)[Ambassador](https://docs.mistral.ai/ambassadors)
Mistral AI ¬© 2026
Toggle theme
![Sun](https://docs.mistral.ai/assets/sprites/sun.gif)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Cat](https://docs.mistral.ai/assets/sprites/cat-walking-white.gif)

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://mistral.ai/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://mistral.ai/pricing                                         
| ‚úì | ‚è±: 1.01s 
[SCRAPE].. ‚óÜ https://mistral.ai/pricing                                         
| ‚úì | ‚è±: 0.04s 
[COMPLETE] ‚óè https://mistral.ai/pricing                                         
| ‚úì | ‚è±: 1.06s 
[![Mistral AI Logo](https://mistral.ai/_next/image?url=%2Fimg%2Fmistral-ai-logo.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)![Mistral AI Logo White](https://mistral.ai/_next/image?url=%2Fimg%2Fmistral-ai-logo-white.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)](https://mistral.ai/)
  * Products
  * Solutions
  * Research
  * Resources
  * [Pricing](https://mistral.ai/pricing)
  * Company


[Try Studio](https://console.mistral.ai/)[Talk to sales](https://mistral.ai/contact)
[![Mistral AI Logo](https://mistral.ai/_next/image?url=%2Fimg%2Fmistral-ai-logo.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)![Mistral AI Logo White](https://mistral.ai/_next/image?url=%2Fimg%2Fmistral-ai-logo-white.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)](https://mistral.ai/)
# Pricing
USD ($)
EUR (‚Ç¨)
# Pricing
USD ($)
EUR (‚Ç¨)
![ae2c3853-f091-43d0-ad96-8f10f48f4244](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2Fae2c3853-f091-43d0-ad96-8f10f48f4244&w=96&q=75)
### Free
Your personal AI assistant for everyday life and work. Get started with Le Chat.
  * Chat, search, learn, create with Le Chat.
  * Access to Mistral‚Äôs SOTA AI models.
  * Save and recall up to 500 memories.
  * Generate pictures.
  * Group chats into projects.
  * 40+ enterprise connectors.


Popular
![8f96c9e2-03f4-49e2-97e9-08dd3208986f](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2F8f96c9e2-03f4-49e2-97e9-08dd3208986f&w=96&q=75)
### Pro
Enhanced productivity, higher limits, and Mistral Vibe for all-day development.
  * More messages and web searches.
  * More extended thinking and deep research reports.
  * Up to 15GB of document storage.
  * Up to 1,000 projects.
  * Mistral Vibe for all-day coding, PAYG beyond.
  * Chat and email support.
  * State-of-the art image generation.


Base
$0012345678900123456789.0012345678900123456789/mo
Excluding taxes
[ $00123456789.0012345678900123456789/mo Excluding taxes ](https://chat.mistral.ai/upgrade/student)
[Start now](https://console.mistral.ai/codestral/cli)
![8bf1fb9e-d179-49bf-8343-44867062c109](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2F8bf1fb9e-d179-49bf-8343-44867062c109&w=96&q=75)
### Team
Secure, collaborative workspace for teams building with AI.
  * Up to 200 flash answers /user/day.
  * Up to 30GB of storage /user.
  * Domain name verification.
  * Data export.


$0012345678900123456789.0012345678900123456789/mo
Excluding taxes
$0012345678900123456789 /mo /
users
[Start now](https://console.mistral.ai/codestral/cli)
[ ![0b2cf819-f009-4bd9-8d90-4fea68a245d0](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2F0b2cf819-f009-4bd9-8d90-4fea68a245d0&w=96&q=75)Enterprise Private deployments powered by custom models, UI, and tools. Contact us ![](https://mistral.ai/_next/image?url=%2Fimg%2Fcoffe.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)](https://mistral.ai/contact)
### [Free Start today ](https://chat.mistral.ai/)### [Pro $14.99* ](https://console.mistral.ai/codestral/cli)### [Team $24.99* ](https://console.mistral.ai/codestral/cli)### [Enterprise Custom ](https://mistral.ai/contact)
### Features
Free
Pro
Team
Enterprise
Messages
Up to 6x free
Up to 6x free
Custom
Voice mode
Custom
Flash answers
Up to 150 / day
Up to 200 / day
Custom
Agents
Custom
Mistral Vibe CLI
-
Custom
Mistral Vibe for IDE
-
-
-
Async coding agents
-
-
-
Custom
Web searches
Up to 5x Free
Up to 5x Free
Custom
Think mode
Up to 30x Free
Up to 30x Free
Custom
Deep research (Preview)
Up to 5x Free
Up to 5x Free
Custom
Memories (beta)
500
1,000
1,000
1,000
Libraries
Limited
Up to 15GB
Up to 30GB / user
Custom
Document upload 
Up to 20x Free
Up to 20x Free
Custom
Verified news
Custom
Connectors directory (beta)
Custom
Custom MCP connectors (beta)
Custom
Projects
Up to 1,000
Up to 1,000
Custom
Image generation
Up to 40x Free
Up to 40x Free
Custom
Code interpreter
Up to 5x Free
Up to 5x Free
Custom
Canvas mode
Custom
### Customer service
Free
Pro
Team
Enterprise
Help center
Custom
Knowledge base
Custom
Chat and email support
-
Custom
### Team and enterprise features
Free
Pro
Team
Enterprise
Domain name verification
-
-
Custom
Admin API
-
-
Custom
Data export
-
-
Custom
Audit logs
-
-
-
Custom
SAML SSO
-
-
-
Custom
White label
-
-
-
Custom
* Excluding taxes
FAQs
### Does Mistral have a free plan?
### Which model should I use?
### How is API pricing calculated?
### How can I track my API usage and spending?
### What‚Äôs the difference between Mistral Free and Pro plans?
### Does Le Chat have any usage limits?
### Can I self-host Mistral‚Äôs models?
### Are there discounts for students?
### Do you offer enterprise solutions and support?
The next chapter of AI is yours.
[Try Le Chat](https://chat.mistral.ai/)[Try Mistral Vibe](https://console.mistral.ai/codestral/vibe)[Build in Mistral Studio](http://console.mistral.ai)[Talk to an expert](https://mistral.ai/contact)
![LeChat - Mistral](https://cms.mistral.ai/assets/920e56ee-25c5-439d-bd31-fbdf5c92c87f)
[](https://mistral.ai/)
[![App Store Mistral AI](https://mistral.ai/_next/image?url=%2Fimg%2Fappstore.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)](https://apps.apple.com/us/app/le-chat-by-mistral-ai/id6740410176)[![Google Play Mistral AI](https://mistral.ai/_next/image?url=%2Fimg%2Fandroidstore.svg&w=256&q=75&dpl=8649b94e330c0725208101f0e7ed2557f05b33a27a2744495bc457c5ca9016ae363938396232353666333265633935343636666266643537)](https://play.google.com/store/apps/details?id=ai.mistral.chat)
Mistral AI ¬© 2026
### Why Mistral
[About us](https://mistral.ai/about)[Our customers](https://mistral.ai/customers)[Careers](https://mistral.ai/careers)[Contact us](https://mistral.ai/contact)
### Explore
[AI solutions](https://mistral.ai/solutions)[Partners](https://mistral.ai/partners)[Research](https://mistral.ai/news?category=research)[Documentation](https://docs.mistral.ai/)
### Build
[Studio](https://mistral.ai/products/studio)[Le Chat](https://mistral.ai/products/le-chat)[Vibe](https://mistral.ai/products/vibe)[Mistral Compute](https://mistral.ai/products/compute)
### Legal
[Terms of service](https://legal.mistral.ai/terms)[Privacy policy](https://legal.mistral.ai/terms/privacy-policy?language=en-US)Privacy choices[Data processing agreement](https://legal.mistral.ai/terms/data-processing-addendum)[Legal notice](https://mistral.ai/legal)[Brand](https://mistral.ai/brand)
en
Mistral AI ¬© 2026
[![](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2F9c3aec2e-9825-4691-8458-cf4bd48ceff5&w=96&q=75)](https://x.com/mistralai)[![](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2Fb68af65f-220d-4116-b522-fe9ab25c7f32&w=96&q=75)](https://www.linkedin.com/company/mistralai/)[![](https://mistral.ai/_next/image?url=https%3A%2F%2Fcms.mistral.ai%2Fassets%2F0f8631ea-bfbc-4075-8f2e-c8f681076d7b&w=96&q=75)](https://discord.gg/mistralai)

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://bigmodel.cn/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://bigmodel.cn/pricing                                        
| ‚úì | ‚è±: 18.14s 
[SCRAPE].. ‚óÜ https://bigmodel.cn/pricing                                        
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://bigmodel.cn/pricing                                        
| ‚úì | ‚è±: 18.17s


>>>TOOL browser_screenshot
{"url":"https://bigmodel.cn/pricing","fullPage":true}
>>>END
>>>TOOL web_fetch
{"url":"https://console.groq.com/docs/overview","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://api-docs.deepseek.com/api/deepseek-api","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_search
{"query":"Mistral API pricing per 1M tokens mistral-large-latest mistral-small-latest codestral pricing page","max_results":5}
>>>END
>>>TOOL web_fetch
{"url":"https://ai.google.dev/gemini-api/docs/models","use_crawl4ai":true,"max_length":20000}
>>>END

---

## üîß TOOL RESULTS

[browser_screenshot]
Error taking screenshot: Playwright not found. Install it in your workspace:
  npm install playwright
  npx playwright install chromium

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://console.groq.com/docs/overview

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://console.groq.com/docs/overview                             
| ‚úì | ‚è±: 0.94s 
[SCRAPE].. ‚óÜ https://console.groq.com/docs/overview                             
| ‚úì | ‚è±: 0.02s 
[COMPLETE] ‚óè https://console.groq.com/docs/overview                             
| ‚úì | ‚è±: 0.97s 
[![Groq](https://console.groq.com/groq-logo.svg)](https://console.groq.com/home)
[](https://console.groq.com/docs/overview)[Login](https://console.groq.com/home)
[Playground](https://console.groq.com/playground)
[API Keys](https://console.groq.com/keys)
[Dashboard](https://console.groq.com/dashboard)
[Docs](https://console.groq.com/docs)
[](https://console.groq.com/settings)
[Log In](https://console.groq.com/login)
## Documentation
[Docs](https://console.groq.com/docs/overview)[API Reference](https://console.groq.com/docs/api-reference)
Search`‚åò``K`
Overview
## Docs
### Getting Started
[Overview](https://console.groq.com/docs/overview)[Quickstart](https://console.groq.com/docs/quickstart)[Models](https://console.groq.com/docs/models)[OpenAI Compatibility](https://console.groq.com/docs/openai)[Responses API](https://console.groq.com/docs/responses-api)[Rate Limits](https://console.groq.com/docs/rate-limits)[Templates](https://console.groq.com/docs/examples)[API Reference](https://console.groq.com/docs/api-reference)
### Core Features
[Text Generation](https://console.groq.com/docs/text-chat)[Speech to Text](https://console.groq.com/docs/speech-to-text)[Text to Speech](https://console.groq.com/docs/text-to-speech)[Orpheus](https://console.groq.com/docs/text-to-speech/orpheus)[OCR and Image Recognition](https://console.groq.com/docs/vision)[Reasoning](https://console.groq.com/docs/reasoning)[Content Moderation](https://console.groq.com/docs/content-moderation)[Structured Outputs](https://console.groq.com/docs/structured-outputs)[Prompt Caching](https://console.groq.com/docs/prompt-caching)
### Tools & Integrations
[Tool Use](https://console.groq.com/docs/tool-use/overview)[Overview](https://console.groq.com/docs/tool-use/overview)[Groq Built-In Tools](https://console.groq.com/docs/tool-use/built-in-tools)[Web Search](https://console.groq.com/docs/tool-use/built-in-tools/web-search)[Visit Website](https://console.groq.com/docs/tool-use/built-in-tools/visit-website)[Browser Automation](https://console.groq.com/docs/tool-use/built-in-tools/browser-automation)[Code Execution](https://console.groq.com/docs/tool-use/built-in-tools/code-execution)[Wolfram Alpha](https://console.groq.com/docs/tool-use/built-in-tools/wolfram-alpha)[Browser Search (GPT OSS Models)](https://console.groq.com/docs/tool-use/built-in-tools/browser-search)[Remote Tools and MCP](https://console.groq.com/docs/tool-use/remote-mcp)[Connectors](https://console.groq.com/docs/tool-use/remote-mcp/connectors)[Local Tool Calling](https://console.groq.com/docs/tool-use/local-tool-calling)[Integrations Catalog](https://console.groq.com/docs/integrations)[Coding with Groq](https://console.groq.com/docs/coding-with-groq)[Factory Droid](https://console.groq.com/docs/coding-with-groq/factory-droid)[OpenCode](https://console.groq.com/docs/coding-with-groq/opencode)[Kilo Code](https://console.groq.com/docs/coding-with-groq/kilo-code)[Roo Code](https://console.groq.com/docs/coding-with-groq/roo-code)[Cline](https://console.groq.com/docs/coding-with-groq/cline)
### Compound (Agentic AI)
[Overview](https://console.groq.com/docs/compound)[Built-In Tools](https://console.groq.com/docs/compound/built-in-tools)[Systems](https://console.groq.com/docs/compound/systems)[Use Cases](https://console.groq.com/docs/compound/use-cases)
### Guides
[Prompting Guide](https://console.groq.com/docs/prompting)[Basics](https://console.groq.com/docs/prompting)[Patterns](https://console.groq.com/docs/prompting/patterns)[Model Migration](https://console.groq.com/docs/prompting/model-migration)[Assistant Message Prefilling](https://console.groq.com/docs/prefilling)
### Service Tiers
[Service Tiers](https://console.groq.com/docs/service-tiers)[Performance Tier](https://console.groq.com/docs/performance-tier)[Flex Processing](https://console.groq.com/docs/flex-processing)[Batch Processing](https://console.groq.com/docs/batch)
### Advanced
[LoRA Inference](https://console.groq.com/docs/lora)
### Production Readiness
[Production Checklist](https://console.groq.com/docs/production-readiness/production-ready-checklist)[Optimizing Latency](https://console.groq.com/docs/production-readiness/optimizing-latency)[Security Onboarding](https://console.groq.com/docs/production-readiness/security-onboarding)[Prometheus Metrics](https://console.groq.com/docs/prometheus-metrics)
### Account and Console
[Spend Limits](https://console.groq.com/docs/spend-limits)[Projects](https://console.groq.com/docs/projects)[Model Permissions](https://console.groq.com/docs/model-permissions)[Billing FAQs](https://console.groq.com/docs/billing-faqs)[Your Data](https://console.groq.com/docs/your-data)
### Developer Resources
[SDK Libraries](https://console.groq.com/docs/libraries)[Groq Badge](https://console.groq.com/docs/badge)[Developer Community](https://community.groq.com)[OpenBench](https://openbench.dev)[Error Codes](https://console.groq.com/docs/errors)[Changelog](https://console.groq.com/docs/changelog)
### Legal
[Policies & Notices](https://console.groq.com/docs/legal)
Search`‚åò``K`
[Docs](https://console.groq.com/docs/overview)[API Reference](https://console.groq.com/docs/api-reference)
### Getting Started
[Overview](https://console.groq.com/docs/overview)
[Quickstart](https://console.groq.com/docs/quickstart)
[Models](https://console.groq.com/docs/models)
[OpenAI Compatibility](https://console.groq.com/docs/openai)
[Responses API](https://console.groq.com/docs/responses-api)
[Rate Limits](https://console.groq.com/docs/rate-limits)
[Templates](https://console.groq.com/docs/examples)
[API Reference](https://console.groq.com/docs/api-reference)
### Core Features
[Text Generation](https://console.groq.com/docs/text-chat)
[Speech to Text](https://console.groq.com/docs/speech-to-text)
[Text to Speech](https://console.groq.com/docs/text-to-speech)
[Orpheus](https://console.groq.com/docs/text-to-speech/orpheus)
[OCR and Image Recognition](https://console.groq.com/docs/vision)
[Reasoning](https://console.groq.com/docs/reasoning)
[Content Moderation](https://console.groq.com/docs/content-moderation)
[Structured Outputs](https://console.groq.com/docs/structured-outputs)
[Prompt Caching](https://console.groq.com/docs/prompt-caching)
### Tools & Integrations
[Tool Use](https://console.groq.com/docs/tool-use/overview)
[Overview](https://console.groq.com/docs/tool-use/overview)
[Groq Built-In Tools](https://console.groq.com/docs/tool-use/built-in-tools)
[Web Search](https://console.groq.com/docs/tool-use/built-in-tools/web-search)
[Visit Website](https://console.groq.com/docs/tool-use/built-in-tools/visit-website)
[Browser Automation](https://console.groq.com/docs/tool-use/built-in-tools/browser-automation)
[Code Execution](https://console.groq.com/docs/tool-use/built-in-tools/code-execution)
[Wolfram Alpha](https://console.groq.com/docs/tool-use/built-in-tools/wolfram-alpha)
[Browser Search (GPT OSS Models)](https://console.groq.com/docs/tool-use/built-in-tools/browser-search)
[Remote Tools and MCP](https://console.groq.com/docs/tool-use/remote-mcp)
[Connectors](https://console.groq.com/docs/tool-use/remote-mcp/connectors)
[Local Tool Calling](https://console.groq.com/docs/tool-use/local-tool-calling)
[Integrations Catalog](https://console.groq.com/docs/integrations)
[Coding with Groq](https://console.groq.com/docs/coding-with-groq)
[Factory Droid](https://console.groq.com/docs/coding-with-groq/factory-droid)
[OpenCode](https://console.groq.com/docs/coding-with-groq/opencode)
[Kilo Code](https://console.groq.com/docs/coding-with-groq/kilo-code)
[Roo Code](https://console.groq.com/docs/coding-with-groq/roo-code)
[Cline](https://console.groq.com/docs/coding-with-groq/cline)
### Compound (Agentic AI)
[Overview](https://console.groq.com/docs/compound)
[Built-In Tools](https://console.groq.com/docs/compound/built-in-tools)
[Systems](https://console.groq.com/docs/compound/systems)
[Use Cases](https://console.groq.com/docs/compound/use-cases)
### Guides
[Prompting Guide](https://console.groq.com/docs/prompting)
[Basics](https://console.groq.com/docs/prompting)
[Patterns](https://console.groq.com/docs/prompting/patterns)
[Model Migration](https://console.groq.com/docs/prompting/model-migration)
[Assistant Message Prefilling](https://console.groq.com/docs/prefilling)
### Service Tiers
[Service Tiers](https://console.groq.com/docs/service-tiers)
[Performance Tier](https://console.groq.com/docs/performance-tier)
[Flex Processing](https://console.groq.com/docs/flex-processing)
[Batch Processing](https://console.groq.com/docs/batch)
### Advanced
[LoRA Inference](https://console.groq.com/docs/lora)
### Production Readiness
[Production Checklist](https://console.groq.com/docs/production-readiness/production-ready-checklist)
[Optimizing Latency](https://console.groq.com/docs/production-readiness/optimizing-latency)
[Security Onboarding](https://console.groq.com/docs/production-readiness/security-onboarding)
[Prometheus Metrics](https://console.groq.com/docs/prometheus-metrics)
### Account and Console
[Spend Limits](https://console.groq.com/docs/spend-limits)
[Projects](https://console.groq.com/docs/projects)
[Model Permissions](https://console.groq.com/docs/model-permissions)
[Billing FAQs](https://console.groq.com/docs/billing-faqs)
[Your Data](https://console.groq.com/docs/your-data)
### Developer Resources
[SDK Libraries](https://console.groq.com/docs/libraries)
[Groq Badge](https://console.groq.com/docs/badge)
[Developer Community](https://community.groq.com)
[OpenBench](https://openbench.dev)
[Error Codes](https://console.groq.com/docs/errors)
[Changelog](https://console.groq.com/docs/changelog)
### Legal
[Policies & Notices](https://console.groq.com/docs/legal)
## Welcome
Fast LLM inference, OpenAI-compatible. Simple to integrate, easy to scale. Start building in minutes.
Python
```
import OpenAI from "openai";
const client = new OpenAI({
    apiKey: process.env.GROQ_API_KEY,
    baseURL: "https://api.groq.com/openai/v1",
});

const response = await client.responses.create({
    model: "openai/gpt-oss-20b",
    input: "Explain the importance of fast language models",
});
console.log(response.output_text);
```

```
1from openai import OpenAI
2import os
3client = OpenAI(
4    api_key=os.environ.get("GROQ_API_KEY"),
5    base_url="https://api.groq.com/openai/v1",
6)
7
8response = client.responses.create(
9    input="Explain the importance of fast language models",
10    model="openai/gpt-oss-20b",
11)
12print(response.output_text)
```

```
curl -X POST https://api.groq.com/openai/v1/responses \
-H "Authorization: Bearer $GROQ_API_KEY" \
-H "Content-Type: application/json" \
-d '{
    "model": "openai/gpt-oss-20b",
    "input": "Explain the importance of fast language models"
}'
```

[ ![MCP Logo](https://console.groq.com/_next/image?url=%2Fmcp.png&w=64&q=75) Google Workspace Connectors are now available on Groq Connect your AI agents to Gmail, Google Calendar, and Google Drive with ready-made connectors. Learn More ](https://console.groq.com/docs/tool-use/remote-mcp/connectors)
![Getting Started video cover](https://console.groq.com/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FlLmPol9YPyI%2Fmaxresdefault.jpg&w=3840&q=75)
## Getting Started
Take a quick video tour on how to get started building your app on Groq.
[ Quick Start Get started with the Groq API ](https://console.groq.com/docs/quickstart)[ Models See all the models Groq offers ](https://console.groq.com/docs/models)[ API Reference Explore all API endpoints ](https://console.groq.com/docs/api-reference)[ Cookbooks See code examples and tutorials ](https://github.com/groq/groq-api-cookbook)[ Rate Limits Reference the model rate limits ](https://console.groq.com/docs/rate-limits)[ Integrations Connect to external services ](https://console.groq.com/docs/integrations)
### External API Compatibility
OpenAI base URL:
https://api.groq.com/openai/v1
[Learn about](https://console.groq.com/docs/openai) OpenAI compatibility
### Was this page helpful?
YesNoSuggest Edits

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://api-docs.deepseek.com/api/deepseek-api

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://api-docs.deepseek.com/api/deepseek-api                     
| ‚úì | ‚è±: 0.56s 
[SCRAPE].. ‚óÜ https://api-docs.deepseek.com/api/deepseek-api                     
| ‚úì | ‚è±: 0.01s 
[COMPLETE] ‚óè https://api-docs.deepseek.com/api/deepseek-api                     
| ‚úì | ‚è±: 0.57s 
[Skip to main content](https://api-docs.deepseek.com/api/deepseek-api#__docusaurus_skipToContent_fallback)
[ ![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png)![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png) **DeepSeek API Docs**](https://api-docs.deepseek.com/)
[](https://api-docs.deepseek.com/api/deepseek-api#)
  * [English](https://api-docs.deepseek.com/api/deepseek-api)
  * [‰∏≠ÊñáÔºà‰∏≠ÂõΩÔºâ](https://api-docs.deepseek.com/zh-cn/api/deepseek-api)


[DeepSeek Platform](https://platform.deepseek.com/)
  * [Quick Start](https://api-docs.deepseek.com/)
    * [Your First API Call](https://api-docs.deepseek.com/)
    * [Models & Pricing](https://api-docs.deepseek.com/quick_start/pricing)
    * [The Temperature Parameter](https://api-docs.deepseek.com/quick_start/parameter_settings)
    * [Token & Token Usage](https://api-docs.deepseek.com/quick_start/token_usage)
    * [Rate Limit](https://api-docs.deepseek.com/quick_start/rate_limit)
    * [Error Codes](https://api-docs.deepseek.com/quick_start/error_codes)
  * [News](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2 Release 2025/12/01](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2-Exp Release 2025/09/29](https://api-docs.deepseek.com/news/news250929)
    * [DeepSeek V3.1 Update 2025/09/22](https://api-docs.deepseek.com/news/news250922)
    * [DeepSeek V3.1 Release 2025/08/21](https://api-docs.deepseek.com/news/news250821)
    * [DeepSeek-R1-0528 Release 2025/05/28](https://api-docs.deepseek.com/news/news250528)
    * [DeepSeek-V3-0324 Release 2025/03/25](https://api-docs.deepseek.com/news/news250325)
    * [DeepSeek-R1 Release 2025/01/20](https://api-docs.deepseek.com/news/news250120)
    * [DeepSeek APP 2025/01/15](https://api-docs.deepseek.com/news/news250115)
    * [Introducing DeepSeek-V3 2024/12/26](https://api-docs.deepseek.com/news/news1226)
    * [DeepSeek-V2.5-1210 Release 2024/12/10](https://api-docs.deepseek.com/news/news1210)
    * [DeepSeek-R1-Lite Release 2024/11/20](https://api-docs.deepseek.com/news/news1120)
    * [DeepSeek-V2.5 Release 2024/09/05](https://api-docs.deepseek.com/news/news0905)
    * [Context Caching is Available 2024/08/02](https://api-docs.deepseek.com/news/news0802)
    * [New API Features 2024/07/25](https://api-docs.deepseek.com/news/news0725)
  * [API Reference](https://api-docs.deepseek.com/api/deepseek-api)
    * [Introduction](https://api-docs.deepseek.com/api/deepseek-api)
    * [Chat](https://api-docs.deepseek.com/api/create-chat-completion)
    * [Completions](https://api-docs.deepseek.com/api/create-completion)
    * [Models](https://api-docs.deepseek.com/api/list-models)
    * [Others](https://api-docs.deepseek.com/api/get-user-balance)
  * [API Guides](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Thinking Mode](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Multi-round Conversation](https://api-docs.deepseek.com/guides/multi_round_chat)
    * [Chat Prefix Completion (Beta)](https://api-docs.deepseek.com/guides/chat_prefix_completion)
    * [FIM Completion (Beta)](https://api-docs.deepseek.com/guides/fim_completion)
    * [JSON Output](https://api-docs.deepseek.com/guides/json_mode)
    * [Tool Calls](https://api-docs.deepseek.com/guides/tool_calls)
    * [Context Caching](https://api-docs.deepseek.com/guides/kv_cache)
    * [Anthropic API](https://api-docs.deepseek.com/guides/anthropic_api)
  * [Other Resources](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [Integrations](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [API Status Page](https://status.deepseek.com/)
  * [FAQ](https://api-docs.deepseek.com/faq)
  * [Change Log](https://api-docs.deepseek.com/updates)


  * [](https://api-docs.deepseek.com/)
  * API Reference
  * Introduction


Version: 1.0.0
# DeepSeek API
The DeepSeek API. To use the DeepSeek API, please [create an API key first](https://platform.deepseek.com/api_keys).
## Authentication[‚Äã](https://api-docs.deepseek.com/api/deepseek-api#authentication "Direct link to Authentication")
  * HTTP: Bearer Auth


Security Scheme Type: | http  
---|---  
HTTP Authorization Scheme: | bearer  
Contact
DeepSeek Support: api-service@deepseek.com
Terms of Service
[](https://cdn.deepseek.com/policies/en-US/deepseek-open-platform-terms-of-service.html)
[](https://cdn.deepseek.com/policies/en-US/deepseek-open-platform-terms-of-service.html)<https://cdn.deepseek.com/policies/en-US/deepseek-open-platform-terms-of-service.html>
License
[MIT](https://opensource.org/license/mit/)
[Previous DeepSeek API Upgrade](https://api-docs.deepseek.com/news/news0725)[Next Create Chat Completion](https://api-docs.deepseek.com/api/create-chat-completion)
WeChat Official Account
  * ![WeChat QRcode](https://cdn.deepseek.com/official_account.jpg)


Community
  * Email
  * [Discord](https://discord.gg/Tc7c45Zzu5)
  * [Twitter](https://twitter.com/deepseek_ai)


More
  * [GitHub](https://github.com/deepseek-ai)


Copyright ¬© 2026 DeepSeek, Inc.

---

[web_search]
üîç DuckDuckGo results for "Mistral API pricing per 1M tokens mistral-large-latest mistral-small-latest codestral pricing page" (5 results):

1. **Mistral AI API Pricing (Updated 2026) - All Models &amp; Token Costs**
   https://pricepertoken.com/pricing-page/provider/mistral-ai
   Complete Mistral AI API pricing guide for 2026. Compare all models with per-token costs, context lengths, and pricing examples.

2. **Pricing - Mistral AI**
   https://mistral.ai/pricing
   Compare Le Chat and Mistral AI Studio plans. Transparent pricing, scalable solutions‚Äîchoose your AI power today.

3. **Mistral AI Pricing - Mistral AI**
   https://iamistral.com/pricing/
   Mistral AI price starts at $0 for hobbyists, scales to custom six-figure enterprise contracts, and remains one of the best $/token values in the LLM market thanks to super-efficient models such as Mistral Medium 3.

4. **Mistral Token Counter - LLM Token Cost Calculator**
   https://llmtokencost.com/mistral
   Mistral token counter calculator. Compare LLM token costs and pricing for Mistral language models. Calculate costs for 31 Mistral models including input and output pricing.

5. **Mistral Large 3 Pricing - API Cost Calculator | API.chat**
   https://api.chat/models/mistral/mistral-large-2512/
   Mistral Large 3 pricing: $0.5/1M input tokens, $1.5/1M output. Compare Mistral model costs and calculate your API expenses.

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://ai.google.dev/gemini-api/docs/models

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://ai.google.dev/gemini-api/docs/models                       
| ‚úì | ‚è±: 2.45s 
[SCRAPE].. ‚óÜ https://ai.google.dev/gemini-api/docs/models                       
| ‚úì | ‚è±: 0.06s 
[COMPLETE] ‚óè https://ai.google.dev/gemini-api/docs/models                       
| ‚úì | ‚è±: 2.51s 
[ Skip to main content ](https://ai.google.dev/gemini-api/docs/models#main-content)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
`/`
  * English
  * Deutsch
  * Espa√±ol ‚Äì Am√©rica Latina
  * Fran√ßais
  * Indonesia
  * Italiano
  * Polski
  * Portugu√™s ‚Äì Brasil
  * Shqip
  * Ti√™ÃÅng Vi√™Ã£t
  * T√ºrk√ße
  * –†—É—Å—Å–∫–∏–π
  * ◊¢◊ë◊®◊ô◊™
  * ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©
  * ŸÅÿßÿ±ÿ≥€å
  * ‡§π‡§ø‡§Ç‡§¶‡•Ä
  * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
  * ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
  * ‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì
  * ‰∏≠Êñá ‚Äì ÁπÅÈ´î
  * Êó•Êú¨Ë™û
  * ÌïúÍµ≠Ïñ¥

[ Get API key ](https://aistudio.google.com/apikey) [ Cookbook ](https://github.com/google-gemini/cookbook) [ Community ](https://discuss.ai.google.dev/c/gemini-api/) Sign in
[ Docs ](https://ai.google.dev/gemini-api/docs) [ API reference ](https://ai.google.dev/api)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
  * [ Gemini API  ](https://ai.google.dev/gemini-api/docs)
    * [ Docs  ](https://ai.google.dev/gemini-api/docs)
    * [ API reference  ](https://ai.google.dev/api)
  * [ Get API key  ](https://aistudio.google.com/apikey)
  * [ Cookbook  ](https://github.com/google-gemini/cookbook)
  * [ Community  ](https://discuss.ai.google.dev/c/gemini-api/)


  * Get started
  * [Overview](https://ai.google.dev/gemini-api/docs)
  * [Quickstart](https://ai.google.dev/gemini-api/docs/quickstart)
  * [API keys](https://ai.google.dev/gemini-api/docs/api-key)
  * [Libraries](https://ai.google.dev/gemini-api/docs/libraries)
  * [Interactions API](https://ai.google.dev/gemini-api/docs/interactions)
  * Models
  * [Gemini](https://ai.google.dev/gemini-api/docs/models)
  * [Gemini 3](https://ai.google.dev/gemini-api/docs/gemini-3)
  * [Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation)
  * [Veo](https://ai.google.dev/gemini-api/docs/video)
  * [Lyria](https://ai.google.dev/gemini-api/docs/music-generation)
  * [Imagen](https://ai.google.dev/gemini-api/docs/imagen)
  * [Embeddings](https://ai.google.dev/gemini-api/docs/embeddings)
  * [Robotics](https://ai.google.dev/gemini-api/docs/robotics-overview)
  * [Text-to-speech](https://ai.google.dev/gemini-api/docs/speech-generation)
  * [Pricing](https://ai.google.dev/gemini-api/docs/pricing)
  * [Rate limits](https://ai.google.dev/gemini-api/docs/rate-limits)
  * Core capabilities
  * [Text](https://ai.google.dev/gemini-api/docs/text-generation)
  * Image
    * [Image generation üçå](https://ai.google.dev/gemini-api/docs/image-generation)
    * [Image understanding](https://ai.google.dev/gemini-api/docs/image-understanding)
  * Video
    * [Video generation](https://ai.google.dev/gemini-api/docs/video)
    * [Video understanding](https://ai.google.dev/gemini-api/docs/video-understanding)
  * [Documents](https://ai.google.dev/gemini-api/docs/document-processing)
  * Speech and audio
    * [Speech generation](https://ai.google.dev/gemini-api/docs/speech-generation)
    * [Audio understanding](https://ai.google.dev/gemini-api/docs/audio)
  * Thinking
    * [Thinking](https://ai.google.dev/gemini-api/docs/thinking)
    * [Thought signatures](https://ai.google.dev/gemini-api/docs/thought-signatures)
  * [Structured outputs](https://ai.google.dev/gemini-api/docs/structured-output)
  * [Function calling](https://ai.google.dev/gemini-api/docs/function-calling)
  * [Long context](https://ai.google.dev/gemini-api/docs/long-context)
  * Tools and agents
  * [Overview](https://ai.google.dev/gemini-api/docs/tools)
  * [Deep Research](https://ai.google.dev/gemini-api/docs/deep-research)
  * [Google Search](https://ai.google.dev/gemini-api/docs/google-search)
  * [Google Maps](https://ai.google.dev/gemini-api/docs/maps-grounding)
  * [Code execution](https://ai.google.dev/gemini-api/docs/code-execution)
  * [URL context](https://ai.google.dev/gemini-api/docs/url-context)
  * [Computer Use](https://ai.google.dev/gemini-api/docs/computer-use)
  * [File Search](https://ai.google.dev/gemini-api/docs/file-search)
  * Live API
  * [Get started](https://ai.google.dev/gemini-api/docs/live)
  * [Capabilities](https://ai.google.dev/gemini-api/docs/live-guide)
  * [Tool use](https://ai.google.dev/gemini-api/docs/live-tools)
  * [Session management](https://ai.google.dev/gemini-api/docs/live-session)
  * [Ephemeral tokens](https://ai.google.dev/gemini-api/docs/ephemeral-tokens)
  * Guides
  * [Batch API](https://ai.google.dev/gemini-api/docs/batch-api)
  * File input
    * [Input methods](https://ai.google.dev/gemini-api/docs/file-input-methods)
    * [Files API](https://ai.google.dev/gemini-api/docs/files)
  * [Context caching](https://ai.google.dev/gemini-api/docs/caching)
  * [OpenAI compatibility](https://ai.google.dev/gemini-api/docs/openai)
  * [Media resolution](https://ai.google.dev/gemini-api/docs/media-resolution)
  * [Token counting](https://ai.google.dev/gemini-api/docs/tokens)
  * [Prompt engineering](https://ai.google.dev/gemini-api/docs/prompting-strategies)
  * Logs and datasets
    * [Get started with logs](https://ai.google.dev/gemini-api/docs/logs-datasets)
    * [Data logging and sharing](https://ai.google.dev/gemini-api/docs/logs-policy)
  * Safety
    * [Safety settings](https://ai.google.dev/gemini-api/docs/safety-settings)
    * [Safety guidance](https://ai.google.dev/gemini-api/docs/safety-guidance)
  * Frameworks
    * [LangChain & LangGraph](https://ai.google.dev/gemini-api/docs/langgraph-example)
    * [CrewAI](https://ai.google.dev/gemini-api/docs/crewai-example)
    * [LlamaIndex](https://ai.google.dev/gemini-api/docs/llama-index)
    * [Vercel AI SDK](https://ai.google.dev/gemini-api/docs/vercel-ai-sdk-example)
  * Resources
  * [Migrate to Gen AI SDK](https://ai.google.dev/gemini-api/docs/migrate)
  * [Release notes](https://ai.google.dev/gemini-api/docs/changelog)
  * [Deprecations](https://ai.google.dev/gemini-api/docs/deprecations)
  * [API troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshooting)
  * [Billing info](https://ai.google.dev/gemini-api/docs/billing)
  * [Partner and library integrations](https://ai.google.dev/gemini-api/docs/partner-integration)
  * Google AI Studio
    * [Quickstart](https://ai.google.dev/gemini-api/docs/ai-studio-quickstart)
    * [Vibe code in Build mode](https://ai.google.dev/gemini-api/docs/aistudio-build-mode)
    * [Try out LearnLM](https://ai.google.dev/gemini-api/docs/learnlm)
    * [Troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio)
    * [Access for Workspace users](https://ai.google.dev/gemini-api/docs/workspace)
  * Google Cloud Platform
    * [VertexAI Gemini API](https://ai.google.dev/gemini-api/docs/migrate-to-cloud)
    * [OAuth authentication](https://ai.google.dev/gemini-api/docs/oauth)
  * Policies
  * [Terms of service](https://ai.google.dev/gemini-api/terms)
  * [Available regions](https://ai.google.dev/gemini-api/docs/available-regions)
  * [Additional usage polices](https://ai.google.dev/gemini-api/docs/usage-policies)


  * [ Home ](https://ai.google.dev/)
  * [ Gemini API ](https://ai.google.dev/gemini-api)
  * [ Docs ](https://ai.google.dev/gemini-api/docs)


Send feedback 
#  Gemini models
OUR MOST INTELLIGENT MODEL
## Gemini 3 Pro
The best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet, delivering richer visuals and deeper interactivity, all built on a foundation of state-of-the-art reasoning. 
### Expand to learn more
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-3-pro-preview)
#### Model details
### Gemini 3 Pro Preview
Property | Description  
---|---  
id_cardModel code | `gemini-3-pro-preview`  
saveSupported data types |  **Inputs** Text, Image, Video, Audio, and PDF **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * `Preview: gemini-3-pro-preview`

  
calendar_monthLatest update | November 2025  
cognition_2Knowledge cutoff | January 2025  
### Gemini 3 Pro Image Preview
Property | Description  
---|---  
id_cardModel code | `gemini-3-pro-image-preview`  
saveSupported data types |  **Inputs** Image and Text **Output** Image and Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 65,536 **Output token limit** 32,768  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Not supported **Code execution** Not supported **File search** Not supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Not supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * `Preview: gemini-3-pro-image-preview`

  
calendar_monthLatest update | November 2025  
cognition_2Knowledge cutoff | January 2025  
OUR MOST BALANCED MODEL, DESIGNED TO SCALE
## Gemini 3 Flash
Our most balanced model built for speed, scale, and frontier intelligence. 
### Expand to learn more
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-3-flash-preview)
#### Model details
### Gemini 3 Flash Preview
Property | Description  
---|---  
id_cardModel code | `gemini-3-flash-preview`  
saveSupported data types |  **Inputs** Text, Image, Video, Audio, and PDF **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * `Preview: gemini-3-flash-preview`

  
calendar_monthLatest update | December 2025  
cognition_2Knowledge cutoff | January 2025  
FAST AND INTELLIGENT
## Gemini 2.5 Flash
Our best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases. 
### Expand to learn more
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash)
#### Model details
### Gemini 2.5 Flash
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash`  
saveSupported data types |  **Inputs** Text, images, video, audio **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Stable: `gemini-2.5-flash`

  
calendar_monthLatest update | June 2025  
cognition_2Knowledge cutoff | January 2025  
### Gemini 2.5 Flash Preview
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash-preview-09-2025`  
saveSupported data types |  **Inputs** Text, images, video, audio **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL Context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Preview: `gemini-2.5-flash-preview-09-2025`

  
calendar_monthLatest update | September 2025  
cognition_2Knowledge cutoff | January 2025  
### Gemini 2.5 Flash Image
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash-image`  
saveSupported data types |  **Inputs** Images and text **Output** Images and text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 65,536 **Output token limit** 32,768  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Not Supported **File search** Not Supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Supported **Live API** Not Supported **Search grounding** Not Supported **Structured outputs** Supported **Thinking** Not Supported **URL context** Not supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Stable: `gemini-2.5-flash-image`
  * Deprecated: `gemini-2.5-flash-image-preview`

  
calendar_monthLatest update | October 2025  
cognition_2Knowledge cutoff | June 2025  
### Gemini 2.5 Flash Live
Property | Description  
---|---  
id_cardModel code |  `gemini-2.5-flash-native-audio-preview-12-2025`  
saveSupported data types |  **Inputs** Audio, video, text **Output** Audio and text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 131,072 **Output token limit** 8,192  
handymanCapabilities |  **Audio generation** Supported **Batch API** Not supported **Caching** Not supported **Code execution** Not supported **File search** Not Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Supported **Search grounding** Supported **Structured outputs** Not supported **Thinking** Supported **URL context** Not supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Preview: `gemini-2.5-flash-native-audio-preview-12-2025`
  * Preview: `gemini-2.5-flash-native-audio-preview-09-2025`

  
calendar_monthLatest update | September 2025  
cognition_2Knowledge cutoff | January 2025  
### Gemini 2.5 Flash TTS
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash-preview-tts`  
saveSupported data types |  **Inputs** Text **Output** Audio  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 8,192 **Output token limit** 16,384  
handymanCapabilities |  **Audio generation** Supported **Batch API** Supported **Caching** Not supported **Code execution** Not supported **File search** Not Supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Not supported **Structured outputs** Not supported **Thinking** Not supported **URL context** Not supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * `gemini-2.5-flash-preview-tts`

  
calendar_monthLatest update | December 2025  
ULTRA FAST
## Gemini 2.5 Flash-Lite
Our fastest flash model optimized for cost-efficiency and high throughput. 
### Expand to learn more
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite)
#### Model details
### Gemini 2.5 Flash-Lite
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash-lite`  
saveSupported data types |  **Inputs** Text, image, video, audio, PDF **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Stable: `gemini-2.5-flash-lite`

  
calendar_monthLatest update | July 2025  
cognition_2Knowledge cutoff | January 2025  
### Gemini 2.5 Flash-Lite Preview
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-flash-lite-preview-09-2025`  
saveSupported data types |  **Inputs** Text, image, video, audio, PDF **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * Preview: `gemini-2.5-flash-lite-preview-09-2025`

  
calendar_monthLatest update | September 2025  
cognition_2Knowledge cutoff | January 2025  
OUR ADVANCED THINKING MODEL
## Gemini 2.5 Pro
Our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context. 
### Expand to learn more
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-pro)
#### Model details
### Gemini 2.5 Pro
Property | Description  
---|---  
id_cardModel code | `gemini-2.5-pro`  
saveSupported data types |  **Inputs** Audio, images, video, text, and PDF **Output** Text  
token_autoToken limits[[*]](https://ai.google.dev/gemini-api/docs/tokens) |  **Input token limit** 1,048,576 **Output token limit** 65,536  
handymanCapabilities |  **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported  
123Versions |  Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details.
  * `Stable: gemini-2.5-pro`

  
ca


>>>TOOL list_dir
{"path":"VSCodeiPadOS/VSCodeiPadOS/Docs"}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.claude.com/docs/en/about-claude/models/overview","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://platform.claude.com/docs/en/api/messages","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_search
{"query":"site:ai.google.dev gemini-2.0-flash input token limit output token limit model code","max_results":5}
>>>END
>>>TOOL web_search
{"query":"site:docs.mistral.ai pricing per 1M tokens mistral-large-latest mistral-small-latest codestral","max_results":5}
>>>END

---

## üîß TOOL RESULTS

[list_dir]
üìÅ VSCodeiPadOS/VSCodeiPadOS/Docs/
   KeyboardShortcuts.md
   MacServerSetup.md
   OnDeviceResearch.md
   SecurityAudit.md
   SSH_SETUP.md

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.claude.com/docs/en/about-claude/models/overview

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.claude.com/docs/en/about-claude/models/overview   
| ‚úì | ‚è±: 2.09s 
[SCRAPE].. ‚óÜ https://platform.claude.com/docs/en/about-claude/models/overview   
| ‚úì | ‚è±: 0.03s 
[COMPLETE] ‚óè https://platform.claude.com/docs/en/about-claude/models/overview   
| ‚úì | ‚è±: 2.12s 
### Cookie settings
We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).
CustomizeCustomize Cookie SettingsRejectReject All CookiesAcceptAccept All Cookies
[](https://platform.claude.com/docs/en/home)
  * [Developer Guide](https://platform.claude.com/docs/en/intro)
  * [API Reference](https://platform.claude.com/docs/en/api/overview)
  * [MCP](https://modelcontextprotocol.io)
  * [Resources](https://platform.claude.com/docs/en/resources/overview)
  * [Release Notes](https://platform.claude.com/docs/en/release-notes/overview)


English[Log in](https://platform.claude.com/login?returnTo=%2Fdocs%2Fen%2Fabout-claude%2Fmodels%2Foverview)
Search...
‚åòK
First steps
[Intro to Claude](https://platform.claude.com/docs/en/intro)[Quickstart](https://platform.claude.com/docs/en/get-started)
Models & pricing
[Models overview](https://platform.claude.com/docs/en/about-claude/models/overview)[Choosing a model](https://platform.claude.com/docs/en/about-claude/models/choosing-a-model)[What's new in Claude 4.6](https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6)[Migration guide](https://platform.claude.com/docs/en/about-claude/models/migration-guide)[Model deprecations](https://platform.claude.com/docs/en/about-claude/model-deprecations)[Pricing](https://platform.claude.com/docs/en/about-claude/pricing)
Build with Claude
[Features overview](https://platform.claude.com/docs/en/build-with-claude/overview)[Using the Messages API](https://platform.claude.com/docs/en/build-with-claude/working-with-messages)[Handling stop reasons](https://platform.claude.com/docs/en/build-with-claude/handling-stop-reasons)[Prompting best practices](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices)
Context management
[Context windows](https://platform.claude.com/docs/en/build-with-claude/context-windows)[Compaction](https://platform.claude.com/docs/en/build-with-claude/compaction)[Context editing](https://platform.claude.com/docs/en/build-with-claude/context-editing)
Capabilities
[Prompt caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching)[Extended thinking](https://platform.claude.com/docs/en/build-with-claude/extended-thinking)[Adaptive thinking](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)[Effort](https://platform.claude.com/docs/en/build-with-claude/effort)[Fast mode (research preview)](https://platform.claude.com/docs/en/build-with-claude/fast-mode)[Streaming Messages](https://platform.claude.com/docs/en/build-with-claude/streaming)[Batch processing](https://platform.claude.com/docs/en/build-with-claude/batch-processing)[Citations](https://platform.claude.com/docs/en/build-with-claude/citations)[Multilingual support](https://platform.claude.com/docs/en/build-with-claude/multilingual-support)[Token counting](https://platform.claude.com/docs/en/build-with-claude/token-counting)[Embeddings](https://platform.claude.com/docs/en/build-with-claude/embeddings)[Vision](https://platform.claude.com/docs/en/build-with-claude/vision)[PDF support](https://platform.claude.com/docs/en/build-with-claude/pdf-support)[Files API](https://platform.claude.com/docs/en/build-with-claude/files)[Search results](https://platform.claude.com/docs/en/build-with-claude/search-results)[Structured outputs](https://platform.claude.com/docs/en/build-with-claude/structured-outputs)
Tools
[Overview](https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview)[How to implement tool use](https://platform.claude.com/docs/en/agents-and-tools/tool-use/implement-tool-use)[Fine-grained tool streaming](https://platform.claude.com/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming)[Bash tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/bash-tool)[Code execution tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool)[Programmatic tool calling](https://platform.claude.com/docs/en/agents-and-tools/tool-use/programmatic-tool-calling)[Computer use tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/computer-use-tool)[Text editor tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool)[Web fetch tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-fetch-tool)[Web search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/web-search-tool)[Memory tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/memory-tool)[Tool search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)
Agent Skills
[Overview](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview)[Quickstart](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/quickstart)[Best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices)[Skills for enterprise](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/enterprise)[Using Skills with the API](https://platform.claude.com/docs/en/build-with-claude/skills-guide)
Agent SDK
[Overview](https://platform.claude.com/docs/en/agent-sdk/overview)[Quickstart](https://platform.claude.com/docs/en/agent-sdk/quickstart)[TypeScript SDK](https://platform.claude.com/docs/en/agent-sdk/typescript)[TypeScript V2 (preview)](https://platform.claude.com/docs/en/agent-sdk/typescript-v2-preview)[Python SDK](https://platform.claude.com/docs/en/agent-sdk/python)[Migration Guide](https://platform.claude.com/docs/en/agent-sdk/migration-guide)
Guides
MCP in the API
[MCP connector](https://platform.claude.com/docs/en/agents-and-tools/mcp-connector)[Remote MCP servers](https://platform.claude.com/docs/en/agents-and-tools/remote-mcp-servers)
Claude on 3rd-party platforms
[Amazon Bedrock](https://platform.claude.com/docs/en/build-with-claude/claude-on-amazon-bedrock)[Microsoft Foundry](https://platform.claude.com/docs/en/build-with-claude/claude-in-microsoft-foundry)[Vertex AI](https://platform.claude.com/docs/en/build-with-claude/claude-on-vertex-ai)
Prompt engineering
[Overview](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview)[Prompt generator](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-generator)[Use prompt templates](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-templates-and-variables)[Prompt improver](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/prompt-improver)[Be clear and direct](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)[Use examples (multishot prompting)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/multishot-prompting)[Let Claude think (CoT)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought)[Use XML tags](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags)[Give Claude a role (system prompts)](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/system-prompts)[Chain complex prompts](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-prompts)[Long context tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/long-context-tips)[Extended thinking tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips)
Test & evaluate
[Define success criteria](https://platform.claude.com/docs/en/test-and-evaluate/define-success)[Develop test cases](https://platform.claude.com/docs/en/test-and-evaluate/develop-tests)[Using the Evaluation Tool](https://platform.claude.com/docs/en/test-and-evaluate/eval-tool)[Reducing latency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-latency)
Strengthen guardrails
[Reduce hallucinations](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-hallucinations)[Increase output consistency](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/increase-consistency)[Mitigate jailbreaks](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)[Streaming refusals](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals)[Reduce prompt leak](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak)[Keep Claude in character](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/keep-claude-in-character)
Administration and monitoring
[Admin API overview](https://platform.claude.com/docs/en/build-with-claude/administration-api)[Data residency](https://platform.claude.com/docs/en/build-with-claude/data-residency)[Workspaces](https://platform.claude.com/docs/en/build-with-claude/workspaces)[Usage and Cost API](https://platform.claude.com/docs/en/build-with-claude/usage-cost-api)[Claude Code Analytics API](https://platform.claude.com/docs/en/build-with-claude/claude-code-analytics-api)[Zero Data Retention](https://platform.claude.com/docs/en/build-with-claude/zero-data-retention)
[Console](https://platform.claude.com/)
[Log in](https://platform.claude.com/login)
Models & pricingModels overview
Models & pricing
# Models overview
Copy page
Claude is a family of state-of-the-art large language models developed by Anthropic. This guide introduces our models and compares their performance.
Copy page
## 
Choosing a model
If you're unsure which model to use, we recommend starting with **Claude Opus 4.6** for the most complex tasks. It is our latest generation model with exceptional performance in coding and reasoning.
All current Claude models support text and image input, text output, multilingual capabilities, and vision. Models are available via the Anthropic API, AWS Bedrock, and Google Vertex AI.
Once you've picked a model, [learn how to make your first API call](https://platform.claude.com/docs/en/get-started).
### 
Latest models comparison
Feature | Claude Opus 4.6 | Claude Sonnet 4.5 | Claude Haiku 4.5  
---|---|---|---  
**Description** | Our most intelligent model for building agents and coding | Our best combination of speed and intelligence | Our fastest model with near-frontier intelligence  
**Claude API ID** | claude-opus-4-6 | claude-sonnet-4-5-20250929 | claude-haiku-4-5-20251001  
**Claude API alias** | claude-opus-4-6 | claude-sonnet-4-5 | claude-haiku-4-5  
**AWS Bedrock ID** | anthropic.claude-opus-4-6-v1 | anthropic.claude-sonnet-4-5-20250929-v1:0 | anthropic.claude-haiku-4-5-20251001-v1:0  
**GCP Vertex AI ID** | claude-opus-4-6 | claude-sonnet-4-5@20250929 | claude-haiku-4-5@20251001  
**Pricing** 1 | $5 / input MTok  
$25 / output MTok | $3 / input MTok  
$15 / output MTok | $1 / input MTok  
$5 / output MTok  
**[Extended thinking](https://platform.claude.com/docs/en/build-with-claude/extended-thinking)** | Yes | Yes | Yes  
**[Adaptive thinking](https://platform.claude.com/docs/en/build-with-claude/adaptive-thinking)** | Yes | No | No  
**[Priority Tier](https://platform.claude.com/docs/en/api/service-tiers)** | Yes | Yes | Yes  
**Comparative latency** | Moderate | Fast | Fastest  
**Context window** |  200K tokens /   
1M tokens (beta)3 |  200K tokens /   
1M tokens (beta)3 | 200K tokens  
**Max output** | 128K tokens | 64K tokens | 64K tokens  
**Reliable knowledge cutoff** | May 20252 | Jan 20252 | Feb 2025  
**Training data cutoff** | Aug 2025 | Jul 2025 | Jul 2025  
_1 - See our[pricing page](https://platform.claude.com/docs/en/about-claude/pricing) for complete pricing information including batch API discounts, prompt caching rates, extended thinking costs, and vision processing fees._
_2 -**Reliable knowledge cutoff** indicates the date through which a model's knowledge is most extensive and reliable. **Training data cutoff** is the broader date range of training data used. For more information, see [Anthropic's Transparency Hub](https://www.anthropic.com/transparency)._
_3 - Claude Opus 4.6 and Sonnet 4.5 support a[1M token context window](https://platform.claude.com/docs/en/build-with-claude/context-windows#1m-token-context-window) when using the `context-1m-2025-08-07` beta header. [Long context pricing](https://platform.claude.com/docs/en/about-claude/pricing#long-context-pricing) applies to requests exceeding 200K tokens._
Models with the same snapshot date (e.g., 20240620) are identical across all platforms and do not change. The snapshot date in the model name ensures consistency and allows developers to rely on stable performance across different environments.
Starting with **Claude Sonnet 4.5 and all subsequent models** , AWS Bedrock and Google Vertex AI offer two endpoint types: **global endpoints** (dynamic routing for maximum availability) and **regional endpoints** (guaranteed data routing through specific geographic regions). For more information, see the [third-party platform pricing section](https://platform.claude.com/docs/en/about-claude/pricing#third-party-platform-pricing).
### Legacy models
## 
Prompt and output performance
Claude 4 models excel in:
  * **Performance** : Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing. See the [Claude 4 blog post](http://www.anthropic.com/news/claude-4) for more information.
  * **Engaging responses** : Claude models are ideal for applications that require rich, human-like interactions.
    * If you prefer more concise responses, you can adjust your prompts to guide the model toward the desired output length. Refer to our [prompt engineering guides](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering) for details.
    * For prompting best practices, see our [prompting best practices guide](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices).
  * **Output quality** : When migrating from previous model generations to Claude 4, you may notice larger improvements in overall performance.


## 
Migrating to Claude 4.6
If you're currently using older Claude models, we recommend migrating to Claude Opus 4.6 to take advantage of improved intelligence and enhanced capabilities. For detailed migration instructions, see [Migrating to Claude 4.6](https://platform.claude.com/docs/en/about-claude/models/migration-guide).
## 
Get started with Claude
If you're ready to start exploring what Claude can do for you, let's dive in! Whether you're a developer looking to integrate Claude into your applications or a user wanting to experience the power of AI firsthand, we've got you covered.
Looking to chat with Claude? Visit [claude.ai](http://www.claude.ai)!
[ Intro to Claude Explore Claude's capabilities and development flow. ](https://platform.claude.com/docs/en/intro)[ Quickstart Learn how to make your first API call in minutes. ](https://platform.claude.com/docs/en/get-started)[ Claude Console Craft and test powerful prompts directly in your browser. ](https://platform.claude.com/)
If you have any questions or need assistance, don't hesitate to reach out to our [support team](https://support.claude.com/) or consult the [Discord community](https://www.anthropic.com/discord).
Was this page helpful?
  * [Choosing a model](https://platform.claude.com/docs/en/about-claude/models/overview#choosing-a-model)
  * [Latest models comparison](https://platform.claude.com/docs/en/about-claude/models/overview#latest-models-comparison)
  * [Prompt and output performance](https://platform.claude.com/docs/en/about-claude/models/overview#prompt-and-output-performance)
  * [Migrating to Claude 4.6](https://platform.claude.com/docs/en/about-claude/models/overview#migrating-to-claude-4-6)
  * [Get started with Claude](https://platform.claude.com/docs/en/about-claude/models/overview#get-started-with-claude)


[](https://platform.claude.com/docs)
[](https://x.com/claudeai)[](https://www.linkedin.com/showcase/claude)[](https://instagram.com/claudeai)
### Solutions
  * [AI agents](https://claude.com/solutions/agents)
  * [Code modernization](https://claude.com/solutions/code-modernization)
  * [Coding](https://claude.com/solutions/coding)
  * [Customer support](https://claude.com/solutions/customer-support)
  * [Education](https://claude.com/solutions/education)
  * [Financial services](https://claude.com/solutions/financial-services)
  * [Government](https://claude.com/solutions/government)
  * [Life sciences](https://claude.com/solutions/life-sciences)


### Partners
  * [Amazon Bedrock](https://claude.com/partners/amazon-bedrock)
  * [Google Cloud's Vertex AI](https://claude.com/partners/google-cloud-vertex-ai)


### Learn
  * [Blog](https://claude.com/blog)
  * [Catalog](https://claude.ai/catalog/artifacts)
  * [Courses](https://www.anthropic.com/learn)
  * [Use cases](https://claude.com/resources/use-cases)
  * [Connectors](https://claude.com/partners/mcp)
  * [Customer stories](https://claude.com/customers)
  * [Engineering at Anthropic](https://www.anthropic.com/engineering)
  * [Events](https://www.anthropic.com/events)
  * [Powered by Claude](https://claude.com/partners/powered-by-claude)
  * [Service partners](https://claude.com/partners/services)
  * [Startups program](https://claude.com/programs/startups)


### Company
  * [Anthropic](https://www.anthropic.com/company)
  * [Careers](https://www.anthropic.com/careers)
  * [Economic Futures](https://www.anthropic.com/economic-futures)
  * [Research](https://www.anthropic.com/research)
  * [News](https://www.anthropic.com/news)
  * [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)
  * [Security and compliance](https://trust.anthropic.com)
  * [Transparency](https://www.anthropic.com/transparency)


### Learn
  * [Blog](https://claude.com/blog)
  * [Catalog](https://claude.ai/catalog/artifacts)
  * [Courses](https://www.anthropic.com/learn)
  * [Use cases](https://claude.com/resources/use-cases)
  * [Connectors](https://claude.com/partners/mcp)
  * [Customer stories](https://claude.com/customers)
  * [Engineering at Anthropic](https://www.anthropic.com/engineering)
  * [Events](https://www.anthropic.com/events)
  * [Powered by Claude](https://claude.com/partners/powered-by-claude)
  * [Service partners](https://claude.com/partners/services)
  * [Startups program](https://claude.com/programs/startups)


### Help and security
  * [Availability](https://www.anthropic.com/supported-countries)
  * [Status](https://status.claude.com/)
  * [Support](https://support.claude.com/)
  * [Discord](https://www.anthropic.com/discord)


### Terms and policies
  * [Privacy policy](https://www.anthropic.com/legal/privacy)
  * [Responsible disclosure policy](https://www.anthropic.com/responsible-disclosure-policy)
  * [Terms of service: Commercial](https://www.anthropic.com/legal/commercial-terms)
  * [Terms of service: Consumer](https://www.anthropic.com/legal/consumer-terms)
  * [Usage policy](https://www.anthropic.com/legal/aup)

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.claude.com/docs/en/api/messages

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.claude.com/docs/en/api/messages                   
| ‚úì | ‚è±: 3.25s 
[SCRAPE].. ‚óÜ https://platform.claude.com/docs/en/api/messages                   
| ‚úì | ‚è±: 1.85s 
[COMPLETE] ‚óè https://platform.claude.com/docs/en/api/messages                   
| ‚úì | ‚è±: 5.12s 
### Cookie settings
We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).
CustomizeCustomize Cookie SettingsRejectReject All CookiesAcceptAccept All Cookies
[](https://platform.claude.com/docs/en/home)
  * [Developer Guide](https://platform.claude.com/docs/en/intro)
  * [API Reference](https://platform.claude.com/docs/en/api/overview)
  * [MCP](https://modelcontextprotocol.io)
  * [Resources](https://platform.claude.com/docs/en/resources/overview)
  * [Release Notes](https://platform.claude.com/docs/en/release-notes/overview)


English[Log in](https://platform.claude.com/login?returnTo=%2Fdocs%2Fen%2Fapi%2Fmessages)
Search...
‚åòK
Using the API
[API overview](https://platform.claude.com/docs/en/api/overview)[Beta headers](https://platform.claude.com/docs/en/api/beta-headers)[Errors](https://platform.claude.com/docs/en/api/errors)
Client SDKs
[Client SDKs overview](https://platform.claude.com/docs/en/api/client-sdks)[Python SDK](https://platform.claude.com/docs/en/api/sdks/python)[TypeScript SDK](https://platform.claude.com/docs/en/api/sdks/typescript)[Java SDK](https://platform.claude.com/docs/en/api/sdks/java)[Go SDK](https://platform.claude.com/docs/en/api/sdks/go)[Ruby SDK](https://platform.claude.com/docs/en/api/sdks/ruby)[C# SDK](https://platform.claude.com/docs/en/api/sdks/csharp)[PHP SDK](https://platform.claude.com/docs/en/api/sdks/php)
[Messages](https://platform.claude.com/docs/en/api/messages)
[Create a Message](https://platform.claude.com/docs/en/api/messages/create)[Count tokens in a Message](https://platform.claude.com/docs/en/api/messages/count_tokens)
Batches
[Models](https://platform.claude.com/docs/en/api/models)
[List Models](https://platform.claude.com/docs/en/api/models/list)[Get a Model](https://platform.claude.com/docs/en/api/models/retrieve)
[Beta](https://platform.claude.com/docs/en/api/beta)
Models
Messages
Files
Skills
[Admin](https://platform.claude.com/docs/en/api/admin)
Organizations
Invites
Users
Workspaces
API Keys
Usage Report
Cost Report
[Completions](https://platform.claude.com/docs/en/api/completions)
[Create a Text Completion](https://platform.claude.com/docs/en/api/completions/create)
Support & configuration
[Rate limits](https://platform.claude.com/docs/en/api/rate-limits)[Service tiers](https://platform.claude.com/docs/en/api/service-tiers)[Versions](https://platform.claude.com/docs/en/api/versioning)[IP addresses](https://platform.claude.com/docs/en/api/ip-addresses)[Supported regions](https://platform.claude.com/docs/en/api/supported-regions)[OpenAI SDK compatibility](https://platform.claude.com/docs/en/api/openai-sdk)
[Console](https://platform.claude.com/)
[Log in](https://platform.claude.com/login)
API ReferenceMessages
Copy page
cURL
# Messages
##### [Create a Message](https://platform.claude.com/docs/en/api/messages/create)
/v1/messages
##### [Count tokens in a Message](https://platform.claude.com/docs/en/api/messages/count_tokens)
/v1/messages/count_tokens
##### ModelsExpand Collapse 
Base64ImageSource = object { data, media_type, type } 
data: string
media_type: "image/jpeg" or "image/png" or "image/gif" or "image/webp"
Accepts one of the following:
"image/jpeg"
"image/png"
"image/gif"
"image/webp"
type: "base64"
Accepts one of the following:
"base64"
Base64PDFSource = object { data, media_type, type } 
data: string
media_type: "application/pdf"
Accepts one of the following:
"application/pdf"
type: "base64"
Accepts one of the following:
"base64"
CacheControlEphemeral = object { type, ttl } 
type: "ephemeral"
Accepts one of the following:
"ephemeral"
ttl: optional "5m" or "1h"
The time-to-live for the cache control breakpoint.
This may be one the following values:
  * `5m`: 5 minutes
  * `1h`: 1 hour


Defaults to `5m`.
Accepts one of the following:
"5m"
"1h"
CacheCreation = object { ephemeral_1h_input_tokens, ephemeral_5m_input_tokens } 
ephemeral_1h_input_tokens: number
The number of input tokens used to create the 1 hour cache entry.
minimum0
ephemeral_5m_input_tokens: number
The number of input tokens used to create the 5 minute cache entry.
minimum0
CitationCharLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
file_id: string
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationCharLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationContentBlockLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
file_id: string
start_block_index: number
type: "content_block_location"
Accepts one of the following:
"content_block_location"
CitationContentBlockLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
start_block_index: number
type: "content_block_location"
Accepts one of the following:
"content_block_location"
CitationPageLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
file_id: string
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationPageLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationSearchResultLocationParam = object { cited_text, end_block_index, search_result_index, 4 more } 
cited_text: string
end_block_index: number
search_result_index: number
source: string
start_block_index: number
title: string
type: "search_result_location"
Accepts one of the following:
"search_result_location"
CitationWebSearchResultLocationParam = object { cited_text, encrypted_index, title, 2 more } 
cited_text: string
encrypted_index: string
title: string
type: "web_search_result_location"
Accepts one of the following:
"web_search_result_location"
url: string
CitationsConfigParam = object { enabled } 
enabled: optional boolean
CitationsDelta = object { citation, type } 
citation: [CitationCharLocation](https://platform.claude.com/docs/en/api/messages#citation_char_location) { cited_text, document_index, document_title, 4 more }  or [CitationPageLocation](https://platform.claude.com/docs/en/api/messages#citation_page_location) { cited_text, document_index, document_title, 4 more }  or [CitationContentBlockLocation](https://platform.claude.com/docs/en/api/messages#citation_content_block_location) { cited_text, document_index, document_title, 4 more }  or 2 more
Accepts one of the following:
CitationCharLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
file_id: string
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationPageLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
file_id: string
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationContentBlockLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
file_id: string
start_block_index: number
type: "content_block_location"
Accepts one of the following:
"content_block_location"
CitationsWebSearchResultLocation = object { cited_text, encrypted_index, title, 2 more } 
cited_text: string
encrypted_index: string
title: string
type: "web_search_result_location"
Accepts one of the following:
"web_search_result_location"
url: string
CitationsSearchResultLocation = object { cited_text, end_block_index, search_result_index, 4 more } 
cited_text: string
end_block_index: number
search_result_index: number
source: string
start_block_index: number
title: string
type: "search_result_location"
Accepts one of the following:
"search_result_location"
type: "citations_delta"
Accepts one of the following:
"citations_delta"
CitationsSearchResultLocation = object { cited_text, end_block_index, search_result_index, 4 more } 
cited_text: string
end_block_index: number
search_result_index: number
source: string
start_block_index: number
title: string
type: "search_result_location"
Accepts one of the following:
"search_result_location"
CitationsWebSearchResultLocation = object { cited_text, encrypted_index, title, 2 more } 
cited_text: string
encrypted_index: string
title: string
type: "web_search_result_location"
Accepts one of the following:
"web_search_result_location"
url: string
ContentBlock = [TextBlock](https://platform.claude.com/docs/en/api/messages#text_block) { citations, text, type }  or [ThinkingBlock](https://platform.claude.com/docs/en/api/messages#thinking_block) { signature, thinking, type }  or [RedactedThinkingBlock](https://platform.claude.com/docs/en/api/messages#redacted_thinking_block) { data, type }  or 3 more
Accepts one of the following:
TextBlock = object { citations, text, type } 
citations: array of [TextCitation](https://platform.claude.com/docs/en/api/messages#text_citation)
Citations supporting the text block.
The type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.
Accepts one of the following:
CitationCharLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
file_id: string
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationPageLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
file_id: string
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationContentBlockLocation = object { cited_text, document_index, document_title, 4 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
file_id: string
start_block_index: number
type: "content_block_location"
Accepts one of the following:
"content_block_location"
CitationsWebSearchResultLocation = object { cited_text, encrypted_index, title, 2 more } 
cited_text: string
encrypted_index: string
title: string
type: "web_search_result_location"
Accepts one of the following:
"web_search_result_location"
url: string
CitationsSearchResultLocation = object { cited_text, end_block_index, search_result_index, 4 more } 
cited_text: string
end_block_index: number
search_result_index: number
source: string
start_block_index: number
title: string
type: "search_result_location"
Accepts one of the following:
"search_result_location"
text: string
type: "text"
Accepts one of the following:
"text"
ThinkingBlock = object { signature, thinking, type } 
signature: string
thinking: string
type: "thinking"
Accepts one of the following:
"thinking"
RedactedThinkingBlock = object { data, type } 
data: string
type: "redacted_thinking"
Accepts one of the following:
"redacted_thinking"
ToolUseBlock = object { id, input, name, type } 
id: string
input: map[unknown]
name: string
type: "tool_use"
Accepts one of the following:
"tool_use"
ServerToolUseBlock = object { id, input, name, type } 
id: string
input: map[unknown]
name: "web_search"
Accepts one of the following:
"web_search"
type: "server_tool_use"
Accepts one of the following:
"server_tool_use"
WebSearchToolResultBlock = object { content, tool_use_id, type } 
content: [WebSearchToolResultBlockContent](https://platform.claude.com/docs/en/api/messages#web_search_tool_result_block_content)
Accepts one of the following:
WebSearchToolResultError = object { error_code, type } 
error_code: "invalid_tool_input" or "unavailable" or "max_uses_exceeded" or 3 more
Accepts one of the following:
"invalid_tool_input"
"unavailable"
"max_uses_exceeded"
"too_many_requests"
"query_too_long"
"request_too_large"
type: "web_search_tool_result_error"
Accepts one of the following:
"web_search_tool_result_error"
UnionMember1 = array of [WebSearchResultBlock](https://platform.claude.com/docs/en/api/messages#web_search_result_block) { encrypted_content, page_age, title, 2 more } 
encrypted_content: string
page_age: string
title: string
type: "web_search_result"
Accepts one of the following:
"web_search_result"
url: string
tool_use_id: string
type: "web_search_tool_result"
Accepts one of the following:
"web_search_tool_result"
ContentBlockParam = [TextBlockParam](https://platform.claude.com/docs/en/api/messages#text_block_param) { text, type, cache_control, citations }  or [ImageBlockParam](https://platform.claude.com/docs/en/api/messages#image_block_param) { source, type, cache_control }  or [DocumentBlockParam](https://platform.claude.com/docs/en/api/messages#document_block_param) { source, type, cache_control, 3 more }  or 7 more
Regular text content.
Accepts one of the following:
TextBlockParam = object { text, type, cache_control, citations } 
text: string
type: "text"
Accepts one of the following:
"text"
cache_control: optional [CacheControlEphemeral](https://platform.claude.com/docs/en/api/messages#cache_control_ephemeral) { type, ttl } 
Create a cache control breakpoint at this content block.
type: "ephemeral"
Accepts one of the following:
"ephemeral"
ttl: optional "5m" or "1h"
The time-to-live for the cache control breakpoint.
This may be one the following values:
  * `5m`: 5 minutes
  * `1h`: 1 hour


Defaults to `5m`.
Accepts one of the following:
"5m"
"1h"
citations: optional array of [TextCitationParam](https://platform.claude.com/docs/en/api/messages#text_citation_param)
Accepts one of the following:
CitationCharLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationPageLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationContentBlockLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
start_block_index: number
type: "content_block_location"
Accepts one of the following:
"content_block_location"
CitationWebSearchResultLocationParam = object { cited_text, encrypted_index, title, 2 more } 
cited_text: string
encrypted_index: string
title: string
type: "web_search_result_location"
Accepts one of the following:
"web_search_result_location"
url: string
CitationSearchResultLocationParam = object { cited_text, end_block_index, search_result_index, 4 more } 
cited_text: string
end_block_index: number
search_result_index: number
source: string
start_block_index: number
title: string
type: "search_result_location"
Accepts one of the following:
"search_result_location"
ImageBlockParam = object { source, type, cache_control } 
source: [Base64ImageSource](https://platform.claude.com/docs/en/api/messages#base64_image_source) { data, media_type, type }  or [URLImageSource](https://platform.claude.com/docs/en/api/messages#url_image_source) { type, url } 
Accepts one of the following:
Base64ImageSource = object { data, media_type, type } 
data: string
media_type: "image/jpeg" or "image/png" or "image/gif" or "image/webp"
Accepts one of the following:
"image/jpeg"
"image/png"
"image/gif"
"image/webp"
type: "base64"
Accepts one of the following:
"base64"
URLImageSource = object { type, url } 
type: "url"
Accepts one of the following:
"url"
url: string
type: "image"
Accepts one of the following:
"image"
cache_control: optional [CacheControlEphemeral](https://platform.claude.com/docs/en/api/messages#cache_control_ephemeral) { type, ttl } 
Create a cache control breakpoint at this content block.
type: "ephemeral"
Accepts one of the following:
"ephemeral"
ttl: optional "5m" or "1h"
The time-to-live for the cache control breakpoint.
This may be one the following values:
  * `5m`: 5 minutes
  * `1h`: 1 hour


Defaults to `5m`.
Accepts one of the following:
"5m"
"1h"
DocumentBlockParam = object { source, type, cache_control, 3 more } 
source: [Base64PDFSource](https://platform.claude.com/docs/en/api/messages#base64_pdf_source) { data, media_type, type }  or [PlainTextSource](https://platform.claude.com/docs/en/api/messages#plain_text_source) { data, media_type, type }  or [ContentBlockSource](https://platform.claude.com/docs/en/api/messages#content_block_source) { content, type }  or [URLPDFSource](https://platform.claude.com/docs/en/api/messages#url_pdf_source) { type, url } 
Accepts one of the following:
Base64PDFSource = object { data, media_type, type } 
data: string
media_type: "application/pdf"
Accepts one of the following:
"application/pdf"
type: "base64"
Accepts one of the following:
"base64"
PlainTextSource = object { data, media_type, type } 
data: string
media_type: "text/plain"
Accepts one of the following:
"text/plain"
type: "text"
Accepts one of the following:
"text"
ContentBlockSource = object { content, type } 
content: string or array of [ContentBlockSourceContent](https://platform.claude.com/docs/en/api/messages#content_block_source_content)
Accepts one of the following:
UnionMember0 = string
ContentBlockSourceContent = array of [ContentBlockSourceContent](https://platform.claude.com/docs/en/api/messages#content_block_source_content)
Accepts one of the following:
TextBlockParam = object { text, type, cache_control, citations } 
text: string
type: "text"
Accepts one of the following:
"text"
cache_control: optional [CacheControlEphemeral](https://platform.claude.com/docs/en/api/messages#cache_control_ephemeral) { type, ttl } 
Create a cache control breakpoint at this content block.
type: "ephemeral"
Accepts one of the following:
"ephemeral"
ttl: optional "5m" or "1h"
The time-to-live for the cache control breakpoint.
This may be one the following values:
  * `5m`: 5 minutes
  * `1h`: 1 hour


Defaults to `5m`.
Accepts one of the following:
"5m"
"1h"
citations: optional array of [TextCitationParam](https://platform.claude.com/docs/en/api/messages#text_citation_param)
Accepts one of the following:
CitationCharLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_char_index: number
start_char_index: number
type: "char_location"
Accepts one of the following:
"char_location"
CitationPageLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_page_number: number
start_page_number: number
type: "page_location"
Accepts one of the following:
"page_location"
CitationContentBlockLocationParam = object { cited_text, document_index, document_title, 3 more } 
cited_text: string
document_index: number
document_title: string
end_block_index: number
start_block_index: number
type: "content_block_lo

---

[web_search]
üîç DuckDuckGo results for "site:ai.google.dev gemini-2.0-flash input token limit output token limit model code" (5 results):

1. **Rate limits | Gemini API | Google AI for Developers**
   https://ai.google.dev/gemini-api/docs/rate-limits
   Rate limits regulate the number of requests you can make to the Gemini API within a given timeframe. These limits help maintain fair usage, protect against abuse, and help maintain system performance for all users. View your active rate limits in AI Studio How rate limits work Rate limits are usually measured across three dimensions: Requests per minute (RPM) Tokens per minute (input) (TPM ...

2. **Understand and count tokens - Gemini API | Google AI for Developers**
   https://ai.google.dev/gemini-api/docs/tokens
   In the following example, you can see that the gemini-2.0-flash model has an input limit of about 1,000,000 tokens and an output limit of about 8,000 tokens, which means a context window is 1,000,000 tokens.

3. **`max_output_tokens` isn&#x27;t respected when using `gemini-2.5-flash` model**
   https://discuss.ai.google.dev/t/max-output-tokens-isnt-respected-when-using-gemini-2-5-flash-model/106708
   Heya, Currently using the Python google.genai package to interact with Gemini, I wanted to set a limit to how many tokens can be used for generating a response but it seems that when using the model gemini-2.5-flash and setting max_output_tokens=1, it doesn&#x27;t take max_output_tokens into account.

4. **Token limit error (1.5 Pro and Flash) - Gemini API - Google AI ...**
   https://discuss.ai.google.dev/t/token-limit-error-1-5-pro-and-flash/57488
   If anyone has similar issues with Gemini 2.0 Flash with structured output, I solved the issue by adding more tokens (!). By adding ~2000 additional tokens to my system prompt, marked as padding to not confuse the model, the requests worked again! Topic Replies Views Activity Incorrect gemini-2.5-pro input token limit response Gemini API api , models 4 406 January 13, 2026 Input token limits ...

5. **Gemini models | Gemini API | Google AI for Developers**
   https://ai.google.dev/gemini-api/docs/models
   Gemini 2.5 Flash-Lite Our fastest flash model optimized for cost-efficiency and high throughput. Expand to learn more OUR ADVANCED THINKING MODEL Gemini 2.5 Pro Our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.

---

[web_search]
üîç DuckDuckGo results for "site:docs.mistral.ai pricing per 1M tokens mistral-large-latest mistral-small-latest codestral" (5 results):

1. **Pricing | Mistral Docs**
   https://docs.mistral.ai/deployment/ai-studio/pricing
   Documentation for the deployment and usage of Mistral AI&#x27;s LLMs

2. **Documentation - Mistral AI**
   https://docs.mistral.ai/
   Learn how to deploy and use Mistral AI&#x27;s Large Language Models with our comprehensive documentation, guides, and tutorials.

3. **Compare Models | Mistral Docs**
   https://docs.mistral.ai/getting-started/models/compare?models=mistral-large-1-0-24-02
   Documentation for the deployment and usage of Mistral AI&#x27;s LLMs

4. **Models - Mistral Docs**
   https://docs.mistral.ai/getting-started/models
   Documentation for the deployment and usage of Mistral AI&#x27;s LLMs

5. **Rate Limits &amp; Usage tiers | Mistral Docs**
   https://docs.mistral.ai/deployment/ai-studio/tier
   Documentation for the deployment and usage of Mistral AI&#x27;s LLMs


>>>TOOL web_fetch
{"url":"https://platform.moonshot.ai/docs/api/chat","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://api-docs.deepseek.com/api/create-chat-completion","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://docs.mistral.ai/deployment/ai-studio/pricing","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_fetch
{"url":"https://ai.google.dev/gemini-api/docs/tokens","use_crawl4ai":true,"max_length":20000}
>>>END
>>>TOOL web_search
{"query":"site:platform.claude.com \"Sonnet 3.7\" \"Context window\" 200K","max_results":5}
>>>END

---

## üîß TOOL RESULTS

[web_fetch]
üï∑Ô∏è Crawl4AI: https://platform.moonshot.ai/docs/api/chat

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://platform.moonshot.ai/docs/api/chat                         
| ‚úì | ‚è±: 1.12s 
[SCRAPE].. ‚óÜ https://platform.moonshot.ai/docs/api/chat                         
| ‚úì | ‚è±: 0.05s 
[COMPLETE] ‚óè https://platform.moonshot.ai/docs/api/chat                         
| ‚úì | ‚è±: 1.17s 
üéâ New kimi k2.5 Multi-modal Model released! Now supports multimodal understanding and processing. [Limited-time top-up bonus is live](https://platform.moonshot.ai/docs/promotion)!
[Platform](https://platform.moonshot.ai/)[Contact Sales](https://platform.moonshot.ai/contact-sales)[Blog](https://platform.moonshot.ai/blog)[Docs](https://platform.moonshot.ai/docs/overview)[Playground](https://platform.moonshot.ai/playground)[Console](https://platform.moonshot.ai/console)
`CTRL K`
`CTRL K`
  * [Welcome](https://platform.moonshot.ai/docs/overview)
  * [User Manual](https://platform.moonshot.ai/docs/introduction)
  * API Reference
    * [Chat](https://platform.moonshot.ai/docs/api/chat)
    * [Tool Use](https://platform.moonshot.ai/docs/api/tool-use)
    * [Partial Mode](https://platform.moonshot.ai/docs/api/partial)
    * [Files](https://platform.moonshot.ai/docs/api/files)
    * [Estimate Token](https://platform.moonshot.ai/docs/api/estimate)
    * [Check Balance](https://platform.moonshot.ai/docs/api/balance)
  * [üéâ Promotions](https://platform.moonshot.ai/docs/promotion)
  * Product Pricing
    * [Chat Pricing](https://platform.moonshot.ai/docs/pricing/chat)
    * [WebSearch Pricing](https://platform.moonshot.ai/docs/pricing/tools)
    * [Recharge and Rate Limiting](https://platform.moonshot.ai/docs/pricing/limits)
    * [FAQ](https://platform.moonshot.ai/docs/pricing/faq)
  * Getting Started Guide
    * [Kimi K2.5 Multi-modal Model](https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart)
    * [Kimi K2](https://platform.moonshot.ai/docs/guide/kimi-k2-quickstart)
    * [Using Thinking Models](https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model)
    * [Quickstart with Kimi API](https://platform.moonshot.ai/docs/guide/start-using-kimi-api)
    * [Use Kimi K2.5 in OpenClaw](https://platform.moonshot.ai/docs/guide/use-kimi-in-openclaw)
    * [Switch from OpenAI to Kimi API](https://platform.moonshot.ai/docs/guide/migrating-from-openai-to-kimi)
    * [Use the API Debugging Tool](https://platform.moonshot.ai/docs/guide/use-moonpalace)
    * [Conduct Multi-turn Chat with Kimi API](https://platform.moonshot.ai/docs/guide/engage-in-multi-turn-conversations-using-kimi-api)
    * [Use the Kimi Vision Model](https://platform.moonshot.ai/docs/guide/use-kimi-vision-model)
    * [Automatic Reconnection](https://platform.moonshot.ai/docs/guide/auto-reconnect)
    * [Use the Streaming Feature of the Kimi API](https://platform.moonshot.ai/docs/guide/utilize-the-streaming-output-feature-of-kimi-api)
    * [Use Tool Calls with Kimi API](https://platform.moonshot.ai/docs/guide/use-kimi-api-to-complete-tool-calls)
    * [Use the Web Search Tool](https://platform.moonshot.ai/docs/guide/use-web-search)
    * [Use JSON Mode with Kimi API](https://platform.moonshot.ai/docs/guide/use-json-mode-feature-of-kimi-api)
    * [Use Partial Mode with Kimi API](https://platform.moonshot.ai/docs/guide/use-partial-mode-feature-of-kimi-api)
    * [Use Kimi API for File-Based Q&A](https://platform.moonshot.ai/docs/guide/use-kimi-api-for-file-based-qa)
    * [Use Playground to Debug the Model](https://platform.moonshot.ai/docs/guide/use-playground-to-debug-the-model)
    * [Use kimi-k2 Model in ClaudeCode/Cline/RooCode](https://platform.moonshot.ai/docs/guide/agent-support)
    * [Configure ModelScope MCP Server in Playground](https://platform.moonshot.ai/docs/guide/configure-the-modelscope-mcp-server)
    * [Use Official Tools in Kimi API](https://platform.moonshot.ai/docs/guide/use-official-tools)
    * [Use Kimi CLI to Call Kimi Model](https://platform.moonshot.ai/docs/guide/kimi-cli-support)
    * [Use Kimi K2 Model to Setup Agent](https://platform.moonshot.ai/docs/guide/use-kimi-k2-to-setup-agent)
    * [Best Practices for Benchmarking](https://platform.moonshot.ai/docs/guide/benchmark-best-practice)
    * [Best Practices for Prompts](https://platform.moonshot.ai/docs/guide/prompt-best-practice)
    * [Best Practices for Organization Management](https://platform.moonshot.ai/docs/guide/org-best-practice)
    * [Frequently Asked Questions and Solutions](https://platform.moonshot.ai/docs/guide/faq)
  * Terms and Agreement
    * [Terms of Service for Kimi OpenPlatform](https://platform.moonshot.ai/docs/agreement/modeluse)
    * [Kimi OpenPlatform Privacy Policy](https://platform.moonshot.ai/docs/agreement/userprivacy)


  * [Moonshot‚Üó (opens in a new tab)](https://www.moonshot.ai/)
  * [Forum‚Üó (opens in a new tab)](https://forum.moonshot.ai/)
  * [Discord‚Üó (opens in a new tab)](https://discord.gg/TYU2fdJykW)
  * Contact Us Via Email‚Üó (opens in a new tab)
  * [‰∏≠ÂõΩÁ´ô | platform.moonshot.cn‚Üó (opens in a new tab)](https://platform.moonshot.cn/)


Outline
  * [Public Service Address](https://platform.moonshot.ai/docs/api/chat#public-service-address)
  * [Single-turn chat](https://platform.moonshot.ai/docs/api/chat#single-turn-chat)
  * [Multi-turn chat](https://platform.moonshot.ai/docs/api/chat#multi-turn-chat)
  * [Chat Completion](https://platform.moonshot.ai/docs/api/chat#chat-completion)
  * [Request URL](https://platform.moonshot.ai/docs/api/chat#request-url)
  * [Request](https://platform.moonshot.ai/docs/api/chat#request)
  * [Return](https://platform.moonshot.ai/docs/api/chat#return)
  * [Example Request](https://platform.moonshot.ai/docs/api/chat#example-request)
  * [Vision](https://platform.moonshot.ai/docs/api/chat#vision)
  * [List Models](https://platform.moonshot.ai/docs/api/chat#list-models)
  * [Request URL](https://platform.moonshot.ai/docs/api/chat#request-url-1)
  * [Example request](https://platform.moonshot.ai/docs/api/chat#example-request-2)
  * [Error Explanation](https://platform.moonshot.ai/docs/api/chat#error-explanation)


Back to top
Docs
API Reference
Chat
# Basic Information
##  Public Service Address[](https://platform.moonshot.ai/docs/api/chat#public-service-address)
```
https://api.moonshot.ai
```

Moonshot offers API services based on HTTP, and for most APIs, we are compatible with the OpenAI SDK.
# Quickstart
##  Single-turn chat[](https://platform.moonshot.ai/docs/api/chat#single-turn-chat)
The official OpenAI SDK supports [Python (opens in a new tab)](https://github.com/openai/openai-python) and [Node.js (opens in a new tab)](https://github.com/openai/openai-node). Below are examples of how to interact with the API using OpenAI SDK and Curl:
pythoncurlnode.js
```
from openai import OpenAI
 
client = OpenAI(
    api_key = "$MOONSHOT_API_KEY",
    base_url = "https://api.moonshot.ai/v1",
)
 
completion = client.chat.completions.create(
    model = "kimi-k2-turbo-preview",
    messages = [
        {"role": "system", "content": "You are Kimi, an AI assistant provided by Moonshot AI. You are proficient in Chinese and English conversations. You provide users with safe, helpful, and accurate answers. You will reject any questions involving terrorism, racism, or explicit content. Moonshot AI is a proper noun and should not be translated."},
        {"role": "user", "content": "Hello, my name is Li Lei. What is 1+1?"}
    ],
    temperature = 0.6,
)
 
print(completion.choices[0].message.content)
```

Replace `$MOONSHOT_API_KEY` with the API Key you created on the platform.
When running the code in the documentation using the OpenAI SDK, ensure that your Python version is at least 3.7.1, your Node.js version is at least 18, and your OpenAI SDK version is no lower than 1.0.0.
```
pip install --upgrade 'openai>=1.0'
```

> You can easily check the version of your library like this:
> ```
python -c 'import openai; print("version =",openai.__version__)'
# The output might be version = 1.10.0, indicating that the current python is using the v1.10.0 library of openai
```

##  Multi-turn chat[](https://platform.moonshot.ai/docs/api/chat#multi-turn-chat)
In the single-turn chat example above, the language model takes a list of user messages as input and returns the generated response as output. Sometimes, we can also use the model's output as part of the input to achieve multi-turn chat. Below is a simple example of implementing multi-turn chat:
pythonnode.js
```
from openai import OpenAI
 
client = OpenAI(
    api_key = "$MOONSHOT_API_KEY",
    base_url = "https://api.moonshot.ai/v1",
)
 
history = [
    {"role": "system", "content": "You are Kimi, an AI assistant provided by Moonshot AI. You are proficient in Chinese and English conversations. You provide users with safe, helpful, and accurate answers. You will reject any questions involving terrorism, racism, or explicit content. Moonshot AI is a proper noun and should not be translated."}
]
 
def chat(query, history):
    history.append({
        "role": "user", 
        "content": query
    })
    completion = client.chat.completions.create(
        model="kimi-k2-turbo-preview",
        messages=history,
        temperature=0.6,
    )
    result = completion.choices[0].message.content
    history.append({
        "role": "assistant",
        "content": result
    })
    return result
 
print(chat("What is the rotation period of the Earth?", history))
print(chat("What about the Moon?", history))
```

It is worth noting that as the chat progresses, the number of tokens the model needs to process will increase linearly. When necessary, some optimization strategies should be employed, such as retaining only the most recent few rounds of chat.
# API Documentation
##  Chat Completion[](https://platform.moonshot.ai/docs/api/chat#chat-completion)
###  Request URL[](https://platform.moonshot.ai/docs/api/chat#request-url)
```
POST https://api.moonshot.ai/v1/chat/completions
```

###  Request[](https://platform.moonshot.ai/docs/api/chat#request)
####  Example[](https://platform.moonshot.ai/docs/api/chat#example)
```
{
    "model": "kimi-k2-turbo-preview",
    "messages": [
        {
            "role": "system",
            "content": "You are Kimi, an AI assistant provided by Moonshot AI. You are proficient in Chinese and English conversations. You aim to provide users with safe, helpful, and accurate responses. You will refuse to answer any questions related to terrorism, racism, or explicit content. Moonshot AI is a proper noun and should not be translated into other languages."
        },
        { "role": "user", "content": "Hello, my name is Li Lei. What is 1+1?" }
    ],
    "temperature": 0.6
}
```

####  Request body[](https://platform.moonshot.ai/docs/api/chat#request-body)
Field | Required | Description | Type | Values  
---|---|---|---|---  
messages | required | A list of messages that have been exchanged in the conversation so far | List[Dict] | This is a list of structured elements, each similar to: `{"role": "user", "content": "Hello"}` The role can only be one of `system`, `user`, `assistant`, and the content must not be empty. See [Content Field Description](https://platform.moonshot.ai/docs/api/chat#content-field-description) for detailed information about the content field formats  
model | required | Model ID, which can be obtained through List Models | string | Currently one of `kimi-k2.5`,`kimi-k2-0905-preview`, `kimi-k2-0711-preview`, `kimi-k2-turbo-preview`, `kimi-k2-thinking-turbo`, `kimi-k2-thinking`, `moonshot-v1-8k`,`moonshot-v1-32k`,`moonshot-v1-128k`, `moonshot-v1-auto`,`moonshot-v1-8k-vision-preview`,`moonshot-v1-32k-vision-preview`,`moonshot-v1-128k-vision-preview`  
max_tokens | optional | Deprecated, please refer to max_completion_tokens | int | -  
max_completion_tokens | optional | The maximum number of tokens to generate for the chat completion. If the result reaches the maximum number of tokens without ending, the finish reason will be "length"; otherwise, it will be "stop" | int | It is recommended to provide a reasonable value as needed. If not provided, we will use a good default integer like 1024. **Note:** This `max_completion_tokens` refers to the length of the tokens you expect us to **return** , not the total length of input plus output. For example, for a `moonshot-v1-8k` model, the maximum total length of input plus output is 8192. When the total length of the input messages is 4096, you can set this to a maximum of 4096; otherwise, our service will return an invalid input parameter (invalid_request_error) and refuse to respond. If you want to know the "exact number of input tokens," you can use the "Token Calculation" API below to get the count using our calculator  
temperature | optional | The sampling temperature to use, ranging from 0 to 1. A higher value (e.g., 0.7) will make the output more random, while a lower value (e.g., 0.2) will make it more focused and deterministic | float | Default is 0.0 for `moonshot-v1` series models, 0.6 for `kimi-k2` models and 1.0 for `kimi-k2-thinking` models. This parameter cannot be modified for the `kimi-k2.5` model.  
top_p | optional | Another sampling method, where the model considers the results of tokens with a cumulative probability mass of top_p. Thus, 0.1 means only considering the top 10% of tokens by probability mass. Generally, we suggest changing either this or the temperature, but not both at the same time | float | Default is 1.0 for `moonshot-v1` series and `kimi-k2` models, 0.95 for `kimi-k2.5` model. This parameter cannot be modified for the `k2.5` model.  
n | optional | The number of results to generate for each input message | int | Default is 1 for `moonshot-v1` series and `kimi-k2` models, and it must not exceed 5. Specifically, when the temperature is very close to 0, we can only return one result. If n is set and > 1 in this case, our service will return an invalid input parameter (invalid_request_error). Default is 1 for `kimi-k2.5` model and it cannot be modified.  
presence_penalty | optional | Presence penalty, a number between -2.0 and 2.0. A positive value will penalize new tokens based on whether they appear in the text, increasing the likelihood of the model discussing new topics | float | Default is 0. This parameter cannot be modified for the `kimi-k2.5` model.  
frequency_penalty | optional | Frequency penalty, a number between -2.0 and 2.0. A positive value will penalize new tokens based on their existing frequency in the text, reducing the likelihood of the model repeating the same phrases verbatim | float | Default is 0. This parameter cannot be modified for the `kimi-k2.5` model.  
response_format | optional | Setting this to `{"type": "json_object"}` enables JSON mode, ensuring that the generated information is valid JSON. When you set response_format to `{"type": "json_object"}`, **you must explicitly guide the model to output JSON-formatted content in the prompt and specify the exact format of the JSON, otherwise it may result in unexpected outcomes**. | object | Default is `{"type": "text"}`  
stop | optional | Stop words, which will halt the output when a full match is found. The matched words themselves will not be output. A maximum of 5 strings is allowed, and each string must not exceed 32 bytes | String, List[String] | Default is null  
thinking | optional | Only available for `kimi-k2.5` model. This parameter controls if the thinking is enabled for this request | object | Default to be `{"type": "enabled"}`. Value can only be one of `{"type": "enabled"}` or `{"type": "disabled"}`  
stream | optional | Whether to return the response in a streaming fashion | bool | Default is false, and true is an option  
stream_options.include_usage | optional | If set, an additional chunk will be streamed before the `data: [DONE]` message. The usage field on this chunk shows the token usage statistics for the entire request, and the choices field will always be an empty array. All other chunks will also include a usage field, but with a null value. NOTE: If the stream is interrupted, you may not receive the final usage chunk which contains the total token usage for the request | bool | Default is false  
prompt_cache_key | optional | Used to cache responses for similar requests to optimize cache hit rates | string | Default is null. For Coding Agents, this is typically a session id or task id representing a single session; if the session is exited and later resumed, this value should remain the same. For Kimi Code Plan, this field is required to improve cache hit rates. For other agents involving multi-turn conversations, it is also recommended to implement this field  
safety_identifier | optional | A stable identifier used to help detect users of your application that may be violating usage policies. The ID should be a string that uniquely identifies each user. It is recommended to hash the username or email address to avoid sending any identifying information | string | Default is null  
####  Content Field Description[](https://platform.moonshot.ai/docs/api/chat#content-field-description)
The `content` field in the message can have different types of values:
  * plain text, just `string`
  * `List[Dict]` when you need to pass more complex information and each dict can have following fields: 
    * `type` field is always necessary and is used to identify type of content. Its value should be one of `text`, `image_url` or `video_url`.
    * `text` field is necessary when`type` is `text`. Its value should be plain text.
    * `image_url` field is necessary when `type` is `image_url`. Its value should be a dict indicating content of image like `{"url": "data:image/png;base64,abc123xxxxx==}`
    * `video_url` field is necessary when `type` is `video_url`. Its value should be a dict indicating content of videl like `{"url": "data:video/mp4;base64,def456yyyyy==}`


The following are all valid content field examples:
  * `"Hello"`
  * `[{"type": "text", "text": "Hello"}]`
  * `[{"type": "image_url", "image_url": {"url": "data:image/png;base64,abc123xxxxx=="}}]`
  * `[{"type": "video_url", "video_url": {"url": "data:video/mp4;base64,def456yyyyy=="}}]`
  * `[{"type": "text", "text": "ËøôÊòØ‰ªÄ‰πàÔºü"}, {"type": "image_url", "image_url": {"url": "data:image/png;base64,abc123xxxxx=="}}]`


**Note** that `url` field of `image_url` and `video_url` can be base64 format or `ms://<file_id>`. Please refer to [Use the Kimi Vision Model](https://platform.moonshot.ai/docs/guide/use-kimi-vision-model.en-US) for detail.
###  Return[](https://platform.moonshot.ai/docs/api/chat#return)
For non-streaming responses, the return format is similar to the following:
```
{
    "id": "cmpl-04ea926191a14749b7f2c7a48a68abc6",
    "object": "chat.completion",
    "created": 1698999496,
    "model": "kimi-k2-turbo-preview",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "Hello, Li Lei! 1+1 equals 2. If you have any other questions, feel free to ask!"
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 19,
        "completion_tokens": 21,
        "total_tokens": 40,
        "cached_tokens": 10  # The number of tokens hit by the cache, only models that support automatic caching will return this field
    }
}
```

For streaming responses, the return format is similar to the following:
```
data: {"id":"cmpl-1305b94c570f447fbde3180560736287","object":"chat.completion.chunk","created":1698999575,"model":"kimi-k2-turbo-preview","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}
 
data: {"id":"cmpl-1305b94c570f447fbde3180560736287","object":"chat.completion.chunk","created":1698999575,"model":"kimi-k2-turbo-preview","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}
 
...
 
data: {"id":"cmpl-1305b94c570f447fbde3180560736287","object":"chat.completion.chunk","created":1698999575,"model":"kimi-k2-turbo-preview","choices":[{"index":0,"delta":{"content":"."},"finish_reason":null}]}
 
data: {"id":"cmpl-1305b94c570f447fbde3180560736287","object":"chat.completion.chunk","created":1698999575,"model":"kimi-k2-turbo-preview","choices":[{"index":0,"delta":{},"finish_reason":"stop","usage":{"prompt_tokens":19,"

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://api-docs.deepseek.com/api/create-chat-completion

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://api-docs.deepseek.com/api/create-chat-completion           
| ‚úì | ‚è±: 0.55s 
[SCRAPE].. ‚óÜ https://api-docs.deepseek.com/api/create-chat-completion           
| ‚úì | ‚è±: 0.05s 
[COMPLETE] ‚óè https://api-docs.deepseek.com/api/create-chat-completion           
| ‚úì | ‚è±: 0.60s 
[Skip to main content](https://api-docs.deepseek.com/api/create-chat-completion#__docusaurus_skipToContent_fallback)
[ ![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png)![DeepSeek API Docs Logo](https://cdn.deepseek.com/platform/favicon.png) **DeepSeek API Docs**](https://api-docs.deepseek.com/)
[](https://api-docs.deepseek.com/api/create-chat-completion#)
  * [English](https://api-docs.deepseek.com/api/create-chat-completion)
  * [‰∏≠ÊñáÔºà‰∏≠ÂõΩÔºâ](https://api-docs.deepseek.com/zh-cn/api/create-chat-completion)


[DeepSeek Platform](https://platform.deepseek.com/)
  * [Quick Start](https://api-docs.deepseek.com/)
    * [Your First API Call](https://api-docs.deepseek.com/)
    * [Models & Pricing](https://api-docs.deepseek.com/quick_start/pricing)
    * [The Temperature Parameter](https://api-docs.deepseek.com/quick_start/parameter_settings)
    * [Token & Token Usage](https://api-docs.deepseek.com/quick_start/token_usage)
    * [Rate Limit](https://api-docs.deepseek.com/quick_start/rate_limit)
    * [Error Codes](https://api-docs.deepseek.com/quick_start/error_codes)
  * [News](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2 Release 2025/12/01](https://api-docs.deepseek.com/news/news251201)
    * [DeepSeek-V3.2-Exp Release 2025/09/29](https://api-docs.deepseek.com/news/news250929)
    * [DeepSeek V3.1 Update 2025/09/22](https://api-docs.deepseek.com/news/news250922)
    * [DeepSeek V3.1 Release 2025/08/21](https://api-docs.deepseek.com/news/news250821)
    * [DeepSeek-R1-0528 Release 2025/05/28](https://api-docs.deepseek.com/news/news250528)
    * [DeepSeek-V3-0324 Release 2025/03/25](https://api-docs.deepseek.com/news/news250325)
    * [DeepSeek-R1 Release 2025/01/20](https://api-docs.deepseek.com/news/news250120)
    * [DeepSeek APP 2025/01/15](https://api-docs.deepseek.com/news/news250115)
    * [Introducing DeepSeek-V3 2024/12/26](https://api-docs.deepseek.com/news/news1226)
    * [DeepSeek-V2.5-1210 Release 2024/12/10](https://api-docs.deepseek.com/news/news1210)
    * [DeepSeek-R1-Lite Release 2024/11/20](https://api-docs.deepseek.com/news/news1120)
    * [DeepSeek-V2.5 Release 2024/09/05](https://api-docs.deepseek.com/news/news0905)
    * [Context Caching is Available 2024/08/02](https://api-docs.deepseek.com/news/news0802)
    * [New API Features 2024/07/25](https://api-docs.deepseek.com/news/news0725)
  * [API Reference](https://api-docs.deepseek.com/api/deepseek-api)
    * [Introduction](https://api-docs.deepseek.com/api/deepseek-api)
    * [Chat](https://api-docs.deepseek.com/api/create-chat-completion)
      * [Create Chat Completion](https://api-docs.deepseek.com/api/create-chat-completion)
    * [Completions](https://api-docs.deepseek.com/api/create-completion)
    * [Models](https://api-docs.deepseek.com/api/list-models)
    * [Others](https://api-docs.deepseek.com/api/get-user-balance)
  * [API Guides](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Thinking Mode](https://api-docs.deepseek.com/guides/thinking_mode)
    * [Multi-round Conversation](https://api-docs.deepseek.com/guides/multi_round_chat)
    * [Chat Prefix Completion (Beta)](https://api-docs.deepseek.com/guides/chat_prefix_completion)
    * [FIM Completion (Beta)](https://api-docs.deepseek.com/guides/fim_completion)
    * [JSON Output](https://api-docs.deepseek.com/guides/json_mode)
    * [Tool Calls](https://api-docs.deepseek.com/guides/tool_calls)
    * [Context Caching](https://api-docs.deepseek.com/guides/kv_cache)
    * [Anthropic API](https://api-docs.deepseek.com/guides/anthropic_api)
  * [Other Resources](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [Integrations](https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main)
    * [API Status Page](https://status.deepseek.com/)
  * [FAQ](https://api-docs.deepseek.com/faq)
  * [Change Log](https://api-docs.deepseek.com/updates)


  * [](https://api-docs.deepseek.com/)
  * API Reference
  * Chat
  * Create Chat Completion


# Create Chat Completion
```
POST 
## /chat/completions

```

Creates a model response for the given chat conversation.
## Request[‚Äã](https://api-docs.deepseek.com/api/create-chat-completion#request "Direct link to Request")
  * application/json


Body
**
required
**
**
messages
**
object[]
required
**Possible values:** `>= 1`
A list of messages comprising the conversation so far.
  * Array [
oneOf
    * System message
    * User message
    * Assistant message
    * Tool message
**content** stringrequired
The contents of the system message.
**role** stringrequired
**Possible values:** [`system`]
The role of the messages author, in this case `system`.
**name** string
An optional name for the participant. Provides the model information to differentiate between participants of the same role.
**content** Text content (string)required
The contents of the user message.
**role** stringrequired
**Possible values:** [`user`]
The role of the messages author, in this case `user`.
**name** string
An optional name for the participant. Provides the model information to differentiate between participants of the same role.
**content** stringnullablerequired
The contents of the assistant message.
**role** stringrequired
**Possible values:** [`assistant`]
The role of the messages author, in this case `assistant`.
**name** string
An optional name for the participant. Provides the model information to differentiate between participants of the same role.
**prefix** bool
(Beta) Set this to `true` to force the model to start its answer by the content of the supplied prefix in this `assistant` message. You must set `base_url="https://api.deepseek.com/beta"` to use this feature.
**reasoning_content** stringnullable
(Beta) Used for the `deepseek-reasoner` model in the [Chat Prefix Completion](https://api-docs.deepseek.com/guides/chat_prefix_completion) feature as the input for the CoT in the last assistant message. When using this feature, the `prefix` parameter must be set to `true`.
**role** stringrequired
**Possible values:** [`tool`]
The role of the messages author, in this case `tool`.
**content** Text content (string)required
The contents of the tool message.
**tool_call_id** stringrequired
Tool call that this message is responding to.
  * ]
**model** stringrequired
**Possible values:** [`deepseek-chat`, `deepseek-reasoner`]
ID of the model to use. You can use deepseek-chat.
**
thinking
**
object
nullable
Controls the switch between thinking and non-thinking mode.
**type** string
**Possible values:** [`enabled`, `disabled`]
If set to `enabled`, then use thinking mode. If set to `disabled`, then use non-thinking model.
**frequency_penalty** numbernullable
**Possible values:** `>= -2` and `<= 2`
**Default value:** `0`
Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
**max_tokens** integernullable
The maximum number of tokens that can be generated in the chat completion.
The total length of input tokens and generated tokens is limited by the model's context length.
For the value range and default value, please refer to the [documentation](https://api-docs.deepseek.com/quick_start/pricing).
**presence_penalty** numbernullable
**Possible values:** `>= -2` and `<= 2`
**Default value:** `0`
Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
**
response_format
**
object
nullable
An object specifying the format that the model must output. Setting to { "type": "json_object" } enables JSON Output, which guarantees the message the model generates is valid JSON.
**Important:** When using JSON Output, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if finish_reason="length", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.
**type** string
**Possible values:** [`text`, `json_object`]
**Default value:** `text`
Must be one of `text` or `json_object`.
**
stop
**
object
**
nullable
**
Up to 16 sequences where the API will stop generating further tokens.
oneOf
    * MOD1
    * MOD2
string
  * Array [
string
  * ]
**stream** booleannullable
If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events (SSE) as they become available, with the stream terminated by a `data: [DONE]` message.
**
stream_options
**
object
nullable
Options for streaming response. Only set this when you set `stream: true`.
**include_usage** boolean
If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.
**temperature** numbernullable
**Possible values:** `<= 2`
**Default value:** `1`
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
We generally recommend altering this or `top_p` but not both.
**top_p** numbernullable
**Possible values:** `<= 1`
**Default value:** `1`
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
We generally recommend altering this or `temperature` but not both.
**
tools
**
object[]
nullable
A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
  * Array [
**type** stringrequired
**Possible values:** [`function`]
The type of the tool. Currently, only `function` is supported.
**
function
**
object
required
**description** string
A description of what the function does, used by the model to choose when and how to call the function.
**name** stringrequired
The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
**
parameters
**
object
The parameters the functions accepts, described as a JSON Schema object. See the [Tool Calls Guide](https://api-docs.deepseek.com/guides/tool_calls) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
Omitting `parameters` defines a function with an empty parameter list.
**property name*** any
The parameters the functions accepts, described as a JSON Schema object. See the [Tool Calls Guide](https://api-docs.deepseek.com/guides/tool_calls) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
Omitting `parameters` defines a function with an empty parameter list.
**strict** boolean
**Default value:** `false`
If set to true, the API will use strict-mode for the tool calls to ensure the output always complies with the function's JSON schema. This is a Beta feature, for more details please refer to [Tool Calls Guide](https://api-docs.deepseek.com/guides/tool_calls)
  * ]
**
tool_choice
**
object
**
nullable
**
Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
`none` is the default when no tools are present. `auto` is the default if tools are present.
oneOf
    * ChatCompletionToolChoice
    * ChatCompletionNamedToolChoice
string
**Possible values:** [`none`, `auto`, `required`]
**type** stringrequired
**Possible values:** [`function`]
The type of the tool. Currently, only `function` is supported.
**
function
**
object
required
**name** stringrequired
The name of the function to call.
**logprobs** booleannullable
Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.
**top_logprobs** integernullable
**Possible values:** `<= 20`
An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.


## Responses[‚Äã](https://api-docs.deepseek.com/api/create-chat-completion#responses "Direct link to Responses")
  * 200 (No streaming)
  * 200 (Streaming)


OK, returns a `chat completion object`
  * application/json


  * Schema
  * Example (from schema)
  * Example


**
Schema
**
**id** stringrequired
A unique identifier for the chat completion.
**
choices
**
object[]
required
A list of chat completion choices.
  * Array [
**finish_reason** stringrequired
**Possible values:** [`stop`, `length`, `content_filter`, `tool_calls`, `insufficient_system_resource`]
The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `insufficient_system_resource` if the request is interrupted due to insufficient resource of the inference system.
**index** integerrequired
The index of the choice in the list of choices.
**
message
**
object
required
A chat completion message generated by the model.
**content** stringnullablerequired
The contents of the message.
**reasoning_content** stringnullable
For `deepseek-reasoner` model only. The reasoning contents of the assistant message, before the final answer.
**
tool_calls
**
object[]
The tool calls generated by the model.
  * Array [
**id** stringrequired
The ID of the tool call.
**type** stringrequired
**Possible values:** [`function`]
The type of the tool. Currently, only `function` is supported.
**
function
**
object
required
The function that the model called.
**name** stringrequired
The name of the function to call.
**arguments** stringrequired
The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
  * ]
**role** stringrequired
**Possible values:** [`assistant`]
The role of the author of this message.
**
logprobs
**
object
nullable
required
Log probability information for the choice.
**
content
**
object[]
nullable
required
A list of message content tokens with log probability information.
  * Array [
**token** stringrequired
The token.
**logprob** numberrequired
The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
**bytes** integer[]nullablerequired
A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
**
top_logprobs
**
object[]
required
List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
  * Array [
**token** stringrequired
The token.
**logprob** numberrequired
The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
**bytes** integer[]nullablerequired
A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
  * ]
  * ]
**
reasoning_content
**
object[]
nullable
A list of message content tokens with log probability information.
  * Array [
**token** stringrequired
The token.
**logprob** numberrequired
The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
**bytes** integer[]nullablerequired
A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
**
top_logprobs
**
object[]
required
List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
  * Array [
**token** stringrequired
The token.
**logprob** numberrequired
The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
**bytes** integer[]nullablerequired
A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
  * ]
  * ]
  * ]
**created** integerrequired
The Unix timestamp (in seconds) of when the chat completion was created.
**model** stringrequired
The model used for the chat completion.
**system_fingerprint** stringrequired
This fingerprint represents the backend configuration that the model runs with.
**object** stringrequired
**Possible values:** [`chat.completion`]
The object type, which is always `chat.completion`.
**
usage
**
object
Usage statistics for the completion request.
**completion_tokens** integerrequired
Number of tokens in the generated completion.
**prompt_tokens** integerrequired
Number of tokens in the prompt. It equals prompt_cache_hit_tokens + prompt_cache_miss_tokens.
**prompt_cache_hit_tokens** integerrequired
Number of tokens in the prompt that hits the context cache.
**prompt_cache_miss_tokens** integerrequired
Number of tokens in the prompt that misses the context cache.
**total_tokens** integerrequired
Total number of tokens used in the request (prompt + completion).
**
completion_tokens_details
**
object
Breakdown of tokens used in a completion.
**reasoning_tokens** integer
Tokens generated by the model for reasoning.


```
{  
  "id": "string",  
  "choices": [  
    {  
      "finish_reason": "stop",  
      "index": 0,  
      "message": {  
        "content": "string",  
        "reasoning_content": "string",  
        "tool_calls": [  
          {  
            "id": "string",  
            "type": "function",  
            "function": {  
              "name": "string",  
              "arguments": "string"  
            }  
          }  
        ],  
        "role": "assistant"  
      },  
      "logprobs": {  
        "content": [  
          {  
            "token": "string",  
            "logprob": 0,

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://docs.mistral.ai/deployment/ai-studio/pricing

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://docs.mistral.ai/deployment/ai-studio/pricing               
| ‚úì | ‚è±: 0.51s 
[SCRAPE].. ‚óÜ https://docs.mistral.ai/deployment/ai-studio/pricing               
| ‚úì | ‚è±: 0.01s 
[COMPLETE] ‚óè https://docs.mistral.ai/deployment/ai-studio/pricing               
| ‚úì | ‚è±: 0.53s 
[](https://docs.mistral.ai/)Docs & API
Search docs
‚åòK
[Docs](https://docs.mistral.ai/)[API](https://docs.mistral.ai/api)[Cookbooks](https://docs.mistral.ai/cookbooks)[Ambassadors](https://docs.mistral.ai/ambassadors)
Toggle theme[Reach out](https://mistral.ai/contact?utm_source=docs&utm_medium=header_cta&utm_campaign=studio_trial)[Try Studio ](https://console.mistral.ai?utm_source=docs&utm_medium=header_cta&utm_campaign=studio_trial)
Search docs
‚åòK
Getting Started
  * [Introduction](https://docs.mistral.ai/getting-started/introduction)
  * [Models](https://docs.mistral.ai/getting-started/models)
  * [Quickstart](https://docs.mistral.ai/getting-started/quickstart)
  * [SDK Clients](https://docs.mistral.ai/getting-started/clients)
  * [Model Customization](https://docs.mistral.ai/getting-started/customization)
  * [Glossary](https://docs.mistral.ai/getting-started/glossary)
  * [Changelog](https://docs.mistral.ai/getting-started/changelog)


Capabilities
  * [Chat Completions](https://docs.mistral.ai/capabilities/completion)
  * [Vision](https://docs.mistral.ai/capabilities/vision)
  * [Audio & Transcription](https://docs.mistral.ai/capabilities/audio_transcription)
  * [Reasoning](https://docs.mistral.ai/capabilities/reasoning)
  * [Document AI](https://docs.mistral.ai/capabilities/document_ai)
  * [Coding](https://docs.mistral.ai/capabilities/code_generation)
  * [Embeddings](https://docs.mistral.ai/capabilities/embeddings)
  * [Function Calling](https://docs.mistral.ai/capabilities/function_calling)
  * [Citations & References](https://docs.mistral.ai/capabilities/citations)
  * [Structured Outputs](https://docs.mistral.ai/capabilities/structured_output)
  * [Moderation & Guardrailing](https://docs.mistral.ai/capabilities/guardrailing)
  * [Fine-Tuning](https://docs.mistral.ai/capabilities/finetuning)
  * [Batch Inference](https://docs.mistral.ai/capabilities/batch)
  * [Predicted outputs](https://docs.mistral.ai/capabilities/predicted_outputs)


Agents
  * [Agents Introduction](https://docs.mistral.ai/agents/introduction)
  * [Agents & Conversations](https://docs.mistral.ai/agents/agents)
  * [Tools](https://docs.mistral.ai/agents/tools)
  * [Handoffs](https://docs.mistral.ai/agents/handoffs)


Deployment
  * [AI Studio](https://docs.mistral.ai/deployment/ai-studio)
    * [Organizations & Workspaces](https://docs.mistral.ai/deployment/ai-studio/organization)
    * [Rate Limits & Usage tiers](https://docs.mistral.ai/deployment/ai-studio/tier)
    * [Pricing](https://docs.mistral.ai/deployment/ai-studio/pricing)
  * [Cloud](https://docs.mistral.ai/deployment/cloud)
  * [Self-Deployment](https://docs.mistral.ai/deployment/self-deployment)


Mistral Vibe
  * [CLI Introduction](https://docs.mistral.ai/mistral-vibe/introduction)
  * [Agents & Skills](https://docs.mistral.ai/mistral-vibe/agents-skills)
  * [Offline / Local](https://docs.mistral.ai/mistral-vibe/local)


  * [Mistral AI Crawlers](https://docs.mistral.ai/robots)


  1. [](https://docs.mistral.ai/)
  2. Deployment
  3. [AI Studio](https://docs.mistral.ai/deployment/ai-studio)
  4. Pricing

Copy markdown
note
Please refer to the [pricing page](https://mistral.ai/pricing#api-pricing) for detailed information on costs.
[Rate Limits & Usage tiers](https://docs.mistral.ai/deployment/ai-studio/tier)[Cloud](https://docs.mistral.ai/deployment/cloud) 

### WHY MISTRAL
[About us](https://mistral.ai/about)[Our customers](https://mistral.ai/customers)[Careers](https://mistral.ai/careers)[Contact us](https://mistral.ai/contact)
### EXPLORE
[AI Solutions](https://mistral.ai/solutions)[Partners](https://mistral.ai/partners)[Research](https://mistral.ai/news?category=Research)
### DOCUMENTATION
[Documentation](https://docs.mistral.ai/)[Contributing](https://docs.mistral.ai/ambassadors)[Cookbooks](https://docs.mistral.ai/cookbooks)
### BUILD
[AI Studio](https://mistral.ai/products/la-plateforme)[Le Chat](https://mistral.ai/products/le-chat)[Mistral Code](https://mistral.ai/products/mistral-code)[Mistral Compute](https://mistral.ai/products/mistral-compute)[Try the API](https://docs.mistral.ai/api)
### LEGAL
[Terms of service](https://mistral.ai/terms)[Privacy policy](https://mistral.ai/terms#privacy-policy)[Legal notice](https://mistral.ai/legal)Privacy Choices[Brand](https://mistral.ai/brand)
### COMMUNITY
[Discord‚Üó](https://discord.gg/mistralai)[X‚Üó](https://x.com/mistralai)[Github‚Üó](https://github.com/mistralai)[LinkedIn‚Üó](https://linkedin.com/company/mistralai)[Ambassador](https://docs.mistral.ai/ambassadors)
Mistral AI ¬© 2026
Toggle theme
![Sun](https://docs.mistral.ai/assets/sprites/sun.gif)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)![Grass](https://docs.mistral.ai/_next/image?url=%2Fassets%2Fsprites%2Fgrass_tile.png&w=640&q=75)
![Cat](https://docs.mistral.ai/assets/sprites/cat-walking-white.gif)

---

[web_fetch]
üï∑Ô∏è Crawl4AI: https://ai.google.dev/gemini-api/docs/tokens

[INIT].... ‚Üí Crawl4AI 0.8.0 
[FETCH]... ‚Üì https://ai.google.dev/gemini-api/docs/tokens                       
| ‚úì | ‚è±: 2.41s 
[SCRAPE].. ‚óÜ https://ai.google.dev/gemini-api/docs/tokens                       
| ‚úì | ‚è±: 0.03s 
[COMPLETE] ‚óè https://ai.google.dev/gemini-api/docs/tokens                       
| ‚úì | ‚è±: 2.44s 
[ Skip to main content ](https://ai.google.dev/gemini-api/docs/tokens#main-content)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
`/`
  * English
  * Deutsch
  * Espa√±ol ‚Äì Am√©rica Latina
  * Fran√ßais
  * Indonesia
  * Italiano
  * Polski
  * Portugu√™s ‚Äì Brasil
  * Shqip
  * Ti√™ÃÅng Vi√™Ã£t
  * T√ºrk√ße
  * –†—É—Å—Å–∫–∏–π
  * ◊¢◊ë◊®◊ô◊™
  * ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©
  * ŸÅÿßÿ±ÿ≥€å
  * ‡§π‡§ø‡§Ç‡§¶‡•Ä
  * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
  * ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
  * ‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì
  * ‰∏≠Êñá ‚Äì ÁπÅÈ´î
  * Êó•Êú¨Ë™û
  * ÌïúÍµ≠Ïñ¥

[ Get API key ](https://aistudio.google.com/apikey) [ Cookbook ](https://github.com/google-gemini/cookbook) [ Community ](https://discuss.ai.google.dev/c/gemini-api/) Sign in
[ Docs ](https://ai.google.dev/gemini-api/docs) [ API reference ](https://ai.google.dev/api)
[ ![Gemini API](https://ai.google.dev/_static/googledevai/images/gemini-api-logo.svg) ](https://ai.google.dev/)
  * [ Gemini API  ](https://ai.google.dev/gemini-api/docs)
    * [ Docs  ](https://ai.google.dev/gemini-api/docs)
    * [ API reference  ](https://ai.google.dev/api)
  * [ Get API key  ](https://aistudio.google.com/apikey)
  * [ Cookbook  ](https://github.com/google-gemini/cookbook)
  * [ Community  ](https://discuss.ai.google.dev/c/gemini-api/)


  * Get started
  * [Overview](https://ai.google.dev/gemini-api/docs)
  * [Quickstart](https://ai.google.dev/gemini-api/docs/quickstart)
  * [API keys](https://ai.google.dev/gemini-api/docs/api-key)
  * [Libraries](https://ai.google.dev/gemini-api/docs/libraries)
  * [Interactions API](https://ai.google.dev/gemini-api/docs/interactions)
  * Models
  * [Gemini](https://ai.google.dev/gemini-api/docs/models)
  * [Gemini 3](https://ai.google.dev/gemini-api/docs/gemini-3)
  * [Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation)
  * [Veo](https://ai.google.dev/gemini-api/docs/video)
  * [Lyria](https://ai.google.dev/gemini-api/docs/music-generation)
  * [Imagen](https://ai.google.dev/gemini-api/docs/imagen)
  * [Embeddings](https://ai.google.dev/gemini-api/docs/embeddings)
  * [Robotics](https://ai.google.dev/gemini-api/docs/robotics-overview)
  * [Text-to-speech](https://ai.google.dev/gemini-api/docs/speech-generation)
  * [Pricing](https://ai.google.dev/gemini-api/docs/pricing)
  * [Rate limits](https://ai.google.dev/gemini-api/docs/rate-limits)
  * Core capabilities
  * [Text](https://ai.google.dev/gemini-api/docs/text-generation)
  * Image
    * [Image generation üçå](https://ai.google.dev/gemini-api/docs/image-generation)
    * [Image understanding](https://ai.google.dev/gemini-api/docs/image-understanding)
  * Video
    * [Video generation](https://ai.google.dev/gemini-api/docs/video)
    * [Video understanding](https://ai.google.dev/gemini-api/docs/video-understanding)
  * [Documents](https://ai.google.dev/gemini-api/docs/document-processing)
  * Speech and audio
    * [Speech generation](https://ai.google.dev/gemini-api/docs/speech-generation)
    * [Audio understanding](https://ai.google.dev/gemini-api/docs/audio)
  * Thinking
    * [Thinking](https://ai.google.dev/gemini-api/docs/thinking)
    * [Thought signatures](https://ai.google.dev/gemini-api/docs/thought-signatures)
  * [Structured outputs](https://ai.google.dev/gemini-api/docs/structured-output)
  * [Function calling](https://ai.google.dev/gemini-api/docs/function-calling)
  * [Long context](https://ai.google.dev/gemini-api/docs/long-context)
  * Tools and agents
  * [Overview](https://ai.google.dev/gemini-api/docs/tools)
  * [Deep Research](https://ai.google.dev/gemini-api/docs/deep-research)
  * [Google Search](https://ai.google.dev/gemini-api/docs/google-search)
  * [Google Maps](https://ai.google.dev/gemini-api/docs/maps-grounding)
  * [Code execution](https://ai.google.dev/gemini-api/docs/code-execution)
  * [URL context](https://ai.google.dev/gemini-api/docs/url-context)
  * [Computer Use](https://ai.google.dev/gemini-api/docs/computer-use)
  * [File Search](https://ai.google.dev/gemini-api/docs/file-search)
  * Live API
  * [Get started](https://ai.google.dev/gemini-api/docs/live)
  * [Capabilities](https://ai.google.dev/gemini-api/docs/live-guide)
  * [Tool use](https://ai.google.dev/gemini-api/docs/live-tools)
  * [Session management](https://ai.google.dev/gemini-api/docs/live-session)
  * [Ephemeral tokens](https://ai.google.dev/gemini-api/docs/ephemeral-tokens)
  * Guides
  * [Batch API](https://ai.google.dev/gemini-api/docs/batch-api)
  * File input
    * [Input methods](https://ai.google.dev/gemini-api/docs/file-input-methods)
    * [Files API](https://ai.google.dev/gemini-api/docs/files)
  * [Context caching](https://ai.google.dev/gemini-api/docs/caching)
  * [OpenAI compatibility](https://ai.google.dev/gemini-api/docs/openai)
  * [Media resolution](https://ai.google.dev/gemini-api/docs/media-resolution)
  * [Token counting](https://ai.google.dev/gemini-api/docs/tokens)
  * [Prompt engineering](https://ai.google.dev/gemini-api/docs/prompting-strategies)
  * Logs and datasets
    * [Get started with logs](https://ai.google.dev/gemini-api/docs/logs-datasets)
    * [Data logging and sharing](https://ai.google.dev/gemini-api/docs/logs-policy)
  * Safety
    * [Safety settings](https://ai.google.dev/gemini-api/docs/safety-settings)
    * [Safety guidance](https://ai.google.dev/gemini-api/docs/safety-guidance)
  * Frameworks
    * [LangChain & LangGraph](https://ai.google.dev/gemini-api/docs/langgraph-example)
    * [CrewAI](https://ai.google.dev/gemini-api/docs/crewai-example)
    * [LlamaIndex](https://ai.google.dev/gemini-api/docs/llama-index)
    * [Vercel AI SDK](https://ai.google.dev/gemini-api/docs/vercel-ai-sdk-example)
  * Resources
  * [Migrate to Gen AI SDK](https://ai.google.dev/gemini-api/docs/migrate)
  * [Release notes](https://ai.google.dev/gemini-api/docs/changelog)
  * [Deprecations](https://ai.google.dev/gemini-api/docs/deprecations)
  * [API troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshooting)
  * [Billing info](https://ai.google.dev/gemini-api/docs/billing)
  * [Partner and library integrations](https://ai.google.dev/gemini-api/docs/partner-integration)
  * Google AI Studio
    * [Quickstart](https://ai.google.dev/gemini-api/docs/ai-studio-quickstart)
    * [Vibe code in Build mode](https://ai.google.dev/gemini-api/docs/aistudio-build-mode)
    * [Try out LearnLM](https://ai.google.dev/gemini-api/docs/learnlm)
    * [Troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio)
    * [Access for Workspace users](https://ai.google.dev/gemini-api/docs/workspace)
  * Google Cloud Platform
    * [VertexAI Gemini API](https://ai.google.dev/gemini-api/docs/migrate-to-cloud)
    * [OAuth authentication](https://ai.google.dev/gemini-api/docs/oauth)
  * Policies
  * [Terms of service](https://ai.google.dev/gemini-api/terms)
  * [Available regions](https://ai.google.dev/gemini-api/docs/available-regions)
  * [Additional usage polices](https://ai.google.dev/gemini-api/docs/usage-policies)


  * [ Home ](https://ai.google.dev/)
  * [ Gemini API ](https://ai.google.dev/gemini-api)
  * [ Docs ](https://ai.google.dev/gemini-api/docs)


Send feedback 
#  Understand and count tokens
Gemini and other generative AI models process input and output at a granularity called a _token_.
**For Gemini models, a token is equivalent to about 4 characters. 100 tokens is equal to about 60-80 English words.**
## About tokens
Tokens can be single characters like `z` or whole words like `cat`. Long words are broken up into several tokens. The set of all tokens used by the model is called the vocabulary, and the process of splitting text into tokens is called _tokenization_.
When billing is enabled, the [cost of a call to the Gemini API](https://ai.google.dev/pricing) is determined in part by the number of input and output tokens, so knowing how to count tokens can be helpful.
  

Python JavaScript Go
## Try out counting tokens in a Colab
You can try out counting tokens by using a Colab.
[![](https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png)View on ai.google.dev](https://ai.google.dev/gemini-api/docs/tokens) |  [![](https://www.tensorflow.org/images/colab_logo_32px.png)Try a Colab notebook](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Counting_Tokens.ipynb) |  [![](https://www.tensorflow.org/images/GitHub-Mark-32px.png)View notebook on GitHub](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Counting_Tokens.ipynb)  
---|---|---  
## Context windows
The models available through the Gemini API have context windows that are measured in tokens. The context window defines how much input you can provide and how much output the model can generate. You can determine the size of the context window by calling the [getModels endpoint](https://ai.google.dev/api/rest/v1/models/get) or by looking in the [models documentation](https://ai.google.dev/gemini-api/docs/models/gemini).
In the following example, you can see that the `gemini-2.0-flash` model has an input limit of about 1,000,000 tokens and an output limit of about 8,000 tokens, which means a context window is 1,000,000 tokens.
```
from google import genai

client = genai.Client()
model_info = client.models.get(model="gemini-2.0-flash")
print(f"{model_info.input_token_limit=}")
print(f"{model_info.output_token_limit=}")
# ( e.g., input_token_limit=30720, output_token_limit=2048 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L25-L31)


```

## Count tokens
All input to and output from the Gemini API is tokenized, including text, image files, and other non-text modalities.
You can count tokens in the following ways:
### Count text tokens
```
from google import genai

client = genai.Client()
prompt = "The quick brown fox jumps over the lazy dog."

# Count tokens using the new client method.
total_tokens = client.models.count_tokens(
    model="gemini-2.0-flash", contents=prompt
)
print("total_tokens: ", total_tokens)
# ( e.g., total_tokens: 10 )

response = client.models.generate_content(
    model="gemini-2.0-flash", contents=prompt
)

# The usage_metadata provides detailed token counts.
print(response.usage_metadata)
# ( e.g., prompt_token_count: 11, candidates_token_count: 73, total_token_count: 84 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L36-L54)


```

### Count multi-turn (chat) tokens
```
from google import genai
from google.genai import types

client = genai.Client()

chat = client.chats.create(
    model="gemini-2.0-flash",
    history=[
        types.Content(
            role="user", parts=[types.Part(text="Hi my name is Bob")]
        ),
        types.Content(role="model", parts=[types.Part(text="Hi Bob!")]),
    ],
)
# Count tokens for the chat history.
print(
    client.models.count_tokens(
        model="gemini-2.0-flash", contents=chat.get_history()
    )
)
# ( e.g., total_tokens: 10 )

response = chat.send_message(
    message="In one sentence, explain how a computer works to a young child."
)
print(response.usage_metadata)
# ( e.g., prompt_token_count: 25, candidates_token_count: 21, total_token_count: 46 )

# You can count tokens for the combined history and a new message.
extra = types.UserContent(
    parts=[
        types.Part(
            text="What is the meaning of life?",
        )
    ]
)
history = chat.get_history()
history.append(extra)
print(client.models.count_tokens(model="gemini-2.0-flash", contents=history))
# ( e.g., total_tokens: 56 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L59-L98)


```

### Count multimodal tokens
All input to the Gemini API is tokenized, including text, image files, and other non-text modalities. Note the following high-level key points about tokenization of multimodal input during processing by the Gemini API:
  * With Gemini 2.0, image inputs with both dimensions <=384 pixels are counted as 258 tokens. Images larger in one or both dimensions are cropped and scaled as needed into tiles of 768x768 pixels, each counted as 258 tokens. Prior to Gemini 2.0, images used a fixed 258 tokens.
  * Video and audio files are converted to tokens at the following fixed rates: video at 263 tokens per second and audio at 32 tokens per second.


#### Media resolutions
Gemini 3 Pro Preview introduces granular control over multimodal vision processing with the `media_resolution` parameter. The `media_resolution` parameter determines the **maximum number of tokens allocated per input image or video frame.** Higher resolutions improve the model's ability to read fine text or identify small details, but increase token usage and latency.
For more details about the parameter and how it can impact token calculations, see the [media resolution](https://ai.google.dev/gemini-api/docs/media-resolution) guide.
#### Image files
**Note:** You'll get the same token count if you use a file uploaded using the File API or you provide the file as inline data.
Example that uses an uploaded image from the File API:
```
from google import genai

client = genai.Client()
prompt = "Tell me about this image"
your_image_file = client.files.upload(file=media / "organ.jpg")

print(
    client.models.count_tokens(
        model="gemini-2.0-flash", contents=[prompt, your_image_file]
    )
)
# ( e.g., total_tokens: 263 )

response = client.models.generate_content(
    model="gemini-2.0-flash", contents=[prompt, your_image_file]
)
print(response.usage_metadata)
# ( e.g., prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L127-L144)


```

Example that provides the image as inline data:
```
from google import genai
import PIL.Image

client = genai.Client()
prompt = "Tell me about this image"
your_image_file = PIL.Image.open(media / "organ.jpg")

# Count tokens for combined text and inline image.
print(
    client.models.count_tokens(
        model="gemini-2.0-flash", contents=[prompt, your_image_file]
    )
)
# ( e.g., total_tokens: 263 )

response = client.models.generate_content(
    model="gemini-2.0-flash", contents=[prompt, your_image_file]
)
print(response.usage_metadata)
# ( e.g., prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L103-L122)


```

#### Video or audio files
Audio and video are each converted to tokens at the following fixed rates:
  * Video: 263 tokens per second
  * Audio: 32 tokens per second

**Note:** You'll get the same token count if you use a file uploaded using the File API or you provide the file as inline data.```
from google import genai
import time

client = genai.Client()
prompt = "Tell me about this video"
your_file = client.files.upload(file=media / "Big_Buck_Bunny.mp4")

# Poll until the video file is completely processed (state becomes ACTIVE).
while not your_file.state or your_file.state.name != "ACTIVE":
    print("Processing video...")
    print("File state:", your_file.state)
    time.sleep(5)
    your_file = client.files.get(name=your_file.name)

print(
    client.models.count_tokens(
        model="gemini-2.0-flash", contents=[prompt, your_file]
    )
)
# ( e.g., total_tokens: 300 )

response = client.models.generate_content(
    model="gemini-2.0-flash", contents=[prompt, your_file]
)
print(response.usage_metadata)
# ( e.g., prompt_token_count: 301, candidates_token_count: 60, total_token_count: 361 )
count_tokens.py[](https://github.com/google-gemini/api-examples/blob/856e8a0f566a2810625cecabba6e2ab1fe97e496/python/count_tokens.py#L149-L174)


```

### System instructions and tools
System instructions and tools also count towards the total token count for the input.
If you use system instructions, the `total_tokens` count increases to reflect the addition of `system_instruction`.
If you use function calling, the `total_tokens` count increases to reflect the addition of `tools`.
Send feedback 
Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.
Last updated 2025-12-18 UTC.
Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Missing the information I need","missingTheInformationINeed","thumb-down"],["Too complicated / too many steps","tooComplicatedTooManySteps","thumb-down"],["Out of date","outOfDate","thumb-down"],["Samples / code issue","samplesCodeIssue","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-12-18 UTC."],[],[]] 
  * [ Terms ](https://policies.google.com/terms)
  * [ Privacy ](https://policies.google.com/privacy)
  * [ Manage cookies ](https://ai.google.dev/gemini-api/docs/tokens#)


  * English
  * Deutsch
  * Espa√±ol ‚Äì Am√©rica Latina
  * Fran√ßais
  * Indonesia
  * Italiano
  * Polski
  * Portugu√™s ‚Äì Brasil
  * Shqip
  * Ti√™ÃÅng Vi√™Ã£t
  * T√ºrk√ße
  * –†—É—Å—Å–∫–∏–π
  * ◊¢◊ë◊®◊ô◊™
  * ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©
  * ŸÅÿßÿ±ÿ≥€å
  * ‡§π‡§ø‡§Ç‡§¶‡•Ä
  * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
  * ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
  * ‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì
  * ‰∏≠Êñá ‚Äì ÁπÅÈ´î
  * Êó•Êú¨Ë™û
  * ÌïúÍµ≠Ïñ¥


‚ùå API Error (iteration 19): terminated
